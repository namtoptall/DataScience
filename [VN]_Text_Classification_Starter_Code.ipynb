{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namtoptall/DataScience/blob/main/%5BVN%5D_Text_Classification_Starter_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AkEoCKaHdpj"
      },
      "source": [
        "\n",
        "Trong notebook này, chúng ta sẽ thử quy trình lập trình RNN với Keras để phân loại các câu văn bản.\n",
        "\n",
        "I.   **Trước tiên**, chúng ta sẽ nhập các thư viện hữu ích.\n",
        "\n",
        "II.   **Sau đó**, chúng ta sẽ load dữ liệu và tạo ma trận word embedding bằng Glove.\n",
        "\n",
        "III.  **Chúng ta sẽ thử một mô hình RNN đơn giản** rồi đánh giá chất lượng của nó.\n",
        "\n",
        "IV. Cuối cùng, chúng ta sẽ sử dụng các kỹ thuật để gia tăng độ chính xác của mô hình."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xY_w9I1cZni"
      },
      "source": [
        "**Task 1:** Thiết lập Fre GPU trong notebook này."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5WyHVt4_UbM",
        "outputId": "d7f4e683-e688-4206-f723-712a7cbaa2a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4iAL0E0ciDS"
      },
      "source": [
        "## Gắn Google Drive cục bộ\n",
        "**Task 2:** Gắn Google vào Google Colab Driver.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "I8iz8Rp8H5pG",
        "outputId": "87d8773f-1f19-47f9-f767-3e71775e2b17"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1c8bb342d9ed>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#mount drive content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "## VIẾT CODE cho task 2 ở đây:\n",
        "#mount drive content\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeAakuO9cD5s"
      },
      "source": [
        "# I. Nhập tất cả các thư viện hữu ích."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWgEP6KSHmV_"
      },
      "outputs": [],
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import tensorflow.keras\n",
        "import datetime\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras.optimizers as Optimizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "# import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from sklearn.metrics import confusion_matrix as CM\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plot\n",
        "import seaborn as sn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvFTfBIscRwC"
      },
      "source": [
        "**Task 3**: Copy tập dữ liệu từ Google Drive vào Colab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy txt file\n",
        "!cp /content/drive/MyDrive/asm2/glove.6B.50d.txt.zip ."
      ],
      "metadata": {
        "id": "YVWPzli_owD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqHYn0qaeH-w"
      },
      "outputs": [],
      "source": [
        "# unzip files\n",
        "!unzip glove.6B.50d.txt.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open the first 3 lines of the dataset\n",
        "text = open('glove.6B.50d.txt', 'r')\n",
        "for i in range(10):\n",
        "    print(text.readline())"
      ],
      "metadata": {
        "id": "WAtrmOGhg1JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the train\n",
        "!cp /content/drive/MyDrive/asm2/train.csv.zip ."
      ],
      "metadata": {
        "id": "kUPIFm8lhh7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the train\n",
        "!unzip /content/drive/MyDrive/asm2/train.csv.zip"
      ],
      "metadata": {
        "id": "AEvGPrajh3Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "2z9yc3iFiAcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "id": "-VWGoLzylW2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_GxFMl7dFJ-"
      },
      "source": [
        "# II. Load dữ liệu.\n",
        "\n",
        "## Về tập dữ liệu.\n",
        "Câu hỏi không hợp lệ là những câu hỏi nhằm đưa ra một tuyên bố thay vì tìm kiếm những câu trả lời hữu ích. Một số đặc điểm cho thấy câu hỏi không hợp lệ gồm:\n",
        "\n",
        "* Có giọng điệu không trung lập.\n",
        "* Có tính chê bai hoặc kích động.\n",
        "* Không có căn cứ thực tế.\n",
        "* Sử dụng nội dung khiêu dâm (loạn luân, thú tính, ấu dâm) để gây sốc, không phải để tìm kiếm câu trả lời xác thực.\n",
        "\n",
        "Dữ liệu bao gồm câu hỏi đã đề ra và liệu nó có được xác định là không hợp lệ hay không (target = 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9HhWwT-gpuN"
      },
      "source": [
        "**Task 4**: Load tập dữ liệu.\n",
        "* Load dữ liệu từ file CSV.\n",
        "* Xóa tất cả các hàng có giá trị NA.\n",
        "* Chia dữ liệu thành 3 tập: Tập huấn luyện, tập kiểm định và tập kiểm tra (0.9/0.05/0.05, random_seed = 9) với cùng một tỷ lệ số dữ liệu giữa mỗi lớp.\n",
        "* In ra mô tả của tập dữ liệu này.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9HMbZrqK1Rq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def load_data(data_link):\n",
        "    '''\n",
        "    input: data link.\n",
        "    output:\n",
        "        train_set, validation_set và test_set(0.95/0.05/0.05) mà không có các giá trị NA.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 4 ở đây:\n",
        "    data = pd.read_csv(data_link)\n",
        "    data = data.dropna()\n",
        "    # Chia dữ liệu thành tập huấn luyện và tập tạm thời (0.9/0.1)\n",
        "    train, temp = train_test_split(data, test_size=0.1, stratify=data['target'], random_state=9)\n",
        "    # Chia tập tạm thời thành tập kiểm định và tập kiểm tra (0.05/0.05)\n",
        "    validation, test = train_test_split(temp, test_size=0.5, stratify=temp['target'], random_state=9)\n",
        "    return train, validation, test\n",
        "\n",
        "train_set, validation_set, test_set = load_data('train.csv')\n",
        "print(train_set['target'].describe())\n",
        "print(validation_set['target'].describe())\n",
        "print(test_set['target'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIcOnRkbqofC"
      },
      "source": [
        "# Mã hóa dữ liệu văn bản.\n",
        "Hãy khai báo một số tham số cơ bản trước:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F3_zcCjHwzm"
      },
      "outputs": [],
      "source": [
        "embed_size = 50 # mỗi vectơ từ lớn bao nhiêu\n",
        "max_features = 20000 # cần sử dụng bao nhiêu từ duy nhất (tức là số hàng trong vectơ embedding)\n",
        "max_len = 50 # sử dụng số từ tối đa trong câu hỏi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8m71iixjxt"
      },
      "source": [
        "**Task 5:** Mã hóa tập dữ liệu bằng Tokenizer và vectơ biểu diễn one-hot.\n",
        "* Mã hóa văn bản (cột question_text) bằng cách chuyển từng question text thành danh sách chỉ mục từ bằng [Tokenizer](https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do) với **max_features** và tất cả các câu văn bản từ tập huấn luyện và tập kiểm định.\n",
        "* Chuyển từng danh sách chỉ mục từ thành độ dài như nhau - **max_len** (có cắt tỉa hoặc đệm nếu cần) bằng cách sử dụng [pad_sequences](https://keras.io/preprocessing/sequence/).\n",
        "* Mã hóa nhãn (cột nhãn) bằng cách sử dụng hàm [to_categorical](https://keras.io/utils/) trong Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1MZKNs4xmfP"
      },
      "outputs": [],
      "source": [
        "def encoding_textdata(train_set, validation_set, test_set, max_features, max_len):\n",
        "    '''\n",
        "    Input:\n",
        "    - Train/validation/test dataset.\n",
        "    - max_features, max_len.\n",
        "    Output:\n",
        "    - X train/validation/test, y train/validation/test.\n",
        "    - Tokenizer.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 5 ở đây:\n",
        "    tokenizer = Tokenizer(num_words=max_features)\n",
        "    tokenizer.fit_on_texts(train_set['question_text'])\n",
        "\n",
        "    X_tr = tokenizer.texts_to_sequences(train_set['question_text'])\n",
        "    X_va = tokenizer.texts_to_sequences(validation_set['question_text'])\n",
        "    X_te = tokenizer.texts_to_sequences(test_set['question_text'])\n",
        "\n",
        "    X_tr = pad_sequences(X_tr, maxlen=max_len)\n",
        "    X_va = pad_sequences(X_va, maxlen=max_len)\n",
        "    X_te = pad_sequences(X_te, maxlen=max_len)\n",
        "\n",
        "    y_tr = train_set['target']\n",
        "    y_va = validation_set['target']\n",
        "    y_te = test_set['target']\n",
        "\n",
        "    return (X_tr, y_tr), (X_va, y_va), (X_te, y_te), tokenizer # Return values from the outer function\n",
        "\n",
        "(X_tr, y_tr), (X_va, y_va), (X_te, y_te), tokenizer = encoding_textdata(train_set, validation_set, test_set, max_features, max_len) # Call the outer function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kpG-p30WUcc"
      },
      "source": [
        "**Task 6**: Tạo ma trận word embedding.\n",
        "* Đầu tiên, hãy viết một hàm để load [GloVe dictionary.](https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db)\n",
        "* Sau đó, tạo ma trận word embedding bằng GloVe dictionary với các tham số sau:\n",
        "    - Shape của ma trận word embedding: (Number of word, embed_size).\n",
        "    - Embed size: 50.\n",
        "    - Number of words: Tối thiểu của (max_features, len(word_index)), trong khi word_index là dictionary của từ chứa trong tokenizer.\n",
        "    - Nếu một từ xuất hiện trong GloVe dictionary, chúng ta nên lấy giá trị khởi tạo của nó như trong GloVe dictionary. Nếu không, hãy lấy một giá trị ngẫu nhiên bình thường với mean và std làm mean và std của giá trị GloVe dictionary.\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47s8-SncWT3V"
      },
      "outputs": [],
      "source": [
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def get_GloVe_dict(GloVe_link):\n",
        "    '''\n",
        "    input: GloVe link.\n",
        "    output: GloVe dictionary.\n",
        "    '''\n",
        "    GloVe_dict = {}\n",
        "    with open(GloVe_link, encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            word, coefs = get_coefs(*line.strip().split())\n",
        "            GloVe_dict[word] = coefs\n",
        "    return GloVe_dict\n",
        "GloVe_dict = get_GloVe_dict('glove.6B.50d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in GloVe_dict.items():\n",
        "    print(key, value)\n",
        "    break"
      ],
      "metadata": {
        "id": "xk4FDeKUpkkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXRyFSLtr4_k"
      },
      "outputs": [],
      "source": [
        "def create_embedding_matrix(GloVe_dict, tokenizer, max_features, embed_size):\n",
        "    '''\n",
        "    input: GloVe dictionary, tokenizer từ tập huấn luyện và tập kiểm định, số lượng đặc trưng tối đa, kích thước embedding.\n",
        "    output: Word embedding matrix.\n",
        "    '''\n",
        "    word_index = tokenizer.word_index\n",
        "    num_words = min(max_features, len(word_index) + 1)\n",
        "    embedding_matrix = np.zeros((num_words, embed_size))\n",
        "\n",
        "    all_embs = np.stack(list(GloVe_dict.values()))  # Chuyển đổi thành danh sách\n",
        "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
        "    emb_size = all_embs.shape[1]\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "            continue\n",
        "        embedding_vector = GloVe_dict.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            embedding_matrix[i] = np.random.normal(emb_mean, emb_std, emb_size)\n",
        "\n",
        "    return embedding_matrix\n",
        "embed_size = 50\n",
        "max_features = 20000\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(GloVe_dict, tokenizer, max_features, embed_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "jLIPgZyqrRcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWybjdQkqWrg"
      },
      "source": [
        "# III. Lập mô hình\n",
        "Chúng ta cần hoàn thành một số bước:\n",
        "\n",
        "Xây dựng mô hình.\n",
        "\n",
        "Biên dịch mô hình.\n",
        "\n",
        "Huấn luyện/khớp dữ liệu với mô hình.\n",
        "\n",
        "Đánh giá mô hình trên tập kiểm tra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6AMfqQkqcET"
      },
      "source": [
        "## Xây dựng mô hình\n",
        "**Task 7:** Chúng ta có thể xây dựng một mô hình dễ dàng gồm các layer khác nhau như:\n",
        "* Layer [Embedding](https://keras.io/layers/embeddings/) với max_features, embed_size và embedding_matrix.\n",
        "* [Bidirectional LSTM layer](https://keras.io/examples/nlp/bidirectional_lstm_imdb/?fbclid=IwAR3fEd6aWyeIDEhZSspjtCRiP0c0Jnz5-XdnUHQYwX8Tp8k9Ni4I8Q5tP9o) với số lượng trạng thái ẩn = 50, dropout_rate = 0.1 và recurrent_dropout_rate = 0.1.\n",
        "* GlobalMaxPool1D.\n",
        "* Dense với số nút = 50, activation = 'relu'.\n",
        "* Dropout với rate = 0.1.\n",
        "* Final dense với số nút = số class, activation = 'sigmoid'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7_eizWaqi_7"
      },
      "outputs": [],
      "source": [
        "def create_model(max_len, max_features, embed_size):\n",
        "    '''\n",
        "    input: max_len, max_features, embed_size\n",
        "    output: model.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 7 ở đây:\n",
        "    inputs = Input(shape=(max_len,))\n",
        "    embedding = Embedding(max_features,\n",
        "                            embed_size,\n",
        "                            weights=[embedding_matrix],trainable=False)(inputs)\n",
        "    lstm = Bidirectional(LSTM(50,\n",
        "                              return_sequences=True,\n",
        "                              dropout=0.1,\n",
        "                              recurrent_dropout=0.1))(embedding)\n",
        "    pooling = GlobalMaxPool1D()(lstm)\n",
        "    dense = Dense(50,activation='relu')(pooling)\n",
        "    dropout = Dropout(0.1)(dense)\n",
        "    output = Dense(1,activation='sigmoid')(dropout)\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model(max_len, max_features, embed_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWcBKhzMux9Z"
      },
      "source": [
        "**Task 8:** Biên dịch mô hình và thiết lập callback. Sau đó in ra model summary.\n",
        "* [Biên dịch](https://keras.io/models/model/#compile) mô hình với Adam Optimizer, lr = 1e-2, loss phù hợp cho bài toán phân loại nhị phân và [\"F1-score\"](https://github.com/tensorflow/addons/issues/825) là phép đo.\n",
        "* In ra model summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9l8EbG0ur1F"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def optimize(model):\n",
        "    model.compile(optimizer=Adam(learning_rate=0.01),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = optimize(model)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BlenccGzLVr"
      },
      "source": [
        "**Task 9**: Thiết lập callback.\n",
        "* Tạo [tensorboard callback](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks) để lưu logs.\n",
        "* Tạo [checkpoint callback](https://machinelearningmastery.com/check-point-deep-learning-models-keras/) để lưu checkpoint với độ chính xác tốt nhất sau mỗi epoch.\n",
        "* Tạo [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau) callback với factor=0.3, patience=1 và \"Validation F1-score\" monitor.\n",
        "* Tạo [early stopping callback](https://keras.io/callbacks/#earlystopping) với patience=7, mode = 'max' và \"Validation F1-score\" monitor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Tạo callback cho TensorBoard\n",
        "logs_name = 'training_logs'\n",
        "tensorboard_callback = TensorBoard(log_dir=logs_name, histogram_freq=1)"
      ],
      "metadata": {
        "id": "2hvDiAG99_M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6x6dteutin0"
      },
      "outputs": [],
      "source": [
        "# Hàm callback_model\n",
        "def callback_model(checkpoint_name, logs_name):\n",
        "    tensorboard_callback = TensorBoard(log_dir=logs_name, histogram_freq=1)\n",
        "    checkpoint_callback = ModelCheckpoint(filepath=checkpoint_name + '.keras',\n",
        "                                          save_best_only=True,\n",
        "                                          monitor='val_loss',\n",
        "                                          mode='min',\n",
        "                                          verbose=1)\n",
        "    reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='min')\n",
        "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=7, mode='min', verbose=1)\n",
        "\n",
        "    return [tensorboard_callback, checkpoint_callback, reduce_lr_callback, early_stopping_callback]\n",
        "\n",
        "checkpoint_name = 'weights.best'\n",
        "callbacks_list = callback_model(checkpoint_name, logs_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHTwh8OyvGqa"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nDCsHAC2HwW"
      },
      "source": [
        "**Task 10:** Huấn luyện mô hình.\n",
        "\n",
        "* Huấn luyện mô hình với 20 epoch với batch_size = 4096.\n",
        "* Trả về mô hình có trọng số checkpoint tốt nhất.\n",
        "\n",
        "*Gợi ý*: Trước tiên hãy khớp mô hình, sau đó reload mô hình (hàm load_model) với trọng số checkpoint tốt nhất."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xttwiHh4u0ES"
      },
      "outputs": [],
      "source": [
        "def train_model(model, callbacks_list):\n",
        "    '''\n",
        "    Input:\n",
        "        Mô hình và callback list,\n",
        "    Return:\n",
        "        Mô hình với trọng số checkpoint tốt nhất.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 10 ở đây:\n",
        "    model.fit(X_tr, y_tr,\n",
        "              batch_size=4096,\n",
        "              epochs=20,\n",
        "              validation_data=(X_va, y_va),\n",
        "              callbacks=callbacks_list)\n",
        "    model.load_weights('weights.best.keras')\n",
        "    return model\n",
        "\n",
        "model = train_model(model, callbacks_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsG02Ao07Mc-"
      },
      "source": [
        "**Task 11:** Hiển thị tensorboard trong notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpBk-EKZ2Ut7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "## VIẾT CODE cho task 11 ở đây:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs_name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "KvZfYjWO5DdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z1ed1CY8Rxh"
      },
      "source": [
        "**Task 12:** Dự đoán trên tập kiểm tra.\n",
        "\n",
        "* Hoàn thành hàm get_prediction_classes.\n",
        "* In ra precision, recall và F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHTjBLZYvx26"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def get_prediction_classes(model, X, y):\n",
        "    '''\n",
        "    Input:\n",
        "        Mô hình và tập dữ liệu dự đoán.\n",
        "    Return:\n",
        "        Prediction list và groundtruth list với predicted classes.\n",
        "    '''\n",
        "    y_pred = model.predict(X)\n",
        "    predictions = (y_pred > 0.5).astype(int).flatten()\n",
        "    groundtruths = y.values.flatten()\n",
        "    return predictions, groundtruths\n",
        "\n",
        "test_predictions, test_groundtruths = get_prediction_classes(model, X_te, y_te)\n",
        "print(f\"Precision: {precision_score(test_groundtruths, test_predictions)}\")\n",
        "print(f\"Recall: {recall_score(test_groundtruths, test_predictions)}\")\n",
        "print(f\"F1 Score: {f1_score(test_groundtruths, test_predictions)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJwQahjp8hZs"
      },
      "source": [
        "**Task 13:** Thực hiện kết quả dự đoán trên tập kiểm tra bằng cách sử dụng ma trận nhầm lẫn. Hãy nhớ hiển thị tên lớp trong ma trận nhầm lẫn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KKAmOGvv2Be"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(predictions, groundtruth, class_names):\n",
        "    ## VIẾT CODE cho task 13 ở đây:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plot.show()\n",
        "class_names = ['valid', 'invalid']\n",
        "plot_confusion_matrix(test_predictions, test_groundtruths, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGmUAFDi87Z6"
      },
      "source": [
        "**Task 14**: Tinh chỉnh mô hình - tinh chỉnh mô hình bằng cách sử dụng một số phương pháp sau:\n",
        "* Tăng tối đa epoch, thay đổi batch size.\n",
        "* Thay thế LSTM bằng các nút GRU và kiểm tra xem nó có thay đổi gì không.\n",
        "* Thêm một layer LSTM/GRU khác hoặc thay thế nó bằng mô-đun Attention/Transformers, xem có cải thiện gì không.\n",
        "* Thử với Dense layer (add/# units/...).\n",
        "* Tìm các quy tắc tiền xử lý mà bạn có thể thêm để cải thiện chất lượng dữ liệu.\n",
        "* Find another GloVe dictionary. Tìm một GloVe dictionary khác.\n",
        "Yêu cầu: F1 score phải tăng thêm 2-3%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELLyczmROE8J"
      },
      "outputs": [],
      "source": [
        "## VIẾT CODE cho task 14 ở đây:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}