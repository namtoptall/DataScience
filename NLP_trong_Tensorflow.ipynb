{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namtoptall/DataScience/blob/main/NLP_trong_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtAgo5zYCClj"
      },
      "source": [
        "# 08. X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP) v·ªõi TensorFlow\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-example-nlp-problems.png)\n",
        "*M·ªôt s·ªë v√≠ d·ª• v·ªÅ b√†i to√°n x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP) v√† hi·ªÉu ng√¥n ng·ªØ t·ª± nhi√™n (NLU). Ch√∫ng c√≤n ƒë∆∞·ª£c g·ªçi l√† b√†i to√°n sequence (t·ª´ sequence n√†y ƒë·∫øn sequence kh√°c).*\n",
        "\n",
        "M·ª•c ti√™u ch√≠nh c·ªßa [X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP)](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32) l√† l·∫•y th√¥ng tin t·ª´ ng√¥n ng·ªØ t·ª± nhi√™n.\n",
        "\n",
        "Ng√¥n ng·ªØ t·ª± nhi√™n l√† m·ªôt thu·∫≠t ng·ªØ r·ªông nh∆∞ng ch√∫ng ta c√≥ th·ªÉ coi n√≥ bao h√†m b·∫•t k·ª≥ nh·ªØng ƒëi·ªÅu sau:\n",
        "* Text (ch·∫≥ng h·∫°n nh∆∞ trong email, b√†i ƒëƒÉng blog, s√°ch, Tweet)\n",
        "* Speech (cu·ªôc h·ªôi tho·∫°i v·ªõi b√°c sƒ©, kh·∫©u l·ªánh truy·ªÅn cho loa th√¥ng minh)\n",
        "\n",
        "Ch√∫ng ta c√≥ th·ªÉ th·ª±c hi·ªán r·∫•t nhi·ªÅu th·ª© v·ªÅ text v√† speech.\n",
        "\n",
        "N·∫øu ƒëang x√¢y d·ª±ng m·ªôt ·ª©ng d·ª•ng email, ch√∫ng ta c√≥ th·ªÉ s·∫Ω mu·ªën qu√©t email ƒë·∫øn ƒë·ªÉ xem ch√∫ng c√≥ ph·∫£i l√† spam hay kh√¥ng (ph√¢n lo·∫°i).\n",
        "\n",
        "N·∫øu b·∫°n ƒëang c·ªë g·∫Øng ph√¢n t√≠ch c√°c ph·∫£n h·ªìi ph√†n n√†n c·ªßa kh√°ch h√†ng, c√≥ th·ªÉ b·∫°n s·∫Ω mu·ªën t√¨m hi·ªÉu xem nh·ªØng ph√†n n√†n n√†y d√†nh cho b·ªô ph·∫≠n n√†o c·ªßa c√¥ng ty.\n",
        "\n",
        "> üîë **L∆∞u √Ω:** C·∫£ hai lo·∫°i d·ªØ li·ªáu n√†y th∆∞·ªùng ƒë∆∞·ª£c g·ªçi l√† *sequence (chu·ªói)* (c√¢u l√† m·ªôt chu·ªói c√°c t·ª´). Do ƒë√≥, ch√∫ng ta c√≥ m·ªôt thu·∫≠t ng·ªØ th∆∞·ªùng th·∫•y trong c√°c b√†i to√°n NLP, ƒë√≥ l√† *seq2seq*, hay n√≥i c√°ch kh√°c l√† t√¨m th√¥ng tin trong m·ªôt chu·ªói ƒë·ªÉ t·∫°o m·ªôt chu·ªói kh√°c (v√≠ d·ª•: chuy·ªÉn ƒë·ªïi speech command th√†nh m·ªôt chu·ªói c√°c b∆∞·ªõc d·ª±a tr√™n text).\n",
        "\n",
        "ƒê·ªÉ l√†m quen v·ªõi NLP trong TensorFlow, ch√∫ng ta s·∫Ω luy·ªán t·∫≠p c√°c b∆∞·ªõc m√† ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng tr∆∞·ªõc ƒë√≥, nh∆∞ng l·∫ßn n√†y l√† v·ªõi d·ªØ li·ªáu text (vƒÉn b·∫£n).\n",
        "\n",
        "```\n",
        "Text -> chuy·ªÉn th√†nh s·ªë -> x√¢y d·ª±ng m√¥ h√¨nh -> hu·∫•n luy·ªán m√¥ h√¨nh ƒë·ªÉ t√¨m pattern -> s·ª≠ d·ª•ng pattern (ƒë∆∞a ra d·ª± ƒëo√°n)\n",
        "```\n",
        "\n",
        "> üìñ **T√†i li·ªáu:** ƒê·ªÉ c√≥ c√°i nh√¨n t·ªïng quan v·ªÅ NLP v√† c√°c b√†i to√°n NLP kh√°c nhau, h√£y ƒë·ªçc b√†i vi·∫øt [*A Simple Introduction to Natural Language Processing*](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32).\n",
        "\n",
        "## Nh·ªØng ƒëi·ªÅu ch√∫ng ta s·∫Ω t√¨m hi·ªÉu\n",
        "\n",
        "H√£y t√¨m hi·ªÉu c·ª• th·ªÉ\n",
        "\n",
        "* Download t·∫≠p d·ªØ li·ªáu text\n",
        "* Tr·ª±c quan h√≥a d·ªØ li·ªáu text\n",
        "* Chuy·ªÉn text th√†nh c√°c con s·ªë, s·ª≠ d·ª•ng tokenization\n",
        "* Bi·∫øn text ƒë∆∞·ª£c m√£ h√≥a th√†nh embedding\n",
        "* L·∫≠p m√¥ h√¨nh t·∫≠p d·ªØ li·ªáu text\n",
        "  * B·∫Øt ƒë·∫ßu v·ªõi baseline (TF-IDF)\n",
        "  * X√¢y d·ª±ng m·ªôt s·ªë m√¥ h√¨nh deep learning text\n",
        "    * Dense, LSTM, GRU, Conv1D, Transfer learning\n",
        "* So s√°nh ch·∫•t l∆∞·ª£ng c·ªßa t·ª´ng m√¥ h√¨nh\n",
        "* K·∫øt h·ª£p c√°c m√¥ h√¨nh th√†nh ensemble model\n",
        "* L∆∞u v√† load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n",
        "* T√¨m ra nh·ªØng d·ª± ƒëo√°n sai nh·∫•t\n",
        "\n",
        "## C√°ch ti·∫øp c·∫≠n notebook n√†y\n",
        "\n",
        "C√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc qua c√°c m√¥ t·∫£ v√† code (t·∫•t c·∫£ s·∫Ω ch·∫°y, tr·ª´ nh·ªØng cell m·∫Øc l·ªói c√≥ ch·ªß ƒë√≠ch), nh∆∞ng c√≥ m·ªôt l·ª±a ch·ªçn t·ªët h∆°n.\n",
        "\n",
        "T·ª± vi·∫øt to√†n b·ªô code.\n",
        "\n",
        "Nghi√™m t√∫c ƒë·∫•y. H√£y t·∫°o notebook m·ªõi v√† t·ª± vi·∫øt l·∫°i t·ª´ng d√≤ng. Ki·ªÉm tra xem b·∫°n c√≥ th·ªÉ thay ƒë·ªïi n√≥ kh√¥ng v√† l√Ω do cho ƒëi·ªÅu ƒë√≥.\n",
        "\n",
        "B·∫°n kh√¥ng c·∫ßn vi·∫øt m√¥ t·∫£ b·∫±ng vƒÉn b·∫£n nh∆∞ng t·ª± vi·∫øt l·∫°i code l√† m·ªôt c√°ch tuy·ªát v·ªùi ƒë·ªÉ c√≥ tr·∫£i nghi·ªám th·ª±c ti·ªÖn.\n",
        "\n",
        "ƒê·ª´ng lo l·∫Øng n·∫øu m·∫Øc sai s√≥t, ai c≈©ng ƒë·ªÅu m·∫Øc l·ªói c·∫£. C√°ch th·ª±c hi·ªán t·ªët h∆°n v√† m·∫Øc √≠t l·ªói h∆°n l√† vi·∫øt nhi·ªÅu code h∆°n.\n",
        "\n",
        "> üìñ **T√†i li·ªáu:** Xem b·ªô t√†i li·ªáu kh√≥a h·ªçc ƒë·∫ßy ƒë·ªß tr√™n GitHub: https://github.com/mrdbourke/tensorflow-deep-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zh2N1hZtvpN"
      },
      "source": [
        "## Ki·ªÉm tra GPU\n",
        "\n",
        "ƒê·ªÉ m√¥ h√¨nh DL ch·∫°y nhanh nh·∫•t c√≥ th·ªÉ, ch√∫ng ta c·∫ßn quy·ªÅn truy c·∫≠p v√†o GPU.\n",
        "\n",
        "Trong Google Colab, ch√∫ng ta c√≥ th·ªÉ c√†i ƒë·∫∑t ƒëi·ªÅu n√†y b·∫±ng c√°ch t·ªõi Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n",
        "\n",
        "Sau khi ch·ªçn GPU, ch√∫ng ta c√≥ th·ªÉ s·∫Ω ph·∫£i kh·ªüi ƒë·ªông l·∫°i runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEYTFigmc3CI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c44ca3-b01f-412c-a670-73b70e861937"
      },
      "source": [
        "# Ki·ªÉm tra GPU\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-7c8181f1-42c3-e0c6-0862-932bb75fde7b)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS3YnNNI8oFk"
      },
      "source": [
        "## L·∫•y h√†m h·ªó tr·ª£\n",
        "\n",
        "Trong c√°c m√¥-ƒëun tr∆∞·ªõc, ch√∫ng ta ƒë√£ t·∫°o kh√° nhi·ªÅu h√†m h·ªó tr·ª£ ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• nh·ªè c·∫ßn thi·∫øt cho notebook.\n",
        "\n",
        "Thay v√¨ vi·∫øt l·∫°i to√†n b·ªô, ch√∫ng ta c√≥ th·ªÉ import script v√† load ch√∫ng t·ª´ ƒë√≥.\n",
        "\n",
        "C√≥ th·ªÉ t√¨m th·∫•y script ch·ª©a c√°c h√†m h·ªó tr·ª£ tr√™n [GitHub](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFOHPqgE8pv-",
        "outputId": "523e55ff-21ee-41ed-e3a4-7e19274f9ea8"
      },
      "source": [
        "# Download script h√†m h·ªó tr·ª£\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-23 05:25:54--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py.4‚Äô\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-23 05:25:54 (43.6 MB/s) - ‚Äòhelper_functions.py.4‚Äô saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICFbSkoM85tq"
      },
      "source": [
        "# Import chu·ªói c√°c h√†m h·ªó tr·ª£ cho notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCZrclc2COWW"
      },
      "source": [
        "## Download t·∫≠p d·ªØ li·ªáu text\n",
        "\n",
        "H√£y b·∫Øt ƒë·∫ßu b·∫±ng c√°ch download t·∫≠p d·ªØ li·ªáu vƒÉn b·∫£n. Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu [Real or Not?](https://www.kaggle.com/c/nlp-getting-started/data) t·ª´ Kaggle, c√≥ ch·ª©a c√°c Tweet d·ª±a tr√™n vƒÉn b·∫£n v·ªÅ c√°c th·∫£m h·ªça thi√™n nhi√™n.\n",
        "\n",
        "C√°c Real Tweet v·ªÅ th·∫£m h·ªça nh∆∞:\n",
        "\n",
        "```\n",
        "Jetstar and Virgin forced to cancel Bali flights again because of ash from Mount Raung volcano\n",
        "```\n",
        "\n",
        "Not Real Tweet l√† c√°c tweet kh√¥ng thu·ªôc ch·ªß ƒë·ªÅ th·∫£m h·ªça (c√≥ th·ªÉ l√† b·∫•t c·ª© ch·ªß ƒë·ªÅ n√†o), ch·∫≥ng h·∫°n:\n",
        "\n",
        "```\n",
        "'Education is the most powerful weapon which you can use to change the world.' Nelson #Mandela #quote\n",
        "```\n",
        "\n",
        "ƒê·ªÉ thu·∫≠n ti·ªán, t·∫≠p d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c [download t·ª´ Kaggle](https://www.kaggle.com/c/nlp-getting-started/data) (s·∫Ω c·∫ßn t√†i kho·∫£n Kaggle) v√† upload ·ªü d·∫°ng file zip c√≥ th·ªÉ download.\n",
        "\n",
        "> üîë **L∆∞u √Ω:** D·ªØ li·ªáu download ban ƒë·∫ßu kh√¥ng b·ªã thay ƒë·ªïi theo c√°ch ch√∫ng ta download n√≥ t·ª´ Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0FEcci5IH8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a40c19-6eae-4323-d84e-c6af405fc0ba"
      },
      "source": [
        "# Download d·ªØ li·ªáu (t∆∞∆°ng t·ª± t·ª´ Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Gi·∫£i n√©n d·ªØ li·ªáu\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-23 05:25:57--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 66.102.1.128, 172.253.120.128, 74.125.206.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|66.102.1.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‚Äònlp_getting_started.zip.4‚Äô\n",
            "\n",
            "\r          nlp_getti   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-09-23 05:25:57 (101 MB/s) - ‚Äònlp_getting_started.zip.4‚Äô saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBIR6tTI9QcR"
      },
      "source": [
        "Gi·∫£i n√©n `nlp_getting_started.zip` s·∫Ω ƒë∆∞·ª£c 3 file `.csv` sau:\n",
        "* `sample_submission.csv` - v√≠ d·ª• v·ªÅ file m√† ch√∫ng ta n·ªôp cho cu·ªôc thi Kaggle c√≥ c√°c d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh.\n",
        "* `train.csv` - c√°c m·∫´u hu·∫•n luy·ªán c√≥ real Tweet not real Tweet v·ªÅ th·∫£m h·ªça\n",
        "* `test.csv` - c√°c m·∫´u ki·ªÉm tra c√≥ real Tweet not real Tweet v·ªÅ th·∫£m h·ªça"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HpxZKYdD6V-"
      },
      "source": [
        "## Tr·ª±c quan h√≥a d·ªØ li·ªáu text\n",
        "\n",
        "Sau khi c√≥ t·∫≠p d·ªØ li·ªáu m·ªõi ƒë·ªÉ l√†m vi·ªác, ƒë·∫ßu ti√™n ch√∫ng ta s·∫Ω l√†m g√¨?\n",
        "\n",
        "ThƒÉm d√≤? Ki·ªÉm tra? L√†m quen?\n",
        "\n",
        "T·∫•t c·∫£ ƒë·ªÅu ƒë√∫ng.\n",
        "\n",
        "Nh·ªõ l·∫°i ph∆∞∆°ng ch√¢m: visualize, visualize, visualize (tr·ª±c quan h√≥a).\n",
        "\n",
        " B√¢y gi·ªù, c√°c m·∫´u d·ªØ li·ªáu text ·ªü d·∫°ng file `.csv`. ƒê·ªÉ d·ªÖ d√†ng hi·ªÉn th·ªã, h√£y chuy·ªÉn ch√∫ng th√†nh pandas DataFrame.\n",
        "\n",
        "> üìñ **T√†i li·ªáu ƒë·ªçc:** Ch√∫ng ta s·∫Ω g·∫∑p c√°c t·∫≠p d·ªØ li·ªáu text ·ªü nhi·ªÅu ƒë·ªãnh d·∫°ng. Ngo√†i file CSV (ƒë·ªãnh d·∫°ng m√† ch√∫ng ta ƒëang thao t√°c), ch√∫ng ta c≈©ng c√≥ th·ªÉ s·∫Ω g·∫∑p file `.txt` v√† `.json`. ƒê·ªÉ l√†m vi·ªác v·ªõi c√°c ki·ªÉu file ƒë√≥, c√°c b·∫°n h√£y tham kh·∫£o hai b√†i vi·∫øt sau tr√™n Realpython:\n",
        "* [How to Read and Write Files in Python](https://realpython.com/read-write-files-python/)\n",
        "* [Working with JSON Data in Python](https://realpython.com/python-json/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRvkeYEJIKsw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "052a1d3e-1d52-47e9-ea39-df6dd4d149ca"
      },
      "source": [
        "# Bi·∫øn file .csv th√†nh pandas DataFrame\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xGqlnQaLmaT"
      },
      "source": [
        "D·ªØ li·ªáu hu·∫•n luy·ªán m√† ch√∫ng ta ƒë√£ download ƒë√£ b·ªã x√°o tr·ªôn, nh∆∞ng ƒë·ªÉ ch·∫Øc ch·∫Øn, h√£y x√°o tr·ªôn l·∫°i."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACCE7h6OMVjR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "51f2ae2e-df2a-4e15-a618-7087ecba1914"
      },
      "source": [
        "# X√°o tr·ªôn training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # x√°o tr·ªôn v·ªõi random_state=42 cho kh·∫£ nƒÉng t√°i l·∫∑p\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw4mKW1yL0kI"
      },
      "source": [
        "L∆∞u √Ω c√°ch d·ªØ li·ªáu hu·∫•n luy·ªán c√≥ c·ªôt `\"target\"`.\n",
        "\n",
        "Ch√∫ng ta s·∫Ω vi·∫øt code ƒë·ªÉ t√¨m c√°c pattern (v√≠ d·ª•: c√°c t·ªï h·ª£p kh√°c nhau c·ªßa c√°c t·ª´) trong c·ªôt `\"text\"` c·ªßa t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n gi√° tr·ªã c·ªßa c·ªôt `\"target\"`.\n",
        "\n",
        "T·∫≠p d·ªØ li·ªáu ki·ªÉm tra kh√¥ng c√≥ c·ªôt `\"target\"`.\n",
        "\n",
        "```\n",
        "Input (c·ªôt text) -> Thu·∫≠t to√°n Machine Learning -> Output (c·ªôt target)\n",
        "```\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-text-classification-inputs-and-outputs.png)\n",
        "*V√≠ d·ª• v·ªÅ ƒë·∫ßu v√†o v√† ƒë·∫ßu ra ph√¢n lo·∫°i text cho b√†i to√°n ph√¢n lo·∫°i xem Tweet c√≥ ph·∫£i l√† v·ªÅ th·∫£m h·ªça kh√¥ng.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDh5t7thI5BM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9f4321e2-a45e-4eef-93d1-71972c992e37"
      },
      "source": [
        "# D·ªØ li·ªáu ki·ªÉm tra kh√¥ng c√≥ target (ƒë√≥ l√† ƒëi·ªÅu m√† ch√∫ng ta s·∫Ω c·ªë d·ª± ƒëo√°n)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4JhBRn5Mn-V"
      },
      "source": [
        "H√£y ki·ªÉm tra xem ch√∫ng ta c√≥ bao nhi√™u m·∫´u c·ªßa m·ªói target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P5DnLhIciD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fa6a7a-a7cf-4dc5-b5a9-01ccb8dfbe61"
      },
      "source": [
        "# M·ªói l·ªõp c√≥ bao nhi√™u m·∫´u?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjEDQ297Ihy4"
      },
      "source": [
        "V√¨ ch√∫ng ta c√≥ hai gi√° tr·ªã target n√™n ch√∫ng ta s·∫Ω gi·∫£i quy·∫øt b√†i to√°n **ph√¢n lo·∫°i nh·ªã ph√¢n**.\n",
        "\n",
        "N√≥ c≈©ng kh√° c√¢n b·∫±ng, kho·∫£ng 60% l·ªõp negative (`target = 0`) v√† 40% l·ªõp positive (`target = 1`).\n",
        "\n",
        "Trong ƒë√≥,\n",
        "\n",
        "* `1` =  real disaster Tweet\n",
        "* `0` = not real disaster Tweet\n",
        "\n",
        "V·∫≠y c√≤n t·ªïng s·ªë m·∫´u m√† ch√∫ng ta c√≥?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQxg7EKKIy5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4aefe4-3405-4a94-8e8a-163386b25709"
      },
      "source": [
        "# C√≥ t·ªïng c·ªông bao nhi√™u m·∫´u?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1upY8-xNPWV"
      },
      "source": [
        "C√≥ v·∫ª ch√∫ng ta c√≥ l∆∞·ª£ng d·ªØ li·ªáu hu·∫•n luy·ªán v√† ki·ªÉm tra kha kh√°. N·∫øu c√≥ b·∫•t c·ª© ƒëi·ªÅu g√¨, ch√∫ng ta c√≥ r·∫•t nhi·ªÅu m·∫´u ki·ªÉm tra, th∆∞·ªùng c√≥ ph√¢n t√°ch 90/10 (90% hu·∫•n luy·ªán, 10% ki·ªÉm tra) ho·∫∑c 80/20 l√† ƒë·ªß.\n",
        "\n",
        "ƒê√£ ƒë·∫øn l√∫c tr·ª±c quan h√≥a, h√£y vi·∫øt m·ªôt √≠t code ƒë·ªÉ hi·ªÉn th·ªã c√°c m·∫´u vƒÉn b·∫£n ng·∫´u nhi√™n.\n",
        "\n",
        "> ü§î **C√¢u h·ªèi:** T·∫°i sao ph·∫£i hi·ªÉn th·ªã c√°c m·∫´u ng·∫´u nhi√™n? Ch√∫ng ta c√≥ th·ªÉ hi·ªÉn th·ªã c√°c m·∫´u theo th·ª© t·ª± nh∆∞ng ƒëi·ªÅu n√†y c√≥ th·ªÉ d·∫´n ƒë·∫øn vi·ªác ch√∫ng ta ch·ªâ th·∫•y m·ªôt t·∫≠p d·ªØ li·ªáu con nh·∫•t ƒë·ªãnh. T·ªët h∆°n l√† h√£y hi·ªÉn th·ªã m·ªôt l∆∞·ª£ng ƒë√°ng k·ªÉ (h∆°n 100) m·∫´u ng·∫´u nhi√™n ƒë·ªÉ n·∫Øm ƒë∆∞·ª£c c√°c lo·∫°i d·ªØ li·ªáu kh√°c nhau m√† ch√∫ng ta ƒëang l√†m vi·ªác. Trong ML, ƒë·ª´ng bao gi·ªù ƒë√°nh gi√° th·∫•p s·ª©c m·∫°nh c·ªßa s·ª± ng·∫´u nhi√™n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH3EXknTI3bQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e068f05-06fd-4611-b0c9-519f4e67d8b9"
      },
      "source": [
        "# H√£y hi·ªÉn th·ªã m·ªôt s·ªë m·∫´u hu·∫•n luy·ªán ng·∫´u nhi√™n\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # t·∫°o c√°c ch·ªâ m·ª•c ng·∫´u nhi√™n kh√¥ng cao h∆°n t·ªïng s·ªë m·∫´u\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "https://t.co/eCMUjkKqX1 @ArianaGrande @ScreamQueens \n",
            "Katherine's Death\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@TinyJecht Are you another Stand-user? If you are I will have to detonate you with my Killer Queen.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "70 Years After Atomic Bombs Japan Still Struggles With War Past http://t.co/5wfXbAQMBK The anniversary of the devastation wrought by the¬â√õ_\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "My lifelong all-time favorite song is 'Landslide'.  This song has gotten me through a lot of though times &amp;... http://t.co/RfB3JXbiEJ\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "I hear the mumbling i hear the cackling i got em scared shook panicking\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FhRRewGPNS_"
      },
      "source": [
        "### Chia d·ªØ li·ªáu th√†nh c√°c t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm ƒë·ªãnh\n",
        "\n",
        "V√¨ t·∫≠p ki·ªÉm tra kh√¥ng c√≥ nh√£n v√† ch√∫ng ta c·∫ßn ƒë√°nh gi√° c√°c m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán, ch√∫ng ta s·∫Ω t√°ch m·ªôt s·ªë d·ªØ li·ªáu hu·∫•n luy·ªán v√† t·∫°o m·ªôt t·∫≠p ki·ªÉm ƒë·ªãnh.\n",
        "\n",
        "Khi m√¥ h√¨nh hu·∫•n luy·ªán (th·ª≠ c√°c patter trong c√°c m·∫´u Tweet), n√≥ s·∫Ω ch·ªâ th·∫•y d·ªØ li·ªáu t·ª´ t·∫≠p hu·∫•n luy·ªán v√† ch√∫ng ta c√≥ th·ªÉ xem n√≥ ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o tr√™n d·ªØ li·ªáu ch∆∞a bi·∫øt th·∫•y b·∫±ng c√°ch s·ª≠ d·ª•ng t·∫≠p ki·ªÉm ƒë·ªãnh.\n",
        "\n",
        "Ch√∫ng ta s·∫Ω chuy·ªÉn ƒë·ªïi c√°c ph·∫ßn t√°ch t·ª´ ki·ªÉu d·ªØ li·ªáu pandas Series th√†nh list c√°c string (cho text) v√† list c√°c int (cho nh√£n) ƒë·ªÉ d·ªÖ d√†ng s·ª≠ d·ª•ng sau n√†y.\n",
        "\n",
        "ƒê·ªÉ t√°ch t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán v√† t·∫°o t·∫≠p d·ªØ li·ªáu ki·ªÉm ƒë·ªãnh, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) c·ªßa Scikit-Learn v√† d√†nh 10% m·∫´u hu·∫•n luy·ªán cho t·∫≠p ki·ªÉm ƒë·ªãnh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OJf31TQ-X8s"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# S·ª≠ d·ª•ng train_test_split ƒë·ªÉ t√°ch d·ªØ li·ªáu hu·∫•n luy·ªán th√†nh c√°c t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm ƒë·ªãnh\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # d√†nh 10% m·∫´u cho t·∫≠p ki·ªÉm ƒë·ªãnh\n",
        "                                                                            random_state=42) # random state cho kh·∫£ nƒÉng t√°i l·∫∑p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWGOTjanBaTQ",
        "outputId": "dd1a42bc-d291-42ad-f370-6b4008b3ec45"
      },
      "source": [
        "# Ki·ªÉm tra ƒë·ªô d√†i\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqhvQK9wBTbw",
        "outputId": "31c510a5-5b33-4c3c-b093-de3982bf145b"
      },
      "source": [
        "# Xem 10 c√¢u hu·∫•n luy·ªán ƒë·∫ßu ti√™n v√† nh√£n c·ªßa ch√∫ng\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN-houoSD-hP"
      },
      "source": [
        "## Chuy·ªÉn text th√†nh s·ªë\n",
        "\n",
        "Tuy·ªát! Ch√∫ng ta c√≥ m·ªôt t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm ƒë·ªãnh ch·ª©a c√°c Tweet v√† nh√£n.\n",
        "\n",
        "C√°c nh√£n ·ªü d·∫°ng s·ªë (`0` v√† `1`) nh∆∞ng Tweet th√¨ ·ªü d·∫°ng string.\n",
        "\n",
        "> ü§î **C√¢u h·ªèi:** B·∫°n nghƒ© ch√∫ng ta c·∫ßn l√†m g√¨ tr∆∞·ªõc khi c√≥ th·ªÉ s·ª≠ d·ª•ng thu·∫≠t to√°n h·ªçc m√°y v·ªõi d·ªØ li·ªáu text?\n",
        "\n",
        "N·∫øu b·∫°n tr·∫£ l·ªùi ki·ªÉu nh∆∞ \"bi·∫øn n√≥ th√†nh s·ªë\" th√¨ b·∫°n ƒë√∫ng r·ªìi ƒë·∫•y. Thu·∫≠t to√°n h·ªçc m√°y y√™u c·∫ßu ƒë·∫ßu v√†o ph·∫£i ·ªü d·∫°ng s·ªë.\n",
        "\n",
        "C√≥ hai kh√°i ni·ªám ch√≠nh cho vi·ªác bi·∫øn text th√†nh s·ªë trong NLP:\n",
        "* **Tokenization** - √Ånh x·∫° tr·ª±c ti·∫øp t·ª´ t·ª´ ho·∫∑c k√Ω t·ª± ho·∫∑c sub-word sang m·ªôt gi√° tr·ªã s·ªë. C√≥ ba m·ª©c ƒë·ªô tokenization ch√≠nh:\n",
        "  1. S·ª≠ d·ª•ng **word-level tokenization** v·ªõi c√¢u \"I love TensorFlow\" s·∫Ω ƒë∆∞·ª£c \"I\" l√† `0`, \"love\" l√† `1` v√† \"TensorFlow\" l√† `2`. Trong tr∆∞·ªùng h·ª£p n√†y, m·ªói t·ª´ trong m·ªôt chu·ªói ƒë∆∞·ª£c coi l√† m·ªôt **token** ƒë∆°n l·∫ª.\n",
        "  2. **Character-level tokenization**, v√≠ d·ª• nh∆∞ chuy·ªÉn ƒë·ªïi c√°c ch·ªØ c√°i A-Z th√†nh c√°c gi√° tr·ªã `1-26`. Trong tr∆∞·ªùng h·ª£p n√†y, m·ªói k√Ω t·ª± trong m·ªôt chu·ªói ƒë∆∞·ª£c coi l√† m·ªôt **token** ƒë∆°n l·∫ª.\n",
        "  3. **Sub-word tokenization** ·ªü gi·ªØa word-level v√† character-level tokenization. N√≥ chia nh·ªè c√°c t·ª´ ri√™ng l·∫ª th√†nh c√°c ph·∫ßn nh·ªè h∆°n v√† sau ƒë√≥ chuy·ªÉn c√°c ph·∫ßn nh·ªè h∆°n ƒë√≥ th√†nh s·ªë. V√≠ d·ª•: \"my favourite food is pineapple pizza\" c√≥ th·ªÉ th√†nh \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". Sau khi l√†m ƒëi·ªÅu n√†y, c√°c sub-word ƒë√≥ s·∫Ω ƒë∆∞·ª£c √°nh x·∫° t·ªõi m·ªôt gi√° tr·ªã s·ªë. Trong tr∆∞·ªùng h·ª£p n√†y, m·ªói t·ª´ c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† nhi·ªÅu **tokens**.\n",
        "* **Embedding** - Embedding l√† m·ªôt ƒë·∫°i di·ªán c·ªßa ng√¥n ng·ªØ t·ª± nhi√™n c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c, ·ªü d·∫°ng **vect∆° ƒë·∫∑c tr∆∞ng**. V√≠ d·ª•: t·ª´ \"dance\" c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng vect∆° 5 chi·ªÅu `[-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]`. C·∫ßn l∆∞u √Ω ·ªü ƒë√¢y l√† k√≠ch th∆∞·ªõc c·ªßa vect∆° ƒë·∫∑c tr∆∞ng c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c. C√≥ hai c√°ch ƒë·ªÉ s·ª≠ d·ª•ng embedding:\n",
        "  1. **T·∫°o embedding ri√™ng** - Khi vƒÉn b·∫£n ƒë∆∞·ª£c chuy·ªÉn th√†nh s·ªë (b·∫Øt bu·ªôc v·ªõi embedding), ch√∫ng ta c√≥ th·ªÉ ƒë∆∞a ch√∫ng qua m·ªôt embedding layer ([`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)), ch√∫ng ta s·∫Ω h·ªçc bi·ªÉu di·ªÖn embedding trong qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh.\n",
        "  2. **S·ª≠ d·ª•ng l·∫°i embedding ƒë√£ t√¨m hi·ªÉu tr∆∞·ªõc ƒë√≥** - Nhi·ªÅu pre-trained embedding c√≥ tr√™n m·∫°ng. C√°c pre-trained embedding n√†y th∆∞·ªùng ƒë∆∞·ª£c h·ªçc tr√™n c√°c kho ng·ªØ li·ªáu text l·ªõn (ch·∫≥ng h·∫°n nh∆∞ t·∫•t c·∫£ Wikipedia) v√† do ƒë√≥ c√≥ m√¥ t·∫£ c∆° b·∫£n c·ªßa ng√¥n ng·ªØ t·ª± nhi√™n. Ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng pre-trained embedding ƒë·ªÉ kh·ªüi t·∫°o m√¥ h√¨nh v√† tinh ch·ªânh n√≥ cho ph√π h·ª£p v·ªõi t√°c v·ª• c·ª• th·ªÉ.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-tokenization-vs-embedding.png)\n",
        "*V√≠ d·ª• v·ªÅ **tokenization** (√°nh x·∫° th·∫±ng t·ª´ word t·ªõi number) v√† **embedding** (bi·ªÉu di·ªÖn phong ph√∫ h∆°n v·ªÅ m·ªëi quan h·ªá gi·ªØa c√°c token).*\n",
        "\n",
        "> ü§î **C√¢u h·ªèi:** T√¥i n√™n s·ª≠ d·ª•ng tokenzation c·∫•p ƒë·ªô n√†o? T√¥i n√™n ch·ªçn embedding n√†o?\n",
        "\n",
        "ƒêi·ªÅu n√†y c√≤n t√πy thu·ªôc v√†o b√†i to√°n. Ch√∫ng ta c√≥ th·ªÉ th·ª≠ character-level tokenization/embedding v√† word-level tokenization/embedding v√† xem c√°i n√†o th·ª±c hi·ªán t·ªët nh·∫•t. Ch√∫ng ta th·∫≠m ch√≠ c√≥ th·ªÉ mu·ªën th·ª≠ x·∫øp ch·ªìng ch√∫ng (t·ª©c l√† k·∫øt h·ª£p ƒë·∫ßu ra c·ªßa c√°c embedding layer b·∫±ng c√°ch s·ª≠ d·ª•ng [`tf.keras.layers.concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)).\n",
        "\n",
        "N·∫øu b·∫°n ƒëang t√¨m ki·∫øm pre-trained word embedding, c√≥ th·ªÉ b·∫Øt ƒë·∫ßu v·ªõi [Word2vec embeddings](http://jalammar.github.io/illustrated-word2vec/), [GloVe embeddings](https://nlp.stanford.edu/projects/glove/) v√† nhi·ªÅu t√πy ch·ªçn c√≥ s·∫µn tr√™n TensorFlow Hub.\n",
        "\n",
        "> üîë **L∆∞u √Ω:** Gi·ªëng nh∆∞ t√¨m ki·∫øm m√¥ h√¨nh th·ªã gi√°c m√°y t√≠nh ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc, ch√∫ng ta c√≥ th·ªÉ t√¨m ki·∫øm pre-trained word embedding ƒë·ªÉ s·ª≠ d·ª•ng cho b√†i to√°n c·ªßa m√¨nh. H√£y th·ª≠ t√¨m ki·∫øm \"use pre-trained word embeddings\" tr√™n TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UnRcM1PELHn"
      },
      "source": [
        "### Text vectorization (tokenization)\n",
        "\n",
        "Ch√∫ng ta ƒë√£ n√≥i kh√° nhi·ªÅu v·ªÅ tokenization v√† embedding, h√£y t·∫°o tokenization th√¥i.\n",
        "\n",
        "Tr∆∞·ªõc ti√™n, ch√∫ng ta s·∫Ω luy·ªán t·∫≠p tokenzation (√°nh x·∫° t·ª´ th√†nh s·ªë).\n",
        "\n",
        "ƒê·ªÉ tokenize t·ª´, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng preprocessing layer h·ªØu √≠ch: [`tf.keras.layers.experimental.preprocessing.TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization).\n",
        "\n",
        "`TextVectorization` layer c√≥ c√°c tham s·ªë sau:\n",
        "* `max_tokens` - S·ªë l∆∞·ª£ng t·ª´ t·ªëi ƒëa trong v·ªën t·ª´ v·ª±ng (v√≠ d·ª•: 20000 ho·∫∑c s·ªë t·ª´ duy nh·∫•t trong text), bao g·ªìm m·ªôt gi√° tr·ªã cho token OOV (out of vocabulary).\n",
        "* `standardize` - Ph∆∞∆°ng ph√°p chu·∫©n h√≥a text. M·∫∑c ƒë·ªãnh l√† `\"lower_and_strip_punctuation\"` gi·∫£m text v√† x√≥a t·∫•t c·∫£ c√°c d·∫•u c√¢u.\n",
        "* `split` - C√°ch chia nh·ªè text, m·∫∑c ƒë·ªãnh l√† `\"whitespace\"` chia c·∫£ d·∫•u c√°ch.\n",
        "* `ngrams` - C√≥ bao nhi√™u t·ª´ c·∫ßn ch·ª©a m·ªói l·∫ßn chia token, ch·∫≥ng h·∫°n: `ngrams=2` chia token th√†nh c√°c chu·ªói li√™n ti·∫øp c·ªßa 2.\n",
        "* `output_mode` -  L√†m th·∫ø n√†o ƒë·ªÉ xu·∫•t token, c√≥ th·ªÉ l√† `\"int\"` (√°nh x·∫° s·ªë nguy√™n), `\"binary\"` (m√£ h√≥a one-hot), `\"count\"` ho·∫∑c `\"tf-idf\"`. Xem th√™m t√†i li·ªáu ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.\n",
        "* `output_sequence_length` - ƒê·ªô d√†i c·ªßa chu·ªói tokenized ƒë·ªÉ xu·∫•t. V√≠ d·ª•: n·∫øu `output_sequence_length=150`, t·∫•t c·∫£ c√°c chu·ªói tokenized s·∫Ω d√†i 150 token.\n",
        "* `pad_to_max_tokens` - M·∫∑c ƒë·ªãnh l√† `False`, n·∫øu `True` th√¨ tr·ª•c ƒë·∫∑c tr∆∞ng ƒë·∫ßu ra s·∫Ω ƒë∆∞·ª£c ƒë·ªám th√†nh `max_tokens` k·ªÉ c·∫£ khi s·ªë l∆∞·ª£ng token duy nh·∫•t trong t·ª´ v·ª±ng √≠t h∆°n `max_tokens`. Ch·ªâ c√≥ hi·ªáu qu·∫£ ·ªü m·ªôt s·ªë ch·∫ø ƒë·ªô, xem t√†i li·ªáu ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.\n",
        "\n",
        "H√£y xem ch√∫ng tri·ªÉn khai th·∫ø n√†o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcZk-LcNunF"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "# L∆∞u √Ω: trong TensorFlow 2.6+, ch√∫ng ta kh√¥ng c·∫ßn \"layers.experimental.preprocessing\" n·ªØa\n",
        "# c√≥ th·ªÉ s·ª≠ d·ª•ng: \"tf.keras.layers.TextVectorization\", xem https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt\n",
        "\n",
        "# S·ª≠ d·ª•ng bi·∫øn TextVectorization m·∫∑c ƒë·ªãnh\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # c√≥ bao nhi√™u t·ª´ trong t·ª´ v·ª±ng (to√†n b·ªô c√°c t·ª´ kh√°c nhau trong text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # c√°ch x·ª≠ l√Ω text\n",
        "                                    split=\"whitespace\", # c√°ch ph√¢n chia token\n",
        "                                    ngrams=None, # c√≥ t·∫°o nh√≥m n-t·ª´ kh√¥ng?\n",
        "                                    output_mode=\"int\", # c√°ch √°nh x·∫° token th√†nh s·ªë\n",
        "                                    output_sequence_length=None) # chu·ªói ƒë·∫ßu ra c·ªßa token d√†i bao l√¢u?\n",
        "                                    # pad_to_max_tokens=True) # Kh√¥ng h·ª£p l·ªá n·∫øu s·ª≠ d·ª•ng max_tokens=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Ej5mzKGkK8"
      },
      "source": [
        "Ch√∫ng ta ƒë√£ kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng `TextVectorization` v·ªõi thi·∫øt l·∫≠p m·∫∑c ƒë·ªãnh nh∆∞ng h√£y t√πy ch·ªânh n√≥ m·ªôt ch√∫t cho tr∆∞·ªùng h·ª£p n√†y.\n",
        "\n",
        "C·ª• th·ªÉ, h√£y thi·∫øt l·∫≠p gi√° tr·ªã cho `max_tokens` v√† `output_sequence_length`.\n",
        "\n",
        "V·ªõi `max_tokens` (s·ªë t·ª´ trong t·ª´ v·ª±ng), b·ªôi s·ªë c·ªßa 10,000 (`10,000`, `20,000`, `30,000`) ho·∫∑c s·ªë t·ª´ duy nh·∫•t ch√≠nh x√°c trong text (v√≠ d·ª•: `32,179`) l√† c√°c gi√° tr·ªã th∆∞·ªùng g·∫∑p.\n",
        "\n",
        "ƒê·ªëi v·ªõi tr∆∞·ªùng h·ª£p n√†y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng 10.000.\n",
        "\n",
        "V√† v·ªõi `output_sequence_length`, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng s·ªë l∆∞·ª£ng token trung b√¨nh m·ªói Tweet trong t·∫≠p hu·∫•n luy·ªán. Nh∆∞ng tr∆∞·ªõc ti√™n, ch√∫ng ta c·∫ßn t√¨m ra n√≥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ3ZCINnR56H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093c7d74-8c3a-4fd1-8624-baa5cc95e183"
      },
      "source": [
        "# T√¨m s·ªë l∆∞·ª£ng token trung b√¨nh (t·ª´) trong c√°c Tweet hu·∫•n luy·ªán\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFGTRcw8Hv7R"
      },
      "source": [
        "B√¢y gi·ªù, h√£y t·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng `TextVectorization` kh√°c b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c tham s·ªë t√πy ch·ªânh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYPcGwdbafmW"
      },
      "source": [
        "# Thi·∫øt l·∫≠p text vectorization v·ªõi c√°c bi·∫øn t√πy ch·ªânh\n",
        "max_vocab_length = 10000 # s·ªë l∆∞·ª£ng t·ª´ t·ªëi ƒëa trong vocabulary\n",
        "max_length = 15 # ƒë·ªô d√†i t·ªëi ƒëa c·ªßa c√°c chu·ªói (v√≠ d·ª•: m√¥ h√¨nh th·∫•y bao nhi√™u word t·ª´ m·ªôt Tweet?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSWycfB3H3wV"
      },
      "source": [
        "Tuy·ªát!\n",
        "\n",
        "ƒê·ªÉ √°nh x·∫° `TextVectorization` instance `text_vectorizer` v√†o d·ªØ li·ªáu, ch√∫ng ta c√≥ th·ªÉ g·ªçi ph∆∞∆°ng th·ª©c `adapt()` tr√™n n√≥ khi chuy·ªÉn n√≥ v√†o text hu·∫•n luy·ªán."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0083KHXPO4m2"
      },
      "source": [
        "# Kh·ªõp text vectorizer v·ªõi text hu·∫•n luy·ªán\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syh0VB9wIHUq"
      },
      "source": [
        "D·ªØ li·ªáu hu·∫•n luy·ªán ƒë√£ ƒë∆∞·ª£c √°nh x·∫°! H√£y th·ª≠ `text_vectorizer` tr√™n m·ªôt c√¢u t√πy th√≠ch (m·ªôt c√¢u t∆∞∆°ng t·ª± nh∆∞ nh·ªØng g√¨ ch√∫ng ta th·∫•y trong d·ªØ li·ªáu hu·∫•n luy·ªán)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uizmdJKvO2OW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908d8b3e-0110-47ba-b7d4-ab2e402af79c"
      },
      "source": [
        "# T·∫°o c√¢u m·∫´u v√† tokenize n√≥\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0RmAeplIW57"
      },
      "source": [
        "C√≥ v·∫ª ch√∫ng ta c√≥ m·ªôt c√°ch ƒë·ªÉ bi·∫øn vƒÉn b·∫£n th√†nh s·ªë (trong tr∆∞·ªùng h·ª£p n√†y l√† word-level tokenization). Ch√∫ √Ω s·ªë 0 ·ªü cu·ªëi tensor ƒë∆∞·ª£c tr·∫£ v·ªÅ, ƒëi·ªÅu n√†y l√† do ch√∫ng ta ƒë·∫∑t `output_sequence_length=15`, t·ª©c l√† b·∫•t k·ªÉ k√≠ch th∆∞·ªõc c·ªßa chu·ªói m√† ch√∫ng ta truy·ªÅn cho `text_vectorizer` l√† bao nhi√™u, n√≥ lu√¥n tr·∫£ v·ªÅ m·ªôt chu·ªói c√≥ ƒë·ªô d√†i 15.\n",
        "\n",
        "H√£y th·ª≠ `text_vectorizer` tr√™n m·ªôt v√†i c√¢u ng·∫´u nhi√™n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZFka4BtRR6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227a570e-d987-49a1-bcf1-3f561d907d00"
      },
      "source": [
        "# Ch·ªçn m·ªôt c√¢u ng·∫´u nhi√™n t·ª´ t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán v√† tokenize n√≥\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Black Eye 9: A space battle occurred at Star O784 involving 3 fleets totaling 3942 ships with 14 destroyed      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 159,  898,  491,    3,  759,  442, 1068,   17,  874, 1629, 1129,\n",
              "         118, 1524, 1457, 6327]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PErGKRbPJF89"
      },
      "source": [
        "Tr√¥ng ·ªïn ƒë·∫•y!\n",
        "\n",
        "Cu·ªëi c√πng, ch√∫ng ta c√≥ th·ªÉ ki·ªÉm tra c√°c token duy nh·∫•t trong t·ª´ v·ª±ng b·∫±ng ph∆∞∆°ng th·ª©c `get_vocabulary()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nwNdgAZIhna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23e1a41-5b2d-4042-cfec-c6b22226a798"
      },
      "source": [
        "# L·∫•y c√°c t·ª´ duy nh·∫•t trong t·ª´ v·ª±ng\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # nh·ªØng token ph·ªï bi·∫øn nh·∫•t (ch√∫ √Ω [UNK] token l√† nh·ªØng t·ª´ \"ch∆∞a bi·∫øt\")\n",
        "bottom_5_words = words_in_vocab[-5:] # nh·ªØng token √≠t ph·ªï bi·∫øn nh·∫•t\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\")\n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHyCdO0uEOkH"
      },
      "source": [
        "### T·∫°o Embedding b·∫±ng Embedding Layer\n",
        "\n",
        "Ch√∫ng ta c√≥ c√°ch ƒë·ªÉ √°nh x·∫° vƒÉn b·∫£n th√†nh s·ªë. L√†m th·∫ø n√†o ƒë·ªÉ ti·∫øn xa h∆°n v√† bi·∫øn nh·ªØng con s·ªë ƒë√≥ th√†nh embedding?\n",
        "\n",
        "Embedding c√≥ th·ªÉ h·ªçc trong qu√° tr√¨nh hu·∫•n luy·ªán. ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† thay v√¨ ch·ªâ c·ªë ƒë·ªãnh (v√≠ d·ª•: `1` = I, `2` = love, `3` = TensorFlow), bi·ªÉu di·ªÖn s·ªë c·ªßa m·ªôt t·ª´ c√≥ th·ªÉ c·∫£i thi·ªán khi m√¥ h√¨nh ƒëi qua c√°c m·∫´u d·ªØ li·ªáu.\n",
        "\n",
        "Ch√∫ng ta c√≥ th·ªÉ th·∫•y embedding m·ªôt t·ª´ tr√¥ng nh∆∞ th·∫ø n√†o b·∫±ng c√°ch s·ª≠ d·ª•ng layer [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding).\n",
        "\n",
        "C√°c tham s·ªë ch√≠nh m√† ch√∫ng ta quan t√¢m ·ªü ƒë√¢y l√†:\n",
        "* `input_dim` - K√≠ch th∆∞·ªõc c·ªßa vocabulary (v√≠ d·ª•: `len(text_vectorizer.get_vocabulary()`).\n",
        "* `output_dim` - K√≠ch th∆∞·ªõc c·ªßa vect∆° embedding ƒë·∫ßu ra, v√≠ d·ª•: gi√° tr·ªã `100` s·∫Ω xu·∫•t ra vect∆° ƒë·∫∑c tr∆∞ng c√≥ k√≠ch th∆∞·ªõc 100 cho m·ªói t·ª´.\n",
        "* `embeddings_initializer` - C√°ch kh·ªüi t·∫°o embedding matrix, m·∫∑c ƒë·ªãnh l√† `\"uniform\"` s·∫Ω ng·∫´u nhi√™n kh·ªüi t·∫°o embedding matrix v·ªõi ph√¢n ph·ªëi ƒë·ªìng nh·∫•t. ƒêi·ªÅu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c thay ƒë·ªïi ƒë·ªÉ s·ª≠ d·ª•ng c√°c embedding ƒë√£ t√¨m hi·ªÉu tr∆∞·ªõc ƒë√≥.\n",
        "* `input_length` - ƒê·ªô d√†i c·ªßa chu·ªói ƒë∆∞·ª£c chuy·ªÉn ƒë·∫øn embedding layer.\n",
        "\n",
        "Sau khi n·∫Øm ƒë∆∞·ª£c nh·ªØng ƒëi·ªÅu n√†y, h√£y t·∫°o m·ªôt embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsB4StymSk_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffa28e2-f368-4f82-ff97-aab8b54241d3"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # thi·∫øt l·∫≠p shape ƒë·∫ßu v√†o\n",
        "                             output_dim=128, # thi·∫øt l·∫≠p k√≠ch th∆∞·ªõc c·ªßa vect∆° embedding\n",
        "                             embeddings_initializer=\"uniform\", # m·∫∑c ƒë·ªãnh, kh·ªüi t·∫°i ng·∫´u nhi√™n\n",
        "                             input_length=max_length, # m·ªói ƒë·∫ßu v√†o d√†i bao nhi√™u\n",
        "                             name=\"embedding_1\")\n",
        "\n",
        "embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f5eb57cee50>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfML_IzlSUho"
      },
      "source": [
        "H√£y ch√∫ √Ω l√†m th·∫ø n√†o ƒë·ªÉ `embedding` l√† m·ªôt layer c·ªßa TensoFlow. ƒêi·ªÅu n√†y r·∫•t quan tr·ªçng v√¨ ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng n√≥ l√†m m·ªôt ph·∫ßn c·ªßa m√¥ h√¨nh, nghƒ©a l√† c√°c tham s·ªë c·ªßa n√≥ (bi·ªÉu di·ªÖn t·ª´) c√≥ th·ªÉ c·∫≠p nh·∫≠t v√† c·∫£i thi·ªán khi m√¥ h√¨nh h·ªçc.\n",
        "\n",
        "H√£y th·ª≠ n√≥ tr√™n m·ªôt c√¢u m·∫´u."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Re6Eew6SZnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f28dec-93fb-483a-a997-a4552ef74426"
      },
      "source": [
        "# L·∫•y m·ªôt c√¢u ng·∫´u nhi√™n t·ª´ t·∫≠p hu·∫•n luy·ªán\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Nh√∫ng c√¢u ng·∫´u nhi√™n ƒë√≥ (bi·∫øn n√≥ th√†nh bi·ªÉu di·ªÖn s·ªë)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "UNR issues Severe Thunderstorm Warning [wind: 60 MPH hail: 0.75 IN] for Weston [WY] and Custer Fall River Lawrence Meade Pennington [S¬â√õ_      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.0235487 , -0.02911143, -0.01600165, ..., -0.03135703,\n",
              "         -0.03661771,  0.02812702],\n",
              "        [ 0.03848192, -0.04844777,  0.0345685 , ..., -0.01402212,\n",
              "         -0.04769395, -0.0404261 ],\n",
              "        [-0.04240407,  0.04235772,  0.04278237, ..., -0.01318695,\n",
              "          0.04171768,  0.01777187],\n",
              "        ...,\n",
              "        [-0.00522641,  0.04871375, -0.03742788, ...,  0.00540795,\n",
              "         -0.04380312, -0.01817607],\n",
              "        [ 0.03406706, -0.00160446,  0.00894339, ..., -0.0356751 ,\n",
              "          0.00541915,  0.00282475],\n",
              "        [ 0.02248487, -0.02848336,  0.04786098, ...,  0.03069806,\n",
              "         -0.04317403, -0.04145076]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Sn8o9pTBE5"
      },
      "source": [
        "M·ªói token trong c√¢u ƒë∆∞·ª£c chuy·ªÉn th√†nh m·ªôt vector ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªô d√†i 128."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_VBepuSTBDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e62e9cf-bf1c-4e21-a304-ba0b277bb220"
      },
      "source": [
        "# Ki·ªÉm tra embedding c·ªßa m·ªôt token ƒë∆°n l·∫ª\n",
        "sample_embed[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-2.3548698e-02, -2.9111434e-02, -1.6001653e-02, -2.4854636e-02,\n",
              "       -1.8839194e-02, -1.7742872e-02,  3.5991777e-02,  4.7734752e-03,\n",
              "       -3.1464353e-02, -1.0192860e-02,  3.9272513e-02,  1.6213503e-02,\n",
              "        3.5752203e-02, -7.9760700e-04, -4.6503343e-02,  4.1901264e-02,\n",
              "        2.7158771e-02, -2.9694129e-02,  6.3859299e-04, -3.6073186e-02,\n",
              "        3.7186686e-02,  8.1444494e-03, -3.4610189e-02, -1.2373447e-02,\n",
              "        3.3506799e-02,  3.4542195e-03, -3.4555770e-02,  3.0121803e-03,\n",
              "        1.2546945e-02,  1.8180419e-02, -2.8727353e-02,  3.0131452e-03,\n",
              "        2.2011306e-02,  1.5216086e-02,  8.3960593e-05, -4.9976040e-02,\n",
              "       -4.1987814e-02, -1.4751814e-02,  3.1978119e-02,  3.0810181e-02,\n",
              "        1.3748173e-02,  1.3646554e-02, -1.8768311e-03,  5.6033619e-03,\n",
              "       -3.2450367e-02, -3.2819200e-02,  6.4723380e-03,  2.4402250e-02,\n",
              "       -4.9929023e-02,  8.7605603e-03,  3.7449453e-02, -3.0369056e-02,\n",
              "        2.8607275e-02, -8.9427829e-03, -2.6780851e-03,  1.9382443e-02,\n",
              "       -4.4139970e-02, -4.8123684e-02,  3.2326613e-02,  1.0355391e-02,\n",
              "       -6.2159896e-03,  3.3066813e-02,  4.1976977e-02,  9.8001361e-03,\n",
              "        9.7909793e-03,  1.8213544e-02,  1.6274918e-02, -1.7997943e-02,\n",
              "        1.4698040e-02,  1.0068141e-02, -2.3385560e-02,  1.7339502e-02,\n",
              "        3.5935570e-02, -4.9711645e-02,  3.2845590e-02,  3.8101044e-02,\n",
              "        3.9486382e-02, -3.1647660e-02, -4.8475552e-02,  4.4873584e-02,\n",
              "        2.7549271e-02, -4.1145109e-02, -3.3895336e-02, -3.6730655e-03,\n",
              "        4.9198270e-03,  9.6562132e-03, -2.2904599e-02, -1.3657093e-02,\n",
              "        1.5388299e-02,  8.1878789e-03,  1.8028166e-02,  3.1150069e-02,\n",
              "        4.7483686e-02, -3.7815310e-02, -4.5389161e-03,  4.1796099e-02,\n",
              "        4.3265197e-02,  3.1167094e-02, -4.9614847e-02, -5.8911927e-03,\n",
              "        4.3997217e-02, -2.2734845e-02, -4.1017674e-02,  1.7939974e-02,\n",
              "        2.3607183e-02,  1.5478458e-02,  7.7072531e-04, -4.3312550e-02,\n",
              "       -4.2333078e-02, -2.2680223e-02,  3.2546792e-02, -4.9846746e-02,\n",
              "        1.3042022e-02, -3.2268692e-02, -1.8501390e-02,  5.7965517e-03,\n",
              "       -6.9886930e-03, -1.9324971e-02, -4.5883238e-02,  3.7569497e-02,\n",
              "        1.4392149e-02, -1.0649189e-03,  2.4147406e-03, -2.7852738e-02,\n",
              "       -3.7008919e-02, -3.1357028e-02, -3.6617707e-02,  2.8127018e-02],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0NTsDklR0xw"
      },
      "source": [
        "Nh·ªØng gi√° tr·ªã n√†y c√≥ th·ªÉ kh√¥ng c√≥ nhi·ªÅu √Ω nghƒ©a v·ªõi ch√∫ng ta, nh∆∞ng ƒë√≥ l√† nh·ªØng g√¨ m√°y t√≠nh th·∫•y v·ªÅ m·ªói t·ª´. Khi m√¥ h√¨nh t√¨m ki·∫øm c√°c pattern trong c√°c m·∫´u kh√°c nhau, c√°c gi√° tr·ªã n√†y s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t khi c·∫ßn thi·∫øt.\n",
        "\n",
        "> üîë **L∆∞u √Ω:** Hai kh√°i ni·ªám tr∆∞·ªõc (tokenization v√† embedding) l√† c∆° s·ªü cho nhi·ªÅu t√°c v·ª• NLP. V√¨ v·∫≠y, n·∫øu b·∫°n kh√¥ng ch·∫Øc ch·∫Øn v·ªÅ b·∫•t c·ª© ƒëi·ªÅu g√¨, h√£y nghi√™n c·ª©u v√† ti·∫øn h√†nh c√°c th·ª≠ nghi·ªám c·ªßa b·∫£n th√¢n ƒë·ªÉ hi·ªÉu th√™m."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJENUdF3F7Rn"
      },
      "source": [
        "## M√¥ h√¨nh h√≥a d·ªØ li·ªáu text\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-inputs-and-outputs-with-shapes-and-models-were-going-to-build.png)\n",
        "*Sau khi ƒë√£ chu·∫©n b·ªã ƒë·∫ßu v√†o v√† ƒë·∫ßu ra, h√£y x√¢y d·ª±ng m√¥ h√¨nh h·ªçc m√°y ƒë·ªÉ thu h·∫πp kho·∫£ng c√°ch gi·ªØa ch√∫ng.*\n",
        "\n",
        "Ch√∫ng ta ƒë√£ c√≥ m·ªôt c√°ch ƒë·ªÉ bi·∫øn d·ªØ li·ªáu vƒÉn b·∫£n th√†nh s·ªë, h√£y b·∫Øt ƒë·∫ßu x√¢y d·ª±ng c√°c m√¥ h√¨nh h·ªçc m√°y ƒë·ªÉ m√¥ h√¨nh h√≥a n√≥.\n",
        "\n",
        "ƒê·ªÉ luy·ªán t·∫≠p nhi·ªÅu, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt lo·∫°t c√°c m√¥ h√¨nh kh√°c nhau, m·ªói m√¥ h√¨nh l√† m·ªôt th·ª≠ nghi·ªám. Sau ƒë√≥, ch√∫ng ta s·∫Ω so s√°nh k·∫øt qu·∫£ c·ªßa t·ª´ng m√¥ h√¨nh v√† xem m√¥ h√¨nh n√†o ho·∫°t ƒë·ªông t·ªët nh·∫•t.\n",
        "\n",
        "C·ª• th·ªÉ, ch√∫ng ta s·∫Ω x√¢y d·ª±ng nh·ªØng m√¥ h√¨nh sau:\n",
        "* **Model 0**: Naive Bayes (m√¥ h√¨nh c∆° s·ªü)\n",
        "* **Model 1**: Feed-forward neural network (dense model)\n",
        "* **Model 2**: M√¥ h√¨nh LSTM\n",
        "* **Model 3**: M√¥ h√¨nh GRU\n",
        "* **Model 4**: M√¥ h√¨nh Bidirectional-LSTM\n",
        "* **Model 5**: 1D Convolutional Neural Network\n",
        "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
        "* **Model 7**: T∆∞∆°ng t·ª± model 6 nh∆∞ng v·ªõi 10% d·ªØ li·ªáu hu·∫•n luy·ªán\n",
        "\n",
        "Model 0 l√† m√¥ h√¨nh ƒë∆°n gi·∫£n nh·∫•t ƒë·ªÉ c√≥ ƒë∆∞·ª£c m√¥ h√¨nh c∆° s·ªü, t·ª´ ƒë√≥ k·ª≥ v·ªçng v∆∞·ª£t qua c√°c m√¥ h√¨nh s√¢u h∆°n kh√°c.\n",
        "\n",
        "M·ªói th·ª≠ nghi·ªám s·∫Ω tr·∫£i qua c√°c b∆∞·ªõc sau:\n",
        "* X√¢y d·ª±ng m√¥ h√¨nh\n",
        "* Hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "* ƒê∆∞a ra d·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
        "* Theo d√µi c√°c ph√©p ƒë√°nh gi√° d·ª± ƒëo√°n cho c√°c so s√°nh sau n√†y\n",
        "\n",
        "H√£y b·∫Øt ƒë·∫ßu th√¥i."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4i5BiQfF--y"
      },
      "source": [
        "### Model 0: M√¥ h√¨nh c∆° s·ªü\n",
        "\n",
        "Nh∆∞ t·∫•t c·∫£ c√°c th·ª≠ nghi·ªám l·∫≠p m√¥ h√¨nh h·ªçc m√°y, c·∫ßn t·∫°o m√¥ h√¨nh c∆° s·ªü ƒë·ªÉ ƒë√°nh gi√° x·∫øp h·∫°ng c√°c th·ª≠ nghi·ªám trong t∆∞∆°ng lai.\n",
        "\n",
        "ƒê·ªÉ x√¢y d·ª±ng m√¥ h√¨nh c∆° s·ªü, ch√∫ng ta s·∫Ω t·∫°o m·ªôt Scikit-Learn Pipeline b·∫±ng c√°ch s·ª≠ d·ª•ng c√¥ng th·ª©c TF-IDF ƒë·ªÉ chuy·ªÉn ƒë·ªïi t·ª´ th√†nh s·ªë r·ªìi m√¥ h√¨nh h√≥a ch√∫ng b·∫±ng [thu·∫≠t to√°n Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). ƒêi·ªÅu n√†y ƒë√£ ƒë∆∞·ª£c ch·ªçn th√¥ng qua tham chi·∫øu [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
        "\n",
        "> üìñ **T√†i li·ªáu ƒë·ªçc:** Th√¥ng tin chi ti·∫øt c·ªßa thu·∫≠t to√°n TF-IDF n·∫±m ngo√†i ph·∫°m vi c·ªßa notebook n√†y, tuy nhi√™n, nh·ªØng ƒë·ªôc gi·∫£ t√≤ m√≤ h√£y xem t√†i li·ªáu c·ªßa Scikit-Learn [t√†i li·ªáu c·ªßa Scikit-Learn](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting) ƒë·ªÉ t√¨m hi·ªÉu th√™m."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFqjqWcXtOOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cec96b9-d78a-49af-9197-86a03b8043c8"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# T·∫°o tokenization v√† l·∫≠p m√¥ h√¨nh pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # chuy·ªÉn t·ª´ th√†nh s·ªë, s·ª≠ d·ª•ng tfidf\n",
        "                    (\"clf\", MultinomialNB()) # l·∫≠p m√¥ h√¨nh vƒÉn b·∫£n\n",
        "])\n",
        "\n",
        "# Kh·ªõp pipeline v·ªõi d·ªØ li·ªáu hu·∫•n luy·ªán\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybOvOuVJbNjg"
      },
      "source": [
        "L·ª£i √≠ch c·ªßa vi·ªác s·ª≠ d·ª•ng m√¥ h√¨nh n√¥ng nh∆∞ m√¥ h√¨nh Multinomial Naive Bayes l√† vi·ªác hu·∫•n luy·ªán di·ªÖn ra r·∫•t nhanh.\n",
        "\n",
        "H√£y ƒë√°nh gi√° m√¥ h√¨nh v√† t√¨m ph√©p ƒëo m√¥ h√¨nh c∆° b·∫£n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soPfnpmQuUIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b947adf2-aaaf-4d9d-afc0-81359138cc5a"
      },
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUv5dyuibf3M"
      },
      "source": [
        "H√£y ƒë∆∞a ra m·ªôt s·ªë d·ª± ƒëo√°n v·ªõi m√¥ h√¨nh c∆° s·ªü c·ªßa ch√∫ng ta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n89JxrJufcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a3f67c-1da2-434e-fd29-73d723cd181e"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K354svk_bmdf"
      },
      "source": [
        "### T·∫°o h√†m ƒë√°nh gi√° cho c√°c th·ª≠ nghi·ªám m√¥ h√¨nh\n",
        "\n",
        "Ch√∫ng ta c√≥ th·ªÉ ƒë√°nh gi√° ngay nh·ªØng ƒëi·ªÅu n√†y, nh∆∞ng v√¨ sau n√†y ch√∫ng ta s·∫Ω ƒë√°nh gi√° m·ªôt s·ªë m√¥ h√¨nh theo c√°ch t∆∞∆°ng t·ª±, n√™n h√£y t·∫°o m·ªôt h√†m h·ªó tr·ª£ gi√∫p l·∫•y m·ªôt m·∫£ng c√°c d·ª± ƒëo√°n v√† nh√£n g·ªëc, v√† t√≠nh to√°n nh·ªØng th·ª© sau:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "\n",
        "> üîë **L∆∞u √Ω:** ƒê√¢y l√† nh·ªØng ph√©p ƒëo th√≠ch h·ª£p nh·∫•t v√¨ ch√∫ng ta ƒëang gi·∫£i b√†i to√°n ph√¢n lo·∫°i. N·∫øu ch√∫ng ta g·∫∑p b√†i to√°n h·ªìi quy, c√°c ph√©p ƒëo kh√°c nh∆∞ MAE (sai s·ªë tuy·ªát ƒë·ªëi c√≥ nghƒ©a l√†) s·∫Ω l√† th√≠ch h·ª£p h∆°n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLmNlDjIxGgJ"
      },
      "source": [
        "# H√†m ƒë·ªÉ ƒë√°nh gi√°: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T√≠nh accuracy, precision, recall v√† f1 score c·ªßa m√¥ h√¨nh ph√¢n lo·∫°i nh·ªã ph√¢n.\n",
        "\n",
        "  ƒê·ªëi s·ªë:\n",
        "  -----\n",
        "  y_true = true label ·ªü d·∫°ng m·∫£ng 1D\n",
        "  y_pred = predicted label ·ªü d·∫°ng m·∫£ng 1D\n",
        "\n",
        "  Tr·∫£ v·ªÅ m·ªôt dictionary c√≥ accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # T√≠nh model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # T√≠nh model precision, recall v√† f1 score s·ª≠ d·ª•ng \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgy1omMhwr52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1ea5fd-b76d-447a-e1f9-af4b46e8aaba"
      },
      "source": [
        "# Nh·∫≠n baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noRJNm7dGNyh"
      },
      "source": [
        "### Model 1: Dense model c∆° b·∫£n\n",
        "\n",
        "M√¥ h√¨nh \"s√¢u\" ƒë·∫ßu ti√™n m√† ch√∫ng ta s·∫Ω x√¢y d·ª±ng l√† m√¥ h√¨nh t·∫ßng k·∫øt n·ªëi d√†y ƒë·∫∑c. Tr√™n th·ª±c t·∫ø, n√≥ s·∫Ω h·∫ßu nh∆∞ kh√¥ng c√≥ layer duy nh·∫•t.\n",
        "\n",
        "M√¥ h√¨nh n√†y s·∫Ω l·∫•y vƒÉn b·∫£n v√† nh√£n l√†m ƒë·∫ßu v√†o, tokenize vƒÉn b·∫£n, t·∫°o embedding, t√¨m m·ª©c trung b√¨nh c·ªßa embedding (s·ª≠ d·ª•ng Global Average Pooling), sau ƒë√≥ chuy·ªÉn m·ª©c trung b√¨nh qua m·ªôt layer k·∫øt n·ªëi ƒë·∫ßy ƒë·ªß v·ªõi m·ªôt n√∫t ƒë·∫ßu ra v√† h√†m k√≠ch ho·∫°t sigmoid\n",
        "\n",
        "N·∫øu c√¢u tr∆∞·ªõc c√≤n kh√≥ hi·ªÉu, h√£y m√£ h√≥a n√≥ ra (h√£y nh·ªõ, n·∫øu nghi ng·ªù ƒëi·ªÅu g√¨, h√£y vi·∫øt m√£)\n",
        "\n",
        "Ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt s·ªë m√¥ h√¨nh h·ªçc s√¢u TensorFlow, h√£y import h√†m `create_tensorboard_callback()` t·ª´ `helper_functions.py` ƒë·ªÉ theo d√µi k·∫øt qu·∫£ c·ªßa t·ª´ng m√¥ h√¨nh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVMPUd3HTit5"
      },
      "source": [
        "# T·∫°o tensorboard callback (c·∫ßn t·∫°o m·ªôt tensorboard callback m·ªõi cho t·ª´ng m√¥ h√¨nh)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# T·∫°o directory ƒë·ªÉ l∆∞u TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pib8hHtu7vt1"
      },
      "source": [
        "H√†m TensorBoard callback ƒë√£ s·∫µn s√†ng, h√£y x√¢y d·ª±ng m√¥ h√¨nh s√¢u ƒë·∫ßu ti√™n c·ªßa ch√∫ng ta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_rVtJA7yVBI"
      },
      "source": [
        "# X√¢y d·ª±ng m√¥ h√¨nh v·ªõi Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # ƒë·∫ßu v√†o l√† c√°c string 1 chi·ªÅu\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers bi·∫øn text ƒë·∫ßu v√†o th√†nh s·ªë\n",
        "x = embedding(x) # t·∫°o embedding c√≥ c√°c s·ªë ƒë∆∞·ª£c ƒë√°nh s·ªë\n",
        "x = layers.GlobalAveragePooling1D()(x) # gi·∫£m k√≠ch th∆∞·ªõc c·ªßa embedding (th·ª≠ ch·∫°y m√¥ h√¨nh kh√¥ng c√≥ layer n√†y v√† xem ƒëi·ªÅu g√¨ s·∫Ω x·∫£y ra)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # t·∫°o layer ƒë·∫ßu ra, ch√∫ng ta mu·ªën ƒë·∫ßu ra nh·ªã ph√¢n, v√¨ v·∫≠y h√£y s·ª≠ d·ª•ng k√≠ch ho·∫°t sigmoid\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # x√¢y d·ª±ng m√¥ h√¨nh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYzsu36Y8JUe"
      },
      "source": [
        "Tr√¥ng ·ªïn ƒë·∫•y. M√¥ h√¨nh l·∫•y string 1 chi·ªÅu l√†m ƒë·∫ßu v√†o (trong tr∆∞·ªùng h·ª£p n√†y l√† Tweet), sau ƒë√≥ n√≥ tokenize string v·ªõi `text_vectorizer` v√† t·∫°o embedding b·∫±ng `embedding`.\n",
        "\n",
        "Sau ƒë√≥, ch√∫ng ta (t√πy ch·ªçn) g·ªôp c√°c ƒë·∫ßu ra c·ªßa embedding layer ƒë·ªÉ gi·∫£m k√≠ch th∆∞·ªõc c·ªßa tensor m√† ch√∫ng ta truy·ªÅn cho layer ƒë·∫ßu ra.\n",
        "\n",
        "> üõ† **Luy·ªán t·∫≠p:** H√£y th·ª≠ x√¢y d·ª±ng `model_1` c√≥ v√† kh√¥ng c√≥ layer `GlobalAveragePooling1D()` sau layer `embedding`. ƒêi·ªÅu g√¨ s·∫Ω x·∫£y ra? T·∫°i sao l·∫°i nh∆∞ v·∫≠y?\n",
        "\n",
        "Cu·ªëi c√πng, ch√∫ng ta chuy·ªÉn ƒë·∫ßu ra c·ªßa pooling layer th√†nh m·ªôt dense layer v·ªõi k√≠ch ho·∫°t sigmoid (ch√∫ng ta s·ª≠ d·ª•ng sigmoid v√¨ ƒë√¢y l√† b√†i to√°n ph√¢n lo·∫°i nh·ªã ph√¢n).\n",
        "\n",
        "Tr∆∞·ªõc khi kh·ªõp m√¥ h√¨nh v·ªõi d·ªØ li·ªáu, ch√∫ng ta c·∫ßn bi√™n d·ªãch n√≥. Do ch√∫ng ta ƒëang th·ª±c hi·ªán ph√¢n lo·∫°i nh·ªã ph√¢n, n√™n h√£y s·ª≠ d·ª•ng `\"binary_crossentropy\"` l√†m h√†m m·∫•t m√°t v√† Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubq0ctLD8CQq"
      },
      "source": [
        "# Bi√™n d·ªãch m√¥ h√¨nh\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crgltz1O9uku"
      },
      "source": [
        "M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c bi√™n d·ªãch. H√£y l·∫•y summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkJa-t8aTw1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c4ada2-1984-41fa-9653-dbfc6bfdfd42"
      },
      "source": [
        "# L·∫•y summary c·ªßa m√¥ h√¨nh\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH0JLyR09yYt"
      },
      "source": [
        "H·∫ßu h·∫øt c√°c tham c√≥ th·ªÉ hu·∫•n luy·ªán ƒë∆∞·ª£c ch·ª©a trong embedding layer. Nh·ªõ r·∫±ng ch√∫ng ta ƒë√£ t·∫°o m·ªôt embedding c√≥ k√≠ch th∆∞·ªõc 128 (`output_dim=128`) cho t·ª´ v·ª±ng c√≥ k√≠ch th∆∞·ªõc 10,000 (`input_dim=10000`), do ƒë√≥ c√≥ 1,280,000 tham s·ªë c√≥ th·ªÉ hu·∫•n luy·ªán.\n",
        "\n",
        "M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c bi√™n d·ªãch, h√£y kh·ªõp n√≥ v·ªõi d·ªØ li·ªáu hu·∫•n luy·ªán cho 5 epoch. Ch√∫ng ta c≈©ng s·∫Ω chuy·ªÉn h√†m TensorBoard callback ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng c√°c ph√©p ƒëo hu·∫•n luy·ªán c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c ghi l·∫°i."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRYpJIfTvHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6ad75c-338c-4e79-d6a0-a1a2bf588652"
      },
      "source": [
        "# Kh·ªõp m√¥ h√¨nh\n",
        "model_1_history = model_1.fit(train_sentences, # c√°c c√¢u ƒë·∫ßu v√†o c√≥ th·ªÉ l√† m·ªôt list c√°c string do m√¥ h√¨nh t√≠ch h·ª£p s·∫µn layer ti·ªÅn x·ª≠ l√Ω text\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20210923-052559\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 17ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZR5_j9C_LW-"
      },
      "source": [
        "V√¨ ch√∫ng ta ƒëang s·ª≠ d·ª•ng m·ªôt m√¥ h√¨nh ƒë∆°n gi·∫£n, n√™n m·ªói epoch x·ª≠ l√Ω r·∫•t nhanh.\n",
        "\n",
        "H√£y ki·ªÉm tra ch·∫•t l∆∞·ª£ng c·ªßa m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm ƒë·ªãnh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSTS87YGzuBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dab9b26-7bd0-42c8-8ad8-c55ae73d0e09"
      },
      "source": [
        "# Ki·ªÉm tra k·∫øt qu·∫£\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 7ms/step - loss: 0.4767 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4766846001148224, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M2CTAetBVfW",
        "outputId": "263af483-3739-4ff7-fa21-52b9eab7a81b"
      },
      "source": [
        "embedding.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
              " array([[ 0.00073166,  0.01504797, -0.03425457, ..., -0.04403538,\n",
              "         -0.01042282,  0.01876436],\n",
              "        [ 0.04135862, -0.03945084, -0.03811942, ...,  0.00464737,\n",
              "          0.03163553,  0.029283  ],\n",
              "        [ 0.00684031,  0.05363134, -0.00241555, ..., -0.07082176,\n",
              "         -0.04750705,  0.01448254],\n",
              "        ...,\n",
              "        [-0.03301444, -0.0052493 , -0.04209725, ...,  0.02028764,\n",
              "          0.00308807,  0.02215792],\n",
              "        [ 0.00692343,  0.05942352, -0.01975194, ..., -0.06199061,\n",
              "         -0.01018393,  0.03510419],\n",
              "        [-0.0372346 ,  0.06267187, -0.07451146, ..., -0.02367217,\n",
              "         -0.0864333 ,  0.01742156]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3rfhJFSBrga",
        "outputId": "e16f8a95-540b-40a7-98f4-8fe1a9dff5ac"
      },
      "source": [
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9dg2aba_VxK"
      },
      "source": [
        "Ch√∫ng ta ƒë√£ theo d√µi nh·∫≠t k√Ω hu·∫•n luy·ªán c·ªßa m√¥ h√¨nh b·∫±ng TensorBoard, v·∫≠y l√†m th·∫ø n√†o ƒë·ªÉ h√¨nh dung ch√∫ng?\n",
        "\n",
        "Ch√∫ng ta c√≥ th·ªÉ th·ª±c hi·ªán b·∫±ng c√°ch upload c√°c file TensorBoard log (c√≥ trong directory `model_logs`) l√™n [TensorBoard.dev](https://tensorboard.dev/).\n",
        "\n",
        "> üîë **L∆∞u √Ω:** H√£y nh·ªõ r·∫±ng, b·∫•t c·ª© th·ª© g√¨ m√† ch√∫ng ta upload l√™n TensorBoard.dev ƒë·ªÅu c√¥ng khai, cho n√™n n·∫øu b·∫°n kh√¥ng mu·ªën chia s·∫ª nh·∫≠t k√Ω hu·∫•n luy·ªán n√†o th√¨ ƒë·ª´ng upload ch√∫ng l√™n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6UrSgRVU6pl"
      },
      "source": [
        "# # Xem tensorboad logs c·ªßa c√°c th·ª≠ nghi·ªám m√¥ h√¨nh h√≥a transfer learning (n√™n l√† 4 m√¥ h√¨nh)\n",
        "# # Upload c√°c b·∫£n ghi TensorBoard dev\n",
        "# !tensorboard dev upload --logdir ./model_logs \\\n",
        "#   --name \"First deep model on text data\" \\\n",
        "#   --description \"Trying a dense model with an embedding layer\" \\\n",
        "#   --one_shot # tho√°t kh·ªèi uploader sau khi ho√†n th√†nh upload"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVyJl-VE1ACz"
      },
      "source": [
        "# N·∫øu c·∫ßn lo·∫°i b·ªè c√°c th·ª≠ nghi·ªám tr∆∞·ªõc, ch√∫ng ta c√≥ th·ªÉ d√πng l·ªánh sau\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkinGcjQ_yI9"
      },
      "source": [
        "C√≥ th·ªÉ xem th·ª≠ nghi·ªám TensorBoard.dev cho m√¥ h√¨nh s√¢u ƒë·∫ßu ti√™n c·ªßa ch√∫ng ta ·ªü ƒë√¢y: https://tensorboard.dev/experiment/5d1Xm10aT6m6MgyW3HAGfw/\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-tensorboard-dense-model-training-curves.png)\n",
        "\n",
        "*C√°c training curve c·ªßa m√¥ h√¨nh trong TensorBoard tr√¥ng nh∆∞ sau. T·ª´ hai h√¨nh n√†y, ch√∫ng ta c√≥ th·ªÉ bi·∫øt m√¥ h√¨nh ƒëang b·ªã overfitting hay underfitting kh√¥ng?*\n",
        "\n",
        "ƒê√≥ l√† m·ªôt s·ªë training curve ƒë·∫ßy m√†u s·∫Øc. C√≥ th·ªÉ k·∫øt lu·∫≠n m√¥ h√¨nh ƒëang b·ªã overfitting hay underfitting kh√¥ng?\n",
        "\n",
        "Ch√∫ng ta ƒë√£ x√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh s√¢u ƒë·∫ßu ti√™n, b∆∞·ªõc ti·∫øp theo l√† ƒë∆∞a ra m·ªôt s·ªë d·ª± ƒëo√°n v·ªõi n√≥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X7kbEmAzzxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3a68f3-5b96-4dd4-e8e0-bf351ff68c9f"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n (·ªü d·∫°ng x√°c su·∫•t)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10] # ch·ªâ in ra 10 x√°c su·∫•t d·ª± ƒëo√°n ƒë·∫ßu ti√™n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4048821 ],\n",
              "       [0.7443312 ],\n",
              "       [0.997895  ],\n",
              "       [0.10889997],\n",
              "       [0.11143532],\n",
              "       [0.93556094],\n",
              "       [0.9134595 ],\n",
              "       [0.9925345 ],\n",
              "       [0.97156817],\n",
              "       [0.26570338]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWU5e1NLAKJ9"
      },
      "source": [
        "V√¨ layer cu·ªëi c√πng s·ª≠ d·ª•ng h√†m k√≠ch ho·∫°t sigmoid, n√™n ch√∫ng ta s·∫Ω l·∫•y l·∫°i c√°c d·ª± ƒëo√°n c·ªßa m√¨nh ·ªü d·∫°ng x√°c su·∫•t.\n",
        "\n",
        "ƒê·ªÉ chuy·ªÉn ƒë·ªïi ch√∫ng th√†nh c√°c l·ªõp d·ª± ƒëo√°n, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng `tf.round()`, t·ª©c l√† x√°c su·∫•t d·ª± ƒëo√°n d∆∞·ªõi 0.5 s·∫Ω ƒë∆∞·ª£c l√†m tr√≤n th√†nh 0 v√† nh·ªØng x√°c su·∫•t tr√™n 0.5 s·∫Ω ƒë∆∞·ª£c l√†m tr√≤n th√†nh 1.\n",
        "\n",
        "> üîë **L∆∞u √Ω:** Tr√™n th·ª±c t·∫ø, ng∆∞·ª°ng ƒë·∫ßu ra c·ªßa x√°c su·∫•t d·ª± ƒëo√°n sigmoid kh√¥ng nh·∫•t thi·∫øt ph·∫£i l√† 0.5. V√≠ d·ª•: th√¥ng qua th·ª≠ nghi·ªám, ch√∫ng ta c√≥ th·ªÉ th·∫•y r·∫±ng gi·ªõi h·∫°n 0.25 s·∫Ω t·ªët h∆°n cho c√°c ph√©p ƒë√°nh gi√° ƒë√£ ch·ªçn. M·ªôt v√≠ d·ª• ph·ªï bi·∫øn c·ªßa gi·ªõi h·∫°n ng∆∞·ª°ng n√†y l√† [precision-recall tradeoff](https://www.machinelearningaptitude.com/topics/machine-learning/what-is-precision-recall-tradeoff/#:~:text=precision%2Drecall%20tradeoff%20occur%20due,the%20threshold%20of%20the%20classifier.&text=When%20threshold%20is%20decreased%20to,but%20precision%20decreases%20to%200.4.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf-R_1vsz47P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3062f826-9564-48d7-bbec-a803b41e9cba"
      },
      "source": [
        "# Bi·∫øn x√°c su·∫•t d·ª± ƒëo√°n th√†nh tensor m·ªôt chi·ªÅu c·ªßa float\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze lo·∫°i b·ªè c√°c tensor 1 chi·ªÅu\n",
        "model_1_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc3ryY0yCHcI"
      },
      "source": [
        "Ch√∫ng ta ƒë√£ c√≥ c√°c d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh ·ªü d·∫°ng class, c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m `calculate_results()` ƒë·ªÉ so s√°nh ch√∫ng v·ªõi c√°c nh√£n ki·ªÉm ƒë·ªãnh g·ªëc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDEEhYTF0X1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31e8bca-894a-44ad-88cc-fdea0dbc453a"
      },
      "source": [
        "# T√≠nh to√°n c√°c ph√©p ƒëo c·ªßa model_1\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'f1': 0.7846966492209201,\n",
              " 'precision': 0.7914920592553047,\n",
              " 'recall': 0.7874015748031497}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnkK6Uc7CYlX"
      },
      "source": [
        "H√£y so s√°nh m√¥ h√¨nh s√¢u ƒë·∫ßu ti√™n c·ªßa ch√∫ng ta v·ªõi m√¥ h√¨nh c∆° s·ªü."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp88ystW1m0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba27df1c-624b-4a24-da50-012a56653038"
      },
      "source": [
        "# M√¥ h√¨nh Keras ƒë∆°n gi·∫£n c·ªßa ch√∫ng ta c√≥ t·ªët h∆°n m√¥ h√¨nh c∆° s·ªü kh√¥ng?\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUINrCdRCpFf"
      },
      "source": [
        "Ch√∫ng ta s·∫Ω th·ª±c hi·ªán ki·ªÉu so s√°nh n√†y (m√¥ h√¨nh c∆° s·ªü v·ªõi m√¥ h√¨nh m·ªõi) kh√° nhi·ªÅu l·∫ßn, n√™n h√£y t·∫°o m·ªôt h√†m tr·ª£ gi√∫p."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo3norTG3GrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b74922-fe0a-44cb-8932-327e05402960"
      },
      "source": [
        "# T·∫°o m·ªôt h√†m h·ªó tr·ª£ ƒë·ªÉ so s√°nh k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh c∆° s·ªü v·ªõi m√¥ h√¨nh m·ªõi\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results,\n",
        "                                new_model_results=model_1_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-1LuioSLAM"
      },
      "source": [
        "## H√¨nh dung c√°c embedding ƒë√£ t√¨m hi·ªÉu\n",
        "\n",
        "M√¥ h√¨nh ƒë·∫ßu ti√™n (`model_1`) ch·ª©a m·ªôt embedding layer (`embedding`) h·ªçc ƒë∆∞·ª£c c√°ch bi·ªÉu di·ªÖn t·ª´ ·ªü d·∫°ng vect∆° ƒë·∫∑c tr∆∞ng b·∫±ng c√°ch chuy·ªÉn qua d·ªØ li·ªáu hu·∫•n luy·ªán.\n",
        "\n",
        " ƒêi·ªÅu n√†y l√∫c ƒë·∫ßu c√≤n kh√° kh√≥ hi·ªÉu.\n",
        "\n",
        "V√¨ v·∫≠y, ƒë·ªÉ t√¨m hi·ªÉu th√™m v·ªÅ text embedding, h√£y h√¨nh dung embedding m√† m√¥ h√¨nh ƒë√£ h·ªçc.\n",
        "\n",
        "ƒê·ªÉ th·ª±c hi·ªán, h√£y nh·ªõ l·∫°i c√°c t·ª´ trong vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DkcfRQBVXuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e10f4fd-50ef-4ccd-a99b-eff8a64082f8"
      },
      "source": [
        "# L·∫•y vocabulary t·ª´ layer text vectorization\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzmAPJXQEx6r"
      },
      "source": [
        "B√¢y gi·ªù, h√£y l·∫•y tr·ªçng s·ªë c·ªßa embedding layer (ƒë√¢y l√† c√°c bi·ªÉu di·ªÖn b·∫±ng s·ªë c·ªßa m·ªói t·ª´)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EUR9PwrZphh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb047f23-dbef-46ea-ce98-2ea91b309d09"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xJ5LrInWDLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc27236-56f5-4ecf-e107-37a51722194a"
      },
      "source": [
        "# L·∫•y ma tr·∫≠n tr·ªçng s·ªë c·ªßa embedding layer\n",
        "# (ƒë√¢y l√† c√°c pattern d·∫°ng s·ªë gi·ªØa text trong t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán m√† m√¥ h√¨nh ƒë√£ h·ªçc)\n",
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape) # c√πng k√≠ch th∆∞·ªõc v·ªõi vocab v√† embedding_dim (m·ªói t·ª´ l√† m·ªôt vect∆° k√≠ch th∆∞·ªõc embedding_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzOJhJHPW1ju"
      },
      "source": [
        "Ch√∫ng ta ƒë√£ c√≥ hai ƒë·ªëi t∆∞·ª£ng n√†y, c√≥ th·ªÉ s·ª≠ d·ª•ng c√¥ng c·ª• [Embedding Projector](http://projector.tensorflow.org/_) ƒë·ªÉ h√¨nh dung embedding.\n",
        "\n",
        "ƒê·ªÉ s·ª≠ d·ª•ng c√¥ng c·ª• Embedding Projector, ch√∫ng ta c·∫ßn hai file:\n",
        "* C√°c vect∆° embedding (gi·ªëng nh∆∞ c√°c tr·ªçng s·ªë embedding).\n",
        "* Si√™u d·ªØ li·ªáu c·ªßa c√°c vect∆° embedding (c√°c t·ª´ m√† ch√∫ng bi·ªÉu di·ªÖn - vocabulary).\n",
        "\n",
        "Hi·ªán gi·ªù, ch√∫ng ta c√≥ c√°c t·ªáp n√†y ·ªü d·∫°ng Python object. ƒê·ªÉ download ch√∫ng v·ªÅ file, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng [m·∫´u code c√≥ s·∫µn tr√™n trang h∆∞·ªõng d·∫´n TensorFlow word embeddings](https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e9rfcK6WxQE"
      },
      "source": [
        "# # Code d∆∞·ªõi ƒë√¢y l·∫•y t·ª´: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "# import io\n",
        "\n",
        "# # T·∫°o output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Ghi c√°c vect∆° embedding v√† t·ª´ v√†o file\n",
        "# for num, word in enumerate(words_in_vocab):\n",
        "#   if num == 0:\n",
        "#      ti·∫øp t·ª•c # b·ªè qua padding token\n",
        "#   vec = embed_weights[num]\n",
        "#   out_m.write(word + \"\\n\") # ghi c√°c t·ª´ v√†o file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # ghi vect∆° t·ª´ t∆∞∆°ng ·ª©ng v√†o file\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "# # c√°c file c·ª•c b·ªô ƒë·ªÉ upload l√™n Embedding Projector\n",
        "# th·ª≠:\n",
        "#   t·ª´ google.colab, import c√°c file\n",
        "# except ImportError:\n",
        "#   truy·ªÅn\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVM7ifzpZaxJ"
      },
      "source": [
        "Sau khi ƒë√£ download c√°c vect∆° v√† si√™u d·ªØ li·ªáu embedding, ch√∫ng ta c√≥ th·ªÉ tr·ª±c quan h√≥a ch√∫ng b·∫±ng c√¥ng c·ª• Embedding Vector:\n",
        "1. T·ªõi  http://projector.tensorflow.org/\n",
        "2. Click v√†o \"Load data\"\n",
        "3. Upload hai file m√† ch√∫ng ta v·ª´a download (`embedding_vectors.tsv` v√† `embedding_metadata.tsv`)\n",
        "4. Kh√°m ph√°\n",
        "5. T√πy ch·ªçn: C√°c b·∫°n c√≥ th·ªÉ chia s·∫ª d·ªØ li·ªáu b·∫°n v·ª´a t·∫°o b·∫±ng c√°ch click v√†o \"Publish\"\n",
        "\n",
        "C√°c b·∫°n th·∫•y ƒëi·ªÅu g√¨?\n",
        "\n",
        "C√≥ ph·∫£i c√°c t·ª´ c√≥ nghƒ©a gi·ªëng nhau th√¨ g·∫ßn nhau kh√¥ng?\n",
        "\n",
        "C√≥ th·ªÉ s·∫Ω kh√¥ng. C√°c embedding m√† ch√∫ng ta ƒë√£ download l√† c√°ch m√† m√¥ h√¨nh hi·ªÉu c√°c t·ª´, ch·ª© kh√¥ng ph·∫£i c√°ch ch√∫ng ta hi·ªÉu t·ª´.\n",
        "\n",
        "Ngo√†i ra, v√¨ embedding ho√†n to√†n ƒë∆∞·ª£c h·ªçc t·ª´ Tweet n√™n n√≥ c√≥ th·ªÉ ch·ª©a m·ªôt s·ªë gi√° tr·ªã k·ª≥ l·∫° do Tweet l√† m·ªôt ki·ªÉu ng√¥n ng·ªØ t·ª± nhi√™n r·∫•t ƒë·ªôc ƒë√°o.\n",
        "\n",
        "> ü§î **C√¢u h·ªèi:** C√≥ ph·∫£i l·∫ßn n√†o ch√∫ng ta c≈©ng c·∫ßn tr·ª±c quan h√≥a embedding kh√¥ng?\n",
        "\n",
        "Kh√¥ng. M·∫∑c d√π ƒëi·ªÅu n√†y kh√° h·ªØu √≠ch ƒë·ªÉ n·∫Øm b·∫Øt natural language embedding, nh∆∞ng kh√¥ng ho√†n to√†n c·∫ßn thi·∫øt. ƒê·∫∑c bi·ªát l√† khi k√≠ch th∆∞·ªõc vocabulary v√† embedding ng√†y c√†ng l·ªõn h∆°n, th√¨ vi·ªác c·ªë g·∫Øng hi·ªÉu ch√∫ng s·∫Ω ng√†y c√†ng kh√≥ khƒÉn h∆°n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcRdDiEtGQj4"
      },
      "source": [
        "## M·∫°ng n∆°-ron h·ªìi ti·∫øp (RNN)\n",
        "\n",
        "ƒê·ªëi v·ªõi lo·∫°t th·ª≠ nghi·ªám m√¥ h√¨nh h√≥a ti·∫øp theo, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng m·ªôt lo·∫°i m·∫°ng n∆°-ron ƒë·∫∑c bi·ªát: **M·∫°ng n∆°-ron h·ªìi ti·∫øp (RNN)**.\n",
        "\n",
        " Ti·ªÅn ƒë·ªÅ c·ªßa RNN r·∫•t ƒë∆°n gi·∫£n: s·ª≠ d·ª•ng th√¥ng tin ƒë√£ bi·∫øt ƒë·ªÉ gi√∫p d·ª± ƒëo√°n th√¥ng tin s·∫Øp t·ªõi (ƒë√¢y l√† ngu·ªìn g·ªëc c·ªßa thu·∫≠t ng·ªØ recurrent). N√≥i c√°ch kh√°c, l·∫•y m·ªôt ƒë·∫ßu v√†o (`X`) v√† t√≠nh to√°n ƒë·∫ßu ra (`y`) d·ª±a tr√™n t·∫•t c·∫£ c√°c ƒë·∫ßu v√†o tr∆∞·ªõc ƒë√≥.\n",
        "\n",
        "Kh√°i ni·ªám n√†y ƒë·∫∑c bi·ªát h·ªØu √≠ch khi x·ª≠ l√Ω c√°c chu·ªói nh∆∞ c√°c ƒëo·∫°n vƒÉn b·∫£n ng√¥n ng·ªØ t·ª± nhi√™n (ch·∫≥ng h·∫°n nh∆∞ Tweet).\n",
        "\n",
        "V√≠ d·ª•: khi ch√∫ng ta ƒë·ªçc c√¢u n√†y, ch√∫ng ta s·∫Ω ph√¢n t√≠ch ng·ªØ c·∫£nh c·ªßa c√°c t·ª´ tr∆∞·ªõc ƒë√≥ khi gi·∫£i m√£ nghƒ©a c·ªßa t·ª´ dog hi·ªán t·∫°i.\n",
        "\n",
        "ƒêi·ªÅu g√¨ ƒë√£ x·∫£y ra ·ªü ƒë√≥?\n",
        "\n",
        "T√¥i ƒë·∫∑t t·ª´ \"dog\" ·ªü cu·ªëi, l√† m·ªôt t·ª´ h·ª£p l·ªá nh∆∞ng n√≥ kh√¥ng c√≥ √Ω nghƒ©a trong ng·ªØ c·∫£nh c√≤n l·∫°i c·ªßa c√¢u.\n",
        "\n",
        "Khi RNN xem x√©t m·ªôt chu·ªói vƒÉn b·∫£n (ƒë√£ ·ªü d·∫°ng s·ªë), c√°c pattern n√≥ h·ªçc ƒë∆∞·ª£c s·∫Ω li√™n t·ª•c c·∫≠p nh·∫≠t d·ª±a tr√™n tr√¨nh t·ª± c·ªßa chu·ªói.\n",
        "\n",
        "X√©t m·ªôt v√≠ d·ª• ƒë∆°n gi·∫£n, h√£y l·∫•y hai c√¢u:\n",
        "1. Massive earthquake last week, no?\n",
        "2. No massive earthquake last week.\n",
        "\n",
        "C·∫£ hai c√¢u ƒë·ªÅu ch·ª©a nh·ªØng t·ª´ gi·ªëng h·ªát nhau nh∆∞ng l·∫°i c√≥ nghƒ©a kh√°c nhau. Th·ª© t·ª± c·ªßa c√°c t·ª´ quy·∫øt ƒë·ªãnh √Ω nghƒ©a (c√≥ ng∆∞·ªùi cho r·∫±ng c√°c d·∫•u c√¢u c≈©ng quy·∫øt ƒë·ªãnh √Ω nghƒ©a nh∆∞ng ƒë·ªÉ ƒë∆°n gi·∫£n, ch√∫ng ta h√£y t·∫≠p trung v√†o c√°c t·ª´).\n",
        "\n",
        "RNN c√≥ th·ªÉ s·ª≠ d·ª•ng cho m·ªôt s·ªë b√†i to√°n d·ª±a tr√™n chu·ªói:\n",
        "* **One to one:** m·ªôt ƒë·∫ßu v√†o, m·ªôt ƒë·∫ßu ra, ch·∫≥ng h·∫°n nh∆∞ ph√¢n lo·∫°i h√¨nh ·∫£nh.\n",
        "* **One to many:** m·ªôt ƒë·∫ßu v√†o, nhi·ªÅu ƒë·∫ßu ra, ch·∫≥ng h·∫°n nh∆∞ ch√∫ th√≠ch h√¨nh ·∫£nh (ƒë·∫ßu v√†o h√¨nh ·∫£nh, ƒë·∫ßu ra l√† m·ªôt chu·ªói vƒÉn b·∫£n l√†m ph·ª• ƒë·ªÅ).\n",
        "* **Many to one:** nhi·ªÅu ƒë·∫ßu v√†o, m·ªôt ƒë·∫ßu ra, ch·∫≥ng h·∫°n nh∆∞ ph√¢n lo·∫°i vƒÉn b·∫£n (ph√¢n lo·∫°i Tweet l√† real diaster hay not real diaster).\n",
        "* **Many to many:** nhi·ªÅu ƒë·∫ßu v√†o, nhi·ªÅu ƒë·∫ßu ra, ch·∫≥ng h·∫°n nh∆∞ d·ªãch m√°y (d·ªãch ti·∫øng Anh sang ti·∫øng T√¢y Ban Nha) ho·∫∑c l·ªùi n√≥i th√†nh vƒÉn b·∫£n (ƒë·∫ßu v√†o l√† s√≥ng √¢m thanh, ƒë·∫ßu ra l√† vƒÉn b·∫£n).\n",
        "\n",
        "Khi l√†m vi·ªác v·ªõi RNN, r·∫•t c√≥ th·ªÉ ch√∫ng ta s·∫Ω b·∫Øt g·∫∑p c√°c bi·∫øn th·ªÉ c·ªßa n√≥ nh∆∞ sau:\n",
        "* C√°c √¥ Long short-term memory (LSTM).\n",
        "* Gated recurrent unit (GRU).\n",
        "* Bidirectional RNN (truy·ªÅn xu√¥i v√† ng∆∞·ª£c d·ªçc theo m·ªôt chu·ªói, t·ª´ tr√°i sang ph·∫£i v√† t·ª´ ph·∫£i sang tr√°i).\n",
        "\n",
        "Ch√∫ng ta s·∫Ω kh√¥ng ƒëi s√¢u v√†o chi ti·∫øt c·ªßa t·ª´ng bi·∫øn th·∫ø tr√™n, ch√∫ng n·∫±m ngo√†i ph·∫°m vi c·ªßa notebook n√†y (m√† thay v√†o ƒë√≥, ch√∫ng ta s·∫Ω t·∫≠p trung v√†o vi·ªác s·ª≠ d·ª•ng ch√∫ng), ch√∫ng ta ch·ªâ c·∫ßn bi·∫øt: ch√∫ng ƒë∆∞·ª£c ch·ª©ng minh l√† r·∫•t hi·ªáu qu·∫£ trong vi·ªác l·∫≠p m√¥ h√¨nh chu·ªói.\n",
        "\n",
        "ƒê·ªÉ hi·ªÉu s√¢u h∆°n v·ªÅ code m√† ch√∫ng ta s·∫Øp vi·∫øt, c√°c b·∫°n n√™n tham kh·∫£o c√°c t√†i nguy√™n sau:\n",
        "\n",
        "> üìñ **T√†i li·ªáu:**\n",
        "> * [MIT Deep Learning Lecture on Recurrent Neural Networks](https://youtu.be/SEnXr6v2ifU) - gi·∫£i th√≠ch n·ªÅn t·∫£ng c·ªßa RNN v√† gi·ªõi thi·ªáu LSTM.\n",
        "> * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) (Andrej Karpathy) - minh h·ªça s·ª©c m·∫°nh c·ªßa RNN v·ªõi c√°c v√≠ d·ª• t·∫°o chu·ªói kh√°c nhau.\n",
        "> * [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) (Chris Olah) - g√≥c nh√¨n chuy√™n s√¢u (v√† k·ªπ thu·∫≠t) v·ªÅ c∆° ch·∫ø c·ªßa √¥ LSTM, c√≥ th·ªÉ l√† c√°c th√†nh ph·∫ßn RNN ph·ªï bi·∫øn nh·∫•t.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDERKwP_XWro"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "Sau khi ƒë√£ th·∫£o lu·∫≠n v·ªÅ RNN v√† c√°c t√°c d·ª•ng c·ªßa RNN, ch·∫Øc h·∫≥n c√°c b·∫°n ƒëang h√°o h·ª©c x√¢y d·ª±ng m·ªôt m√¥ h√¨nh nh∆∞ v·∫≠y.\n",
        "\n",
        "Ch√∫ng ta s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi LSTM-powered RNN.\n",
        "\n",
        "ƒê·ªÉ khai th√°c kh·∫£ nƒÉng c·ªßa √¥ LSTM (√¥ LSTM v√† layer LSTM th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng thay th·∫ø cho nhau) trong TensorFlow, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng [`tensorflow.keras.layers.LSTM()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM).\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-RNN-architecture-coloured-block-edition.png)\n",
        "*V√≠ d·ª• v·ªÅ kh·ªëi m√†u c·∫•u tr√∫c c·ªßa RNN.*\n",
        "\n",
        "M√¥ h√¨nh c·ªßa ch√∫ng ta s·∫Ω c√≥ c·∫•u tr√∫c r·∫•t gi·ªëng v·ªõi `model_1`:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "Kh√°c bi·ªát ch√≠nh l√† ch√∫ng ta s·∫Ω th√™m m·ªôt layer LSTM gi·ªØa embedding v√† ƒë·∫ßu ra.\n",
        "\n",
        "V√† ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng ch√∫ng ta kh√¥ng s·ª≠ d·ª•ng l·∫°i c√°c embedding ƒë√£ hu·∫•n luy·ªán (ƒëi·ªÅu n√†y li√™n quan ƒë·∫øn vi·ªác r√≤ r·ªâ d·ªØ li·ªáu gi·ªØa c√°c m√¥ h√¨nh, d·∫´n ƒë·∫øn so s√°nh kh√¥ng ƒë·ªìng ƒë·ªÅu sau n√†y), ch√∫ng ta s·∫Ω t·∫°o m·ªôt embedding layer kh√°c (`model_2_embedding`) cho m√¥ h√¨nh. Layer `text_vectorizer` c√≥ th·ªÉ s·ª≠ d·ª•ng l·∫°i v√¨ n√≥ kh√¥ng ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong qu√° tr√¨nh hu·∫•n luy·ªán.\n",
        "\n",
        "> üîë **L∆∞u √Ω:** L√Ω do ch√∫ng ta s·ª≠ d·ª•ng m·ªôt embedding layer m·ªõi cho m·ªói m√¥ h√¨nh l√† v√¨ embedding layer l√† m·ªôt bi·ªÉu di·ªÖn *ƒë√£ h·ªçc* c·ªßa c√°c t·ª´ (d∆∞·ªõi d·∫°ng s·ªë), n·∫øu ch√∫ng ta s·ª≠ d·ª•ng c√πng m·ªôt embedding layer (`embedding_1`) cho m·ªói m√¥ h√¨nh, ch√∫ng ta s·∫Ω k·∫øt h·ª£p nh·ªØng g√¨ m·ªôt m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c v·ªõi m√¥ h√¨nh ti·∫øp theo. V√† b·ªüi v√¨ sau ƒë√≥ ch√∫ng ta c√≤n mu·ªën so s√°nh c√°c m√¥ h√¨nh, n√™n h√£y b·∫Øt ƒë·∫ßu m·ªói l·∫ßn v·ªõi embedding layer c·ªßa ri√™ng ch√∫ng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi3vjpFU46hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373cad05-9cf7-4c40-b41b-622f51563819"
      },
      "source": [
        "# Thi·∫øt l·∫≠p random seed v√† t·∫°o embedding layer (embedding layer m·ªõi cho t·ª´ng m√¥ h√¨nh)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# T·∫°o m√¥ h√¨nh LSTM\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # tr·∫£ v·ªÅ vect∆° cho t·ª´ng t·ª´ trong Tweet (ch√∫ng ta c√≥ th·ªÉ x·∫øp ch·ªìng c√°c √¥ RNN mi·ªÖn l√† return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # tr·∫£ v·ªÅ vect∆° cho to√†n b·ªô chu·ªói\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # dense layer t√πy ch·ªçn tr√™n ƒë·∫ßu ra c·ªßa √¥ LSTM\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1wfTARuwWDg"
      },
      "source": [
        "> üîë **L∆∞u √Ω:** Trong t√†i li·ªáu v·ªÅ [TensorFlow LSTM layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM), ch√∫ng ta s·∫Ω t√¨m th·∫•y r·∫•t nhi·ªÅu tham s·ªë. Nhi·ªÅu tham s·ªë trong ƒë√≥ ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ ƒë·∫£m b·∫£o ch√∫ng t√≠nh to√°n nhanh nh·∫•t c√≥ th·ªÉ. Ch√∫ng ta s·∫Ω t√¨m c√°ch ƒëi·ªÅu ch·ªânh c√°c tham s·ªë: `units` (s·ªë l∆∞·ª£ng n√∫t ·∫©n) v√† `return_sequences` (ƒë·∫∑t gi√° tr·ªã n√†y th√†nh `True` khi x·∫øp ch·ªìng LSTM ho·∫∑c c√°c recurrent layer kh√°c).\n",
        "\n",
        "Ch√∫ng ta ƒë√£ x√¢y d·ª±ng m√¥ h√¨nh LSTM, h√£y bi√™n d·ªãch n√≥ b·∫±ng c√°ch s·ª≠ d·ª•ng `\"binary_crossentropy\"` loss v√† Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWdt3bFRwG6w"
      },
      "source": [
        "# Bi√™n d·ªãch m√¥ h√¨nh\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2e_t8RFxgXG"
      },
      "source": [
        "Tr∆∞·ªõc khi ch√∫ng ta kh·ªõp m√¥ h√¨nh v·ªõi d·ªØ li·ªáu, h√£y l·∫•y summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAjdfDfLwK_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f345c914-32a3-437a-89c9-07ae4989ec62"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5NLw3wD0aMz"
      },
      "source": [
        "Tr√¥ng ƒë∆∞·ª£c ƒë·∫•y! B·∫°n s·∫Ω nh·∫≠n th·∫•y m·ªôt v√†i tham s·ªë c√≥ th·ªÉ hu·∫•n luy·ªán ƒë∆∞·ª£c trong LSTM layer h∆°n l√† `model_1`.\n",
        "\n",
        "N·∫øu b·∫°n mu·ªën bi·∫øt con s·ªë n√†y ƒë·∫øn t·ª´ ƒë√¢u, h√£y xem qua c√°c t√†i li·ªáu ·ªü tr√™n c≈©ng nh∆∞ t√†i li·ªáu sau v·ªÅ c√°ch t√≠nh s·ªë l∆∞·ª£ng tham s·ªë trong m·ªôt √¥ LSTM:\n",
        "* [C√¢u tr·∫£ l·ªùi c·ªßa Stack Overflow: t√≠nh to√°n s·ªë l∆∞·ª£ng tham s·ªë trong m·ªôt √¥ LSTM](https://stackoverflow.com/questions/38080035/how-to-calculate-the-number-of-parameters-of-an-lstm-network) (Marcin Mo≈ºejko)\n",
        "* [T√≠nh to√°n s·ªë l∆∞·ª£ng tham s·ªë trong m·ªôt layer v√† n√∫t LSTM](https://medium.com/@priyadarshi.cse/calculating-number-of-parameters-in-a-lstm-unit-layer-7e491978e1e4) (Shridhar Priyadarshi)  \n",
        "\n",
        "M√¥ h√¨nh RNN ƒë·∫ßu ti√™n c·ªßa ch√∫ng ta ƒë√£ ƒë∆∞·ª£c bi√™n d·ªãch, h√£y kh·ªõp v·ªõi d·ªØ li·ªáu hu·∫•n luy·ªán, x√°c th·ª±c n√≥ tr√™n d·ªØ li·ªáu ki·ªÉm ƒë·ªãnh v√† theo d√µi c√°c tham s·ªë hu·∫•n luy·ªán c·ªßa n√≥ b·∫±ng TensorBoard callback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgZ7ojDvwKcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34da9032-cfe3-46b2-8cab-80d6abc3a593"
      },
      "source": [
        "# Kh·ªõp m√¥ h√¨nh\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"LSTM\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20210923-052618\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 34ms/step - loss: 0.5100 - accuracy: 0.7416 - val_loss: 0.4566 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.3176 - accuracy: 0.8717 - val_loss: 0.5138 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.5858 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.6041 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8746 - val_accuracy: 0.7507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gikGe_Z16PP"
      },
      "source": [
        "M√¥ h√¨nh RNN ƒë·∫ßu ti√™n c·ªßa ch√∫ng ta ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c √¥ LSTM. H√£y ƒë∆∞a ra m·ªôt v√†i d·ª± ƒëo√°n v·ªõi n√≥.\n",
        "\n",
        "T∆∞∆°ng t·ª± nh∆∞ tr∆∞·ªõc, h√†m k√≠ch ho·∫°t sigmoid ·ªü layer cu·ªëi c√πng s·∫Ω tr·∫£ v·ªÅ x√°c su·∫•t d·ª± ƒëo√°n thay v√¨ c√°c l·ªõp khi ch√∫ng ta g·ªçi ph∆∞∆°ng th·ª©c `predict()` trong m√¥ h√¨nh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c_lVbKLemrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08161e1d-fb72-4046-8ba1-1937487eebc4"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n tr√™n t·∫≠p d·ªØ li·ªáu ki·ªÉm ƒë·ªãnh\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[0.00712602],\n",
              "        [0.7873681 ],\n",
              "        [0.9996376 ],\n",
              "        [0.05679193],\n",
              "        [0.0025822 ],\n",
              "        [0.9996238 ],\n",
              "        [0.9217023 ],\n",
              "        [0.9997993 ],\n",
              "        [0.9994954 ],\n",
              "        [0.6645735 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ6ope-ddpOo"
      },
      "source": [
        "Ch√∫ng ta c√≥ th·ªÉ chuy·ªÉn ƒë·ªïi nh·ªØng x√°c su·∫•t d·ª± ƒëo√°n n√†y th√†nh c√°c l·ªõp d·ª± ƒëo√°n b·∫±ng c√°ch l√†m tr√≤n ƒë·∫øn s·ªë nguy√™n g·∫ßn nh·∫•t (theo m·∫∑c ƒë·ªãnh, c√°c x√°c su·∫•t d·ª± ƒëo√°n d∆∞·ªõi 0.5 s·∫Ω th√†nh 0, c√≤n nh·ªØng x√°c su·∫•t tr√™n 0.5 s·∫Ω th√†nh 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFnIhtyE7hlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284865b4-bfd5-470d-b3da-c3bef6f7ea92"
      },
      "source": [
        "# L√†m tr√≤n c√°c d·ª± ƒëo√°n v√† gi·∫£m th√†nh m·∫£ng 1 chi·ªÅu\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTBy4poXd_7p"
      },
      "source": [
        "Tuy·ªát, b√¢y gi·ªù h√£y d√πng h√†m `caculate_results()` ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh LSTM v√† h√†m `compare_baseline_to_new_results()` ƒë·ªÉ so s√°nh n√≥ v·ªõi m√¥ h√¨nh c∆° s·ªü."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iHXv04y76vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9265fa0c-a725-4333-f91f-4d96fa5a5c06"
      },
      "source": [
        "# T√≠nh c√°c k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh LSTM\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.06561679790026,\n",
              " 'f1': 0.7489268622514025,\n",
              " 'precision': 0.7510077975908164,\n",
              " 'recall': 0.7506561679790026}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdQGn2L68B5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686d82ce-8eb5-40d3-9db2-85ffc4fa6484"
      },
      "source": [
        "# So s√°nh model_2 v·ªõi baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.07, Difference: -4.20\n",
            "Baseline precision: 0.81, New precision: 0.75, Difference: -0.06\n",
            "Baseline recall: 0.79, New recall: 0.75, Difference: -0.04\n",
            "Baseline f1: 0.79, New f1: 0.75, Difference: -0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0pAtADt8ju7"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "M·ªôt th√†nh ph·∫ßn ph·ªï bi·∫øn v√† hi·ªáu qu·∫£ kh√°c c·ªßa RNN l√† GRU hay n√∫t h·ªìi ti·∫øp c√≥ c·ªïng.\n",
        "\n",
        "√î GRU c√≥ c√°c ƒë·∫∑c tr∆∞ng t∆∞∆°ng t·ª± nh∆∞ √¥ LSTM, nh∆∞ng √≠t tham s·ªë h∆°n.\n",
        "\n",
        "> üìñ **T√†i li·ªáu:** A full explanation of the GRU cell is beyond the scope of this noteook but I'd suggest the following resources to learn more: Gi·∫£i th√≠ch ƒë·∫ßy ƒë·ªß v·ªÅ √¥ GRU n·∫±m ngo√†i ph·∫°m vi c·ªßa noteook n√†y, nh∆∞ng c√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m c√°c t√†i li·ªáu sau:\n",
        "* [Gated Recurrent Unit](https://en.wikipedia.org/wiki/Gated_recurrent_unit) t·ª´ Wikipedia\n",
        "* [Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be) (Simeon Kostadinov)\n",
        "\n",
        "ƒê·ªÉ s·ª≠ d·ª•ng √¥ GRU trong TensorFlow, ch√∫ng ta s·∫Ω g·ªçi l·ªõp [`tensorflow.keras.layers.GRU()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU).\n",
        "\n",
        "Ki·∫øn tr√∫c c·ªßa m√¥ h√¨nh do GRU cung c·∫•p tu√¢n theo c√πng m·ªôt c·∫•u tr√∫c m√† ch√∫ng ta ƒë√£ d√πng:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "Kh√°c bi·ªát duy nh·∫•t s·∫Ω l√† (c√°c) layer m√† ch√∫ng ta s·ª≠ d·ª•ng gi·ªØa embedding v√† output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoSCGq3H47Yo"
      },
      "source": [
        "# Thi·∫øt l·∫≠p random seed v√† t·∫°o embedding layer (embedding layer m·ªõi cho t·ª´ng m√¥ h√¨nh)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# X√¢y d·ª±ng m√¥ h√¨nh RNN b·∫±ng c√°ch s·ª≠ d·ª•ng √¥ GRU\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # x·∫øp ch·ªìng c√°c √¥ h·ªìi ti·∫øp c·∫ßn return_sequences=True\n",
        "x = layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # dense layer t√πy ch·ªçn sau √¥ GRU\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLT5maFWhKH1"
      },
      "source": [
        "TensorFlow gi√∫p ch√∫ng ta d·ªÖ d√†ng s·ª≠ d·ª•ng c√°c th√†nh ph·∫ßn m·∫°nh m·∫Ω nh∆∞ √¥ GRU trong c√°c m√¥ h√¨nh c·ªßa m√¨nh. B√¢y gi·ªù, m√¥ h√¨nh th·ª© ba ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng, h√£y bi√™n d·ªãch n√≥, gi·ªëng nh∆∞ tr∆∞·ªõc ƒë√¢y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBL1mb31hHDS"
      },
      "source": [
        "# Bi√™n d·ªãch m√¥ h√¨nh GRU\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvnksvkmha2A"
      },
      "source": [
        "Summary c·ªßa m√¥ h√¨nh tr√¥ng nh∆∞ th·∫ø n√†o?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVnB5yQeiAWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068184f9-c913-46fd-83d9-8547e8f4f1f6"
      },
      "source": [
        "# L·∫•y summary c·ªßa m√¥ h√¨nh GRU\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcXzKqgXhdez"
      },
      "source": [
        "L∆∞u √Ω t·ªõi s·ª± kh√°c bi·ªát v·ªÅ s·ªë l∆∞·ª£ng tham s·ªë c√≥ th·ªÉ hu·∫•n luy·ªán gi·ªØa `model_2` (LSTM) v√† `model_3` (GRU). Kh√°c bi·ªát n√†y l√† do √¥ LSTM c√≥ nhi·ªÅu tham s·ªë c√≥ th·ªÉ hu·∫•n luy·ªán h∆°n so v·ªõi √¥ GRU.\n",
        "\n",
        "Ch√∫ng ta s·∫Ω kh·ªõp m√¥ h√¨nh nh∆∞ ƒë√£ l√†m tr∆∞·ªõc ƒë√¢y v√† theo d√µi k·∫øt qu·∫£ m√¥ h√¨nh b·∫±ng h√†m `create_tensorboard_callback()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvamg5JOh_jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629279a6-1dd9-43fb-f0ae-975be030ebe7"
      },
      "source": [
        "# Kh·ªõp m√¥ h√¨nh\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20210923-052650\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 24ms/step - loss: 0.5242 - accuracy: 0.7314 - val_loss: 0.4553 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3195 - accuracy: 0.8694 - val_loss: 0.4937 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.2197 - accuracy: 0.9181 - val_loss: 0.5607 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1599 - accuracy: 0.9441 - val_loss: 0.6220 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1221 - accuracy: 0.9584 - val_loss: 0.6205 - val_accuracy: 0.7677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM4mQj1Sh7Gn"
      },
      "source": [
        "Do thi·∫øt l·∫≠p m·∫∑c ƒë·ªãnh ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a c·ªßa √¥ GRU trong TensorFlow n√™n vi·ªác hu·∫•n luy·ªán kh√¥ng h·ªÅ m·∫•t nhi·ªÅu th·ªùi gian.\n",
        "\n",
        "ƒê√£ ƒë·∫øn l√∫c ƒë∆∞a ra m·ªôt s·ªë d·ª± ƒëo√°n v·ªÅ c√°c m·∫´u ki·ªÉm ƒë·ªãnh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5TUVHCl9pe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21116150-7412-49c4-ae12-679f3c688c44"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n tr√™n d·ªØ li·ªáu ki·ªÉm ƒë·ªãnh\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[0.33325258],\n",
              "        [0.87741184],\n",
              "        [0.9980252 ],\n",
              "        [0.11561754],\n",
              "        [0.01235959],\n",
              "        [0.9925639 ],\n",
              "        [0.6214262 ],\n",
              "        [0.99813336],\n",
              "        [0.9982377 ],\n",
              "        [0.50181067]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hasS7dzRiYQh"
      },
      "source": [
        "M·ªôt l·∫ßn n·ªØa, ch√∫ng ta nh·∫≠n ƒë∆∞·ª£c m·ªôt m·∫£ng c√°c x√°c su·∫•t d·ª± ƒëo√°n c√≥ th·ªÉ chuy·ªÉn ƒë·ªïi th√†nh c√°c l·ªõp d·ª± ƒëo√°n b·∫±ng c√°ch l√†m tr√≤n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haILbddg98CY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d567022-4f1f-46cb-aae1-70242ce55e56"
      },
      "source": [
        "# Chuy·ªÉn x√°c su·∫•t d·ª± ƒëo√°n th√†nh l·ªõp d·ª± ƒëo√°n\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7yAgh-viglB"
      },
      "source": [
        "Ch√∫ng ta ƒë√£ c√≥ c√°c l·ªõp d·ª± ƒëo√°n, h√£y ƒë√°nh gi√° ch√∫ng d·ª±a tr√™n nh√£n g·ªëc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9OZbQu1-LPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b32ee9f-3291-4f8c-873d-c7780488cab8"
      },
      "source": [
        "# T√≠nh k·∫øt qu·∫£ c·ªßa model_3\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'f1': 0.7667932666650168,\n",
              " 'precision': 0.7675450859410361,\n",
              " 'recall': 0.7677165354330708}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9t7wcALiuRk"
      },
      "source": [
        "Cu·ªëi c√πng, ch√∫ng ta c√≥ th·ªÉ so s√°nh k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh GRU v·ªõi m√¥ h√¨nh c∆° s·ªü."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7AE6vtn-RQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8ad89a-089a-4b29-be3f-b0c6f87c19ad"
      },
      "source": [
        "# So s√°nh v·ªõi m√¥ h√¨nh c∆° s·ªü\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLm6r4nQ-Wdr"
      },
      "source": [
        "### Model 4: M√¥ h√¨nh RNN hai chi·ªÅu\n",
        "\n",
        "Ch√∫ng ta ƒë√£ x√¢y d·ª±ng hai RNN v·ªõi √¥ GRU v√† LSTM. B√¢y gi·ªù, ch√∫ng ta s·∫Ω xem x√©t m·ªôt lo·∫°i RNN kh√°c: RNN hai chi·ªÅu.\n",
        "\n",
        "RNN ti√™u chu·∫©n s·∫Ω x·ª≠ l√Ω chu·ªói t·ª´ tr√°i sang ph·∫£i, trong khi RNN hai chi·ªÅu s·∫Ω x·ª≠ l√Ω chu·ªói t·ª´ tr√°i sang ph·∫£i r·ªìi l·∫°i t·ª´ ph·∫£i sang tr√°i.\n",
        "\n",
        "C√≥ th·ªÉ h√¨nh dung nh∆∞ vi·ªác b·∫°n ƒëang ƒë·ªçc m·ªôt c√¢u: l·∫ßn ƒë·∫ßu ti√™n ƒë·ªçc theo c√°ch th√¥ng th∆∞·ªùng (t·ª´ tr√°i sang ph·∫£i) nh∆∞ng v√¨ l√Ω do n√†o ƒë√≥ n√≥ kh√¥ng r√µ n√™n b·∫°n l∆∞·ªõt qua c√°c t·ª´ v√† quay l·∫°i ƒë·ªçc m·ªôt l·∫ßn n·ªØa (ph·∫£i sang tr√°i).\n",
        "\n",
        "Trong th·ª±c t·∫ø, nhi·ªÅu m√¥ h√¨nh chu·ªói th∆∞·ªùng th·∫•y v√† c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng khi s·ª≠ d·ª•ng RNN hai chi·ªÅu.\n",
        "\n",
        "Tuy nhi√™n, vi·ªác c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng n√†y th∆∞·ªùng k√©o theo th·ªùi gian hu·∫•n luy·ªán d√†i h∆°n v√† gia tƒÉng c√°c tham s·ªë c·ªßa m√¥ h√¨nh (v√¨ m√¥ h√¨nh ƒëi t·ª´ tr√°i sang ph·∫£i v√† t·ª´ ph·∫£i sang tr√°i n√™n s·ªë l∆∞·ª£ng tham s·ªë c√≥ th·ªÉ hu·∫•n luy·ªán tƒÉng s·∫Ω g·∫•p ƒë√¥i).\n",
        "\n",
        "H√£y x√¢y d·ª±ng m√¥ h√¨nh RNN hai chi·ªÅu.\n",
        "\n",
        "TensorFlow cung c·∫•p cho ch√∫ng ta l·ªõp [`tensorflow.keras.layers.Bidirectional`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional). Ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng l·ªõp `Bidirectional` ƒë·ªÉ b·ªçc c√°c RNN hi·ªán c√≥, ngay l·∫≠p t·ª©c l√†m cho ch√∫ng c√≥ hai chi·ªÅu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAU9dvGm47_2"
      },
      "source": [
        "# Thi·∫øt l·∫≠p random seed v√† t·∫°o embedding layer (embedding layer m·ªõi cho t·ª´ng m√¥ h√¨nh)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# X√¢y d·ª±ng RNN hai chi·ªÅu trong TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # x·∫øp ch·ªìng c√°c layer c·ªßa RNN c·∫ßn return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional ƒëi theo c·∫£ hai h∆∞·ªõng, do ƒë√≥ c√≥ s·ªë l∆∞·ª£ng tham s·ªë g·∫•p ƒë√¥i m·ªôt LSTM layer th√¥ng th∆∞·ªùng\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hm5cwmNm-g4"
      },
      "source": [
        "> üîë **L∆∞u √Ω:** Ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng `Bidirectional` wrapper tr√™n b·∫•t k·ª≥ √¥ RNN n√†o trong TensorFlow. V√≠ d·ª•: `layers.Bidirectional(layers.GRU(64))` t·∫°o ra m·ªôt √¥ GRU hai chi·ªÅu.\n",
        "\n",
        "M√¥ h√¨nh hai chi·ªÅu ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng, h√£y bi√™n d·ªãch n√≥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP1jeF0am9x0"
      },
      "source": [
        "# Bi√™n d·ªãch\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtpYyjsbnEwN"
      },
      "source": [
        "T·∫•t nhi√™n c≈©ng h√£y ki·ªÉm tra summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sUd9AQ6nFXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1d6295-7753-41b9-df0d-4f4986cb3cbf"
      },
      "source": [
        "# L·∫•y summary c·ªßa m√¥ h√¨nh hai chi·ªÅu\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvItfzeZnIE-"
      },
      "source": [
        "L∆∞u √Ω: s·ªë l∆∞·ª£ng tham s·ªë c√≥ th·ªÉ hu·∫•n luy·ªán tƒÉng l√™n trong `model_4` (LSTM hai chi·ªÅu) so v·ªõi `model_2` (LSTM th√¥ng th∆∞·ªùng), do t√≠nh hai chi·ªÅu m√† ch√∫ng ta ƒë√£ th√™m v√†o RNN.\n",
        "\n",
        "ƒê√£ ƒë·∫øn l√∫c kh·ªõp m√¥ h√¨nh hai chi·ªÅu v√† theo d√µi ch·∫•t l∆∞·ª£ng c·ªßa n√≥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAKY_QbHXPHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e576aae-b7a6-4bc5-b229-99e0885d9bd2"
      },
      "source": [
        "# Kh·ªõp m√¥ h√¨nh (l√¢u h∆°n do c√°c layer hai chi·ªÅu)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20210923-052719\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 21ms/step - loss: 0.5093 - accuracy: 0.7481 - val_loss: 0.4606 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3135 - accuracy: 0.8708 - val_loss: 0.5144 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.5626 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1523 - accuracy: 0.9469 - val_loss: 0.6365 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.6509 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkt8GVRHoJz6"
      },
      "source": [
        "Do t√≠nh hai chi·ªÅu c·ªßa m√¥ h√¨nh, ch√∫ng ta th·∫•y th·ªùi gian hu·∫•n luy·ªán tƒÉng nh·∫π.\n",
        "\n",
        "ƒê·ª´ng lo l·∫Øng, n√≥ kh√¥ng tƒÉng qu√° nhi·ªÅu.\n",
        "\n",
        "H√£y ƒë∆∞a ra m·ªôt s·ªë d·ª± ƒëo√°n v·ªõi m√¥ h√¨nh n√†y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFc7QHRtXmn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a915b9-2e27-492e-86a7-6b114354cfcf"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n v·ªõi m√¥ h√¨nh RNN hai chi·ªÅu tr√™n d·ªØ li·ªáu ki·ªÉm ƒë·ªãnh\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04000043],\n",
              "       [0.827929  ],\n",
              "       [0.99842227],\n",
              "       [0.1353109 ],\n",
              "       [0.00311337],\n",
              "       [0.99220747],\n",
              "       [0.9552836 ],\n",
              "       [0.99945647],\n",
              "       [0.99898285],\n",
              "       [0.28141677]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_9HmNIYobDB"
      },
      "source": [
        "Chuy·ªÉn ƒë·ªïi ch√∫ng th√†nh c√°c l·ªõp d·ª± ƒëo√°n v√† ƒë√°nh gi√° ch√∫ng cƒÉn c·ª© v√†o nh√£n g·ªëc v√† m√¥ h√¨nh c∆° s·ªü."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5z8bMdaXw51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbb2c9e-5b45-4872-a126-6f6b4de3f091"
      },
      "source": [
        "# Chuy·ªÉn ƒë·ªïi x√°c su·∫•t d·ª± ƒëo√°n th√†nh c√°c nh√£n\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a7Ym_vKYAO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d841a2-6cdd-4da2-d623-d046f608841c"
      },
      "source": [
        "# T√≠nh k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh RNN hai chi·ªÅu\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'f1': 0.7651213533864446,\n",
              " 'precision': 0.7665895370389821,\n",
              " 'recall': 0.7664041994750657}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAET-LKpYT18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69437c7-e780-41ab-d575-b9cfdefdf82b"
      },
      "source": [
        "# Ki·ªÉm tra xem m√¥ h√¨nh hai chi·ªÅu ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o so v·ªõi m√¥ h√¨nh c∆° s·ªü\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.64, Difference: -2.62\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcvt_7emuKlR"
      },
      "source": [
        "## M·∫°ng n∆°-ron t√≠ch ch·∫≠p (CNN) cho Text\n",
        "\n",
        "Tr∆∞·ªõc ƒë√¢y, ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng m·∫°ng n∆°-ron t√≠ch ch·∫≠p (CNN) cho h√¨nh ·∫£nh, tuy nhi√™n ch√∫ng c≈©ng c√≥ th·ªÉ d√πng cho chu·ªói.\n",
        "\n",
        "Kh√°c bi·ªát ch√≠nh gi·ªØa vi·ªác s·ª≠ d·ª•ng CNN cho h√¨nh ·∫£nh v√† cho chu·ªói l√† shape c·ªßa d·ªØ li·ªáu. H√¨nh ·∫£nh c√≥ 2 chi·ªÅu (chi·ªÅu cao x chi·ªÅu r·ªông) trong khi c√°c chu·ªói th∆∞·ªùng ch·ªâ c√≥ 1 chi·ªÅu (m·ªôt chu·ªói vƒÉn b·∫£n).\n",
        "\n",
        "V√¨ v·∫≠y, ƒë·ªÉ s·ª≠ d·ª•ng CNN v·ªõi chu·ªói, ch√∫ng ta s·ª≠ d·ª•ng t√≠ch ch·∫≠p 1 chi·ªÅu thay v√¨ t√≠ch ch·∫≠p 2 chi·ªÅu.\n",
        "\n",
        "Ki·∫øn ‚Äã‚Äãtr√∫c CNN ƒëi·ªÉn h√¨nh cho chu·ªói nh∆∞ sau:\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)\n",
        "```\n",
        "\n",
        "C√≥ th·ªÉ b·∫°n ƒëang nghƒ© \"tr√¥ng gi·ªëng nh∆∞ s∆° ƒë·ªì ki·∫øn ‚Äã‚Äãtr√∫c m√† ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng cho c√°c m√¥ h√¨nh kh√°c ...\"\n",
        "\n",
        "ƒê√∫ng r·ªìi ƒë√≥.\n",
        "\n",
        "Kh√°c bi·ªát l√† ·ªü th√†nh ph·∫ßn layers. Thay v√¨ s·ª≠ d·ª•ng √¥ LSTM ho·∫∑c GRU, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng layer [`tensorflow.keras.layers.Conv1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D), sau ƒë√≥ l√† layer [`tensorflow.keras.layers.GlobablMaxPool1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D).\n",
        "\n",
        "> üìñ **T√†i li·ªáu:** T·ªïng quan ·ªü ƒë√¢y ƒë∆∞·ª£c gi·∫£i th√≠ch m·ªôt c√°ch c√¥ ƒë·ªçng trong t√†i li·ªáu [*Understanding Convolutional Neural Networks for Text Classification*](https://www.aclweb.org/anthology/W18-5408.pdf), trong ƒë√≥ c√≥ ƒë·ªÅ c·∫≠p r·∫±ng CNN ph√¢n lo·∫°i text qua c√°c b∆∞·ªõc sau:\n",
        "1. B·ªô l·ªçc xoay v√≤ng 1 chi·ªÅu ƒë∆∞·ª£c s·ª≠ d·ª•ng l√†m b·ªô ph√°t hi·ªán ngram, m·ªói b·ªô l·ªçc chuy√™n v·ªÅ m·ªôt h·ªç ngram c√≥ li√™n quan ch·∫∑t ch·∫Ω (ngram l√† t·∫≠p h·ª£p c√≥ n t·ª´, v√≠ d·ª•: ngram 5 c√≥ th·ªÉ l√† \"hello, my name is Daniel\").\n",
        "2. Max-pooling theo th·ªùi gian tr√≠ch xu·∫•t c√°c ngam li√™n quan ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh.\n",
        "3. Ph·∫ßn c√≤n l·∫°i c·ªßa m·∫°ng ph√¢n lo·∫°i text d·ª±a tr√™n th√¥ng tin n√†y.\n",
        "\n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgXEorf9GWY1"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "Tr∆∞·ªõc khi x√¢y d·ª±ng m√¥ h√¨nh CNN 1 chi·ªÅu ƒë·∫ßy ƒë·ªß, h√£y xem layer t√≠ch ch·∫≠p 1 chi·ªÅu (c√≤n g·ªçi l√† **t√≠ch ch·∫≠p th·ªùi gian**) ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o.\n",
        "\n",
        "Tr∆∞·ªõc ti√™n, ch√∫ng ta s·∫Ω t·∫°o embedding c·ªßa m·ªôt m·∫´u vƒÉn b·∫£n v√† th·ª≠ nghi·ªám chuy·ªÉn n√≥ qua layer `Conv1D()` v√† layer `GlobalMaxPool1D()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "563hl7nPWP_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a7e900-e4b4-4b1b-9b4e-617ca9f7eb92"
      },
      "source": [
        "# Ki·ªÉm tra embedding, 1D convolutional v√† max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # bi·∫øn c√¢u m·ª•c ti√™u th√†nh embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve chu·ªói m·ª•c ti√™u 5 t·ª´ c√πng m·ªôt l√∫c\n",
        "conv_1d_output = conv_1d(embedding_test) # truy·ªÅn embedding qua layer t√≠ch ch·∫≠p m·ªôt chi·ªÅu\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # l·∫•y c√°c ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WzTeShEemJ2"
      },
      "source": [
        "L∆∞u √Ω shape ƒë·∫ßu ra c·ªßa m·ªói layer.\n",
        "\n",
        "Embedding c√≥ k√≠ch th∆∞·ªõc shape ƒë·∫ßu ra c·ªßa c√°c tham s·ªë ƒë∆∞·ª£c ƒë·∫∑t th√†nh (`input_length=15` and `output_dim=128`).\n",
        "\n",
        "Layer t√≠ch ch·∫≠p 1 chi·ªÅu c√≥ ƒë·∫ßu ra ƒë∆∞·ª£c n√©n tr·ª±c ti·∫øp v·ªõi c√°c tham s·ªë c·ªßa n√≥. T∆∞∆°ng t·ª± v·ªõi ƒë·∫ßu ra c·ªßa max pooling layer.\n",
        "\n",
        "Text b·∫Øt ƒë·∫ßu ·ªü d·∫°ng string nh∆∞ng ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi th√†nh m·ªôt vect∆° ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªô d√†i 64 th√¥ng qua c√°c b∆∞·ªõc bi·∫øn ƒë·ªïi kh√°c nhau (t·ª´ tokenization ƒë·∫øn embedding ƒë·∫øn t√≠ch ch·∫≠p 1 chi·ªÅu ƒë·∫øn max pool).\n",
        "\n",
        "H√£y t√¨m hi·ªÉu xem m·ªói ph√©p bi·∫øn ƒë·ªïi n√†y tr√¥ng nh∆∞ th·∫ø n√†o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRcxYgs-dxM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33616ed5-7333-4891-d3fa-d798c64fd789"
      },
      "source": [
        "# Xem ƒë·∫ßu ra c·ªßa t·ª´ng layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[ 0.02534914, -0.03109061,  0.00285616, ..., -0.00783159,\n",
              "          -0.02685575, -0.0443413 ],\n",
              "         [-0.0658626 ,  0.09451495, -0.01477603, ..., -0.00657781,\n",
              "          -0.04238792,  0.07777896],\n",
              "         [-0.04803652, -0.00709756, -0.02330894, ..., -0.0180733 ,\n",
              "           0.02351036,  0.02676384],\n",
              "         ...,\n",
              "         [ 0.00073166,  0.01504797, -0.03425457, ..., -0.04403538,\n",
              "          -0.01042282,  0.01876436],\n",
              "         [ 0.00073166,  0.01504797, -0.03425457, ..., -0.04403538,\n",
              "          -0.01042282,  0.01876436],\n",
              "         [ 0.00073166,  0.01504797, -0.03425457, ..., -0.04403538,\n",
              "          -0.01042282,  0.01876436]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[0.08324985, 0.00648716, 0.        , 0.03983572, 0.        ,\n",
              "          0.01144416, 0.00416251, 0.0228839 , 0.        , 0.00900978,\n",
              "          0.        , 0.        , 0.03401771, 0.06408274, 0.08103722,\n",
              "          0.00409014, 0.01579616, 0.        , 0.07930177, 0.        ,\n",
              "          0.        , 0.        , 0.14525084, 0.        , 0.        ,\n",
              "          0.        , 0.03682078, 0.06534287, 0.        , 0.        ,\n",
              "          0.05094624, 0.        ],\n",
              "         [0.        , 0.05387188, 0.        , 0.11491331, 0.        ,\n",
              "          0.        , 0.1623708 , 0.        , 0.        , 0.00171254,\n",
              "          0.14336711, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.01197936, 0.        , 0.        , 0.13551372, 0.0040106 ,\n",
              "          0.10309819, 0.09445544, 0.08390297, 0.        , 0.04213036,\n",
              "          0.04487597, 0.06560461, 0.        , 0.02272684, 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.03683221, 0.04895764, 0.        , 0.1532475 , 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.04650313, 0.00496456, 0.07349401, 0.01608641,\n",
              "          0.        , 0.02779119, 0.        , 0.0808056 , 0.01403176,\n",
              "          0.        , 0.03768815, 0.1038278 , 0.        , 0.03361662,\n",
              "          0.        , 0.02577607, 0.00140354, 0.        , 0.        ,\n",
              "          0.03211498, 0.        ],\n",
              "         [0.0088782 , 0.10450974, 0.        , 0.06974535, 0.02328686,\n",
              "          0.        , 0.04052207, 0.        , 0.        , 0.02733764,\n",
              "          0.08674346, 0.        , 0.        , 0.06129852, 0.02007267,\n",
              "          0.        , 0.        , 0.        , 0.03364263, 0.        ,\n",
              "          0.04525332, 0.05219702, 0.06375706, 0.        , 0.        ,\n",
              "          0.00774407, 0.00273467, 0.        , 0.        , 0.00499633,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.02369069, 0.        , 0.05827617, 0.05297644,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.01719718, 0.02936822, 0.00466103, 0.06879887, 0.01944808,\n",
              "          0.01585533, 0.01294545, 0.        , 0.06866529, 0.        ,\n",
              "          0.00623766, 0.0351405 , 0.02407533, 0.        , 0.05979815,\n",
              "          0.        , 0.01170142, 0.        , 0.        , 0.        ,\n",
              "          0.04444929, 0.        ],\n",
              "         [0.03544863, 0.        , 0.        , 0.05054973, 0.06105441,\n",
              "          0.        , 0.00997427, 0.01403005, 0.        , 0.01680727,\n",
              "          0.0314851 , 0.03889389, 0.        , 0.07710679, 0.0059097 ,\n",
              "          0.        , 0.00263033, 0.        , 0.08935824, 0.        ,\n",
              "          0.        , 0.05331149, 0.0522795 , 0.        , 0.06658384,\n",
              "          0.01881707, 0.02448696, 0.        , 0.        , 0.        ,\n",
              "          0.02008456, 0.        ],\n",
              "         [0.03544863, 0.        , 0.        , 0.05054973, 0.06105442,\n",
              "          0.        , 0.00997426, 0.01403006, 0.        , 0.01680727,\n",
              "          0.03148509, 0.03889391, 0.        , 0.07710679, 0.0059097 ,\n",
              "          0.        , 0.00263035, 0.        , 0.08935823, 0.        ,\n",
              "          0.        , 0.05331149, 0.05227951, 0.        , 0.06658384,\n",
              "          0.01881707, 0.02448694, 0.        , 0.        , 0.        ,\n",
              "          0.02008457, 0.        ],\n",
              "         [0.03544864, 0.        , 0.        , 0.05054973, 0.06105441,\n",
              "          0.        , 0.00997426, 0.01403005, 0.        , 0.01680726,\n",
              "          0.0314851 , 0.03889389, 0.        , 0.07710679, 0.0059097 ,\n",
              "          0.        , 0.00263034, 0.        , 0.08935826, 0.        ,\n",
              "          0.        , 0.0533115 , 0.0522795 , 0.        , 0.06658384,\n",
              "          0.01881707, 0.02448694, 0.        , 0.        , 0.        ,\n",
              "          0.02008457, 0.        ],\n",
              "         [0.03544863, 0.        , 0.        , 0.05054973, 0.06105442,\n",
              "          0.        , 0.00997426, 0.01403005, 0.        , 0.01680727,\n",
              "          0.0314851 , 0.0388939 , 0.        , 0.07710679, 0.0059097 ,\n",
              "          0.        , 0.00263034, 0.        , 0.08935825, 0.        ,\n",
              "          0.        , 0.05331149, 0.05227951, 0.        , 0.06658386,\n",
              "          0.01881707, 0.02448695, 0.        , 0.        , 0.        ,\n",
              "          0.02008456, 0.        ],\n",
              "         [0.03544863, 0.        , 0.        , 0.05054973, 0.0610544 ,\n",
              "          0.        , 0.00997427, 0.01403005, 0.        , 0.01680727,\n",
              "          0.0314851 , 0.0388939 , 0.        , 0.0771068 , 0.0059097 ,\n",
              "          0.        , 0.00263034, 0.        , 0.08935825, 0.        ,\n",
              "          0.        , 0.05331149, 0.05227951, 0.        , 0.06658386,\n",
              "          0.01881707, 0.02448695, 0.        , 0.        , 0.        ,\n",
              "          0.02008456, 0.        ],\n",
              "         [0.03544863, 0.        , 0.        , 0.05054973, 0.06105442,\n",
              "          0.        , 0.00997426, 0.01403006, 0.        , 0.01680726,\n",
              "          0.03148509, 0.0388939 , 0.        , 0.0771068 , 0.0059097 ,\n",
              "          0.        , 0.00263034, 0.        , 0.08935824, 0.        ,\n",
              "          0.        , 0.05331149, 0.05227952, 0.        , 0.06658386,\n",
              "          0.01881706, 0.02448695, 0.        , 0.        , 0.        ,\n",
              "          0.02008456, 0.        ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.08324985, 0.10450974, 0.        , 0.1532475 , 0.06105442,\n",
              "         0.01144416, 0.1623708 , 0.0228839 , 0.        , 0.02733764,\n",
              "         0.14336711, 0.04650313, 0.03401771, 0.0771068 , 0.08103722,\n",
              "         0.01585533, 0.02779119, 0.        , 0.13551372, 0.01403176,\n",
              "         0.10309819, 0.09445544, 0.14525084, 0.        , 0.06658386,\n",
              "         0.04487597, 0.06560461, 0.06534287, 0.02272684, 0.00499633,\n",
              "         0.05094624, 0.        ]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMcrthJwg3B2"
      },
      "source": [
        "Ch√∫ng ta ƒë√£ th·∫•y ƒë·∫ßu ra c·ªßa m·ªôt s·ªë th√†nh ph·∫ßn c·ªßa CNN cho chu·ªói, h√£y t·∫≠p h·ª£p ch√∫ng l·∫°i v·ªõi nhau v√† x√¢y d·ª±ng m·ªôt m√¥ h√¨nh ƒë·∫ßy ƒë·ªß, bi√™n d·ªãch n√≥ (nh∆∞ ch√∫ng ta ƒë√£ th·ª±c hi·ªán v·ªõi c√°c m√¥ h√¨nh kh√°c) v√† nh·∫≠n summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9aphPWCYkWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d723bc4-84d1-49eb-9ef9-0887364f029b"
      },
      "source": [
        "# Thi·∫øt l·∫≠p random seed v√† t·∫°o embedding layer (embedding layer m·ªõi cho t·ª´ng m√¥ h√¨nh)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "\n",
        "# T·∫°o layer t√≠ch ch·∫≠p 1 chi·ªÅu ƒë·ªÉ l·∫≠p m√¥ h√¨nh chu·ªói\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Bi√™n d·ªãch m√¥ h√¨nh Conv1D\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Nh·∫≠n summary c·ªßa m√¥ h√¨nh Conv1D\n",
        "model_5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 32)            20512     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Y4BpMGh0jG"
      },
      "source": [
        "Tuy·ªát! L∆∞u √Ω r·∫±ng s·ªë l∆∞·ª£ng tham s·ªë c√≥ th·ªÉ hu·∫•n luy·ªán cho layer t√≠ch ch·∫≠p 1 chi·ªÅu t∆∞∆°ng t·ª± nh∆∞ c·ªßa LSTM layer trong `model_2`.\n",
        "\n",
        "H√£y kh·ªõp m√¥ h√¨nh CNN 1D v·ªõi d·ªØ li·ªáu text. V·ªõi c√°c th·ª≠ nghi·ªám tr∆∞·ªõc ƒë√≥, ch√∫ng ta s·∫Ω l∆∞u k·∫øt qu·∫£ b·∫±ng c√°ch h√†m `create_tensorboard_callback()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fzlaKm1ZrMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544b3d97-2d9c-40a3-b0e5-51feac67a4fa"
      },
      "source": [
        "# Kh·ªõp m√¥ h√¨nh\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210923-052810\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 10ms/step - loss: 0.5652 - accuracy: 0.7141 - val_loss: 0.4733 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.3380 - accuracy: 0.8615 - val_loss: 0.4758 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2070 - accuracy: 0.9234 - val_loss: 0.5457 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.1314 - accuracy: 0.9578 - val_loss: 0.6163 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0933 - accuracy: 0.9691 - val_loss: 0.6779 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2up-1tLiXKD"
      },
      "source": [
        "Nh·ªù kh·∫£ nƒÉng tƒÉng t·ªëc GPU, m√¥ h√¨nh Conv1D ho·∫°t ƒë·ªông kh√° t·ªët v√† nhanh. H√£y ƒë∆∞a ra m·ªôt s·ªë d·ª± ƒëo√°n v·ªõi n√≥ v√† ƒë√°nh gi√° ch√∫ng nh∆∞ ch√∫ng ta ƒë√£ th·ª±c hi·ªán tr∆∞·ªõc ƒë√≥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHYw5GkxZ2OK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a902e9-9710-4854-d61d-649b7a6f5ef3"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n v·ªõi model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.225345  ],\n",
              "       [0.7534112 ],\n",
              "       [0.9995602 ],\n",
              "       [0.05562792],\n",
              "       [0.01449848],\n",
              "       [0.9858518 ],\n",
              "       [0.98418933],\n",
              "       [0.99758804],\n",
              "       [0.99862623],\n",
              "       [0.26914373]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9YqTtjiaauS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb1e353-5ecc-4cdb-cd73-07911d7857c2"
      },
      "source": [
        "# Chuy·ªÉn x√°c su·∫•t d·ª± ƒëo√°n c·ªßa model_5 th√†nh c√°c nh√£n\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMY3s1Pnaj34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45f024e-6352-4583-8946-bf3da8249a21"
      },
      "source": [
        "# T√≠nh to√°n c√°c ph√©p ƒë√°nh g√°i c·ªßa model_5\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'f1': 0.7758810170952618,\n",
              " 'precision': 0.7807522349051432,\n",
              " 'recall': 0.7782152230971129}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRfF4B6_at8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de35775-b434-4465-e63c-0066a7fa3f69"
      },
      "source": [
        "# So s√°nh k·∫øt qu·∫£ c·ªßa model_5 v·ªõi baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.82, Difference: -1.44\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_roVSSRt-7h"
      },
      "source": [
        "## S·ª≠ d·ª•ng c√°c Embedding ti·ªÅn hu·∫•n luy·ªán (transfer learning cho NLP)\n",
        "\n",
        "ƒê·ªëi v·ªõi t·∫•t c·∫£ c√°c m√¥ h√¨nh h·ªçc s√¢u m√† ch√∫ng ta ƒë√£ x√¢y d·ª±ng v√† hu·∫•n luy·ªán tr∆∞·ªõc ƒë√¢y, m·ªói l·∫ßn ch√∫ng ta ƒë·ªÅu t·∫°o v√† s·ª≠ d·ª•ng embedding t·ª´ ƒë·∫ßu.\n",
        "\n",
        "Tuy nhi√™n, th·ª±c t·∫ø ch√∫ng ta s·∫Ω t·∫≠n d·ª•ng embedding ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc th√¥ng qua **transfer learning**. ƒê√¢y l√† m·ªôt trong nh·ªØng l·ª£i √≠ch ch√≠nh c·ªßa vi·ªác s·ª≠ d·ª•ng m√¥ h√¨nh s√¢u: c√≥ th·ªÉ l·∫•y nh·ªØng g√¨ m·ªôt m√¥ h√¨nh (th∆∞·ªùng l·ªõn h∆°n) ƒë√£ h·ªçc ƒë∆∞·ª£c (th∆∞·ªùng tr√™n nhi·ªÅu d·ªØ li·ªáu) v√† ƒëi·ªÅu ch·ªânh cho tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng c·ªßa ch√∫ng ta.\n",
        "\n",
        "V·ªõi m√¥ h√¨nh ti·∫øp theo, thay v√¨ s·ª≠ d·ª•ng embedding layer c·ªßa ch√∫ng ta, h√£y s·ª≠ d·ª•ng m·ªôt embedding layer ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc.\n",
        "\n",
        "C·ª• th·ªÉ h∆°n, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng [Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) t·ª´ [TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4) (m·ªôt ngu·ªìn d·ªØ li·ªáu tuy·ªát v·ªùi ch·ª©a r·∫•t nhi·ªÅu t√†i li·ªáu m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc cho nhi·ªÅu t√°c v·ª• kh√°c nhau).\n",
        "\n",
        "> üîë **L∆∞u √Ω:** C√≥ nhi·ªÅu t√πy ch·ªçn text embedding ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc kh√°c nhau tr√™n TensorFlow Hub, tuy nhi√™n, m·ªôt s·ªë t√πy ch·ªçn y√™u c√°c c·∫•p ƒë·ªô ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n kh√°c v·ªõi c√°c t√πy ch·ªçn c√≤n l·∫°i. T·ªët nh·∫•t h√£y th·ª≠ nghi·ªám v·ªõi m·ªôt s·ªë t√πy ch·ªçn v√† xem c√°i n√†o ph√π h·ª£p nh·∫•t v·ªõi tr∆∞·ªùng h·ª£p c·ªßa b·∫°n.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-NQ2MA5GZBo"
      },
      "source": [
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Kh√°c bi·ªát ch√≠nh gi·ªØa embedding layer m√† ch√∫ng ta ƒë√£ t·∫°o v√† Universal Sentence Encoder l√† thay v√¨ t·∫°o word-level embedding, Universal Sentence Encoder t·∫°o ra sentence-level embedding.\n",
        "\n",
        "Embedding layer c·ªßa ch√∫ng ta c≈©ng xu·∫•t ra m·ªôt vect∆° 128 chi·ªÅu cho m·ªói t·ª´, trong khi ƒë√≥ Universal Sentence Encoder xu·∫•t ra m·ªôt vect∆° 512 chi·ªÅu cho m·ªói c√¢u.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-USE-tensorflow-hub-encoder-decoder-model.png)\n",
        "*M√¥ h√¨nh feature extractor m√† ch√∫ng ta ƒëang x√¢y d·ª±ng th√¥ng qua m√¥ h√¨nh **encoder/decoder**.*\n",
        "\n",
        "> üîë **L∆∞u √Ω:** **Encoder** l√† t√™n g·ªçi c·ªßa m·ªôt m√¥ h√¨nh chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√¥ nh∆∞ text th√†nh bi·ªÉu di·ªÖn s·ªë (vect∆° ƒë·∫∑c tr∆∞ng), **decoder** chuy·ªÉn ƒë·ªïi bi·ªÉu di·ªÖn s·ªë th√†nh ƒë·∫ßu ra mong mu·ªën.\n",
        "\n",
        "Nh∆∞ th∆∞·ªùng l·ªá, h√£y minh h·ªça ƒëi·ªÅu n√†y b·∫±ng m·ªôt v√≠ d·ª•.\n",
        "\n",
        "Ch√∫ng ta c√≥ th·ªÉ load m√¥-ƒëun TensorFlow Hub b·∫±ng ph∆∞∆°ng th·ª©c [`hub.load()`](https://www.tensorflow.org/hub/api_docs/python/hub/load) v√† chuy·ªÉn cho n√≥ URL ƒë√≠ch c·ªßa m√¥-ƒëun m√† ch√∫ng ta mu·ªën s·ª≠ d·ª•ng, trong tr∆∞·ªùng h·ª£p n√†y l√† \"https://tfhub.dev/google/universal-sentence-encoder/4\".\n",
        "\n",
        "H√£y load m√¥ h√¨nh Universal Sentence Encoder v√† ki·ªÉm tra n√≥ v·ªõi m·ªôt v√†i c√¢u."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7piW5jtxbUkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc509df1-e7a6-4145-82ca-674785ac5257"
      },
      "source": [
        "# V√≠ d·ª• v·ªÅ embedding ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc v·ªõi universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157024  0.0248591   0.0287805  -0.01271502  0.03971543  0.08827759\n",
            "  0.02680986  0.05589837 -0.01068731 -0.0059729   0.00639324 -0.01819523\n",
            "  0.00030817  0.09105891  0.05874644 -0.03180627  0.01512476 -0.05162928\n",
            "  0.00991369 -0.06865346 -0.04209306  0.0267898   0.03011008  0.00321069\n",
            " -0.00337969 -0.04787359  0.02266718 -0.00985924 -0.04063614 -0.01292095\n",
            " -0.04666384  0.056303   -0.03949255  0.00517685  0.02495828 -0.07014439\n",
            "  0.02871508  0.04947682 -0.00633971 -0.08960191  0.02807117 -0.00808362\n",
            " -0.01360601  0.05998649 -0.10361786 -0.05195372  0.00232955 -0.02332528\n",
            " -0.03758105  0.0332773 ], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvArnKkGb4vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d73b29-193e-4e95-bd8d-e071b551ec3b"
      },
      "source": [
        "# M·ªói c√¢u ƒë∆∞·ª£c m√£ h√≥a th√†nh m·ªôt vect∆° 512 chi·ªÅu\n",
        "embed_samples[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxYFDkGD-XjF"
      },
      "source": [
        "Chuy·ªÉn c√°c c√¢u c·ªßa ch√∫ng ta t·ªõi Universal Sentence Encoder (USE), m√£ h√≥a ch√∫ng t·ª´ string th√†nh vect∆° 512 chi·ªÅu, ƒëi·ªÅu n√†y kh√¥ng c√≥ √Ω nghƒ©a g√¨ ƒë·ªëi v·ªõi ch√∫ng ta nh∆∞ng hy v·ªçng c√≥ √Ω nghƒ©a v·ªõi c√°c m√¥ h√¨nh h·ªçc m√°y.\n",
        "\n",
        "H√£y x√¢y d·ª±ng m·ªôt m√¥ h√¨nh v·ªõi embedding layer l√† USE.\n",
        "\n",
        "Ch√∫ng ta c√≥ th·ªÉ chuy·ªÉn ƒë·ªïi m√¥-ƒëun TensorFlow Hub USE th√†nh m·ªôt Keras layer b·∫±ng l·ªõp [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) .\n",
        "\n",
        "> üîë **L∆∞u √Ω:** Do k√≠ch th∆∞·ªõc c·ªßa m√¥-ƒëun USE TensorFlow Hub, n√™n vi·ªác download s·∫Ω c√≥ th·ªÉ t·ªën m·ªôt ch√∫t th·ªùi gian. Sau khi ƒë√£ download, n√≥ s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o b·ªô nh·ªõ ƒë·ªám v√† s·∫µn s√†ng s·ª≠ d·ª•ng. C≈©ng nh∆∞ v·ªõi nhi·ªÅu m√¥-ƒëun TensorFlow Hub kh√°c, c√≥ [phi√™n b·∫£n USE \"lite\"](https://tfhub.dev/google/universal-sentence-encoder-lite/2) chi·∫øm √≠t dung l∆∞·ª£ng h∆°n nh∆∞ng c·∫ßn hi·ªáu su·∫•t v√† y√™u c·∫ßu nhi·ªÅu b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω h∆°n. Tuy nhi√™n, t√πy thu·ªôc v√†o c√¥ng su·∫•t m√°y t√≠nh hi·ªán c√≥, phi√™n b·∫£n lite c√≥ th·ªÉ t·ªët h∆°n cho tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng ·ª©ng d·ª•ng c·ªßa b·∫°n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcbBj0aXqrs9"
      },
      "source": [
        "# Ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng layer m√£ h√≥a n√†y thay cho text_vectorizer v√† embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape c·ªßa ƒë·∫ßu v√†o ƒëi v√†o m√¥ h√¨nh\n",
        "                                        dtype=tf.string, # ki·ªÉu d·ªØ li·ªáu c·ªßa ƒë·∫ßu v√†o ƒëi v√†o USE layer\n",
        "                                        trainable=False, # gi·ªØ c√°c tr·ªçng s·ªë hu·∫•n luy·ªán tr∆∞·ªõc (ch√∫ng ta s·∫Ω t·∫°o feature extractor)\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvjQl4p7BO_A"
      },
      "source": [
        "Tuy·ªát! B√¢y gi·ªù USE ƒë√£ l√† Keras layer, ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng n√≥ trong m·ªôt m√¥ h√¨nh Keras Sequential."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_pjIvPuYltA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141cb32c-b1a7-46e8-8b95-12c7ec4d589e"
      },
      "source": [
        "# T·∫°o m√¥ h√¨nh s·ª≠ d·ª•ng Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # nh·∫≠p c√°c c√¢u r·ªìi m√£ h√≥a ch√∫ng th√†nh embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Bi√™n d·ªãch m√¥ h√¨nh\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yukgxOgCCR2Z"
      },
      "source": [
        "Ch√∫ √Ω s·ªë l∆∞·ª£ng tham s·ªë trong USE layer, ƒë√¢y l√† nh·ªØng tr·ªçng s·ªë ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc m√† n√≥ h·ªçc ƒë∆∞·ª£c t·ª´ c√°c ngu·ªìn vƒÉn b·∫£n kh√°c nhau (Wikipedia, tin t·ª©c tr√™n web, di·ªÖn ƒë√†n Q&A tr√™n m·∫°ng,... Xem [t√†i li·ªáu Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) ƒë·ªÉ t√¨m hi·ªÉu th√™m).\n",
        "\n",
        "C√°c tham s·ªë c√≥ th·ªÉ hu·∫•n luy·ªán ch·ªâ n·∫±m ·ªü c√°c layer ƒë·∫ßu ra, n√≥i c√°ch kh√°c, ch√∫ng ta ƒëang duy tr√¨ ƒë√≥ng bƒÉng c√°c tr·ªçng s·ªë c·ªßa USE v√† s·ª≠ d·ª•ng n√≥ l√†m feature-extractor. Ch√∫ng ta c√≥ th·ªÉ tinh ch·ªânh c√°c tr·ªçng s·ªë n√†y b·∫±ng c√°ch ƒë·∫∑t `trainable=True` khi t·∫°o instance `hub.KerasLayer`.\n",
        "\n",
        "M·ªôt m√¥ h√¨nh feature extractor ƒë√£ s·∫µn s√†ng, h√£y hu·∫•n luy·ªán n√≥ v√† theo d√µi k·∫øt qu·∫£ v√†o TensorBoard b·∫±ng c√°ch s·ª≠ d·ª•ng h√†m `create_tensorboard_callback()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX9S0YvafybG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c3c8d1-b3cf-4c87-dd75-2ed786b5e5d5"
      },
      "source": [
        "# Hu·∫•n luy·ªán b·ªô ph√¢n lo·∫°i tr√™n c√°c embedding ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210923-052854\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 32ms/step - loss: 0.5008 - accuracy: 0.7892 - val_loss: 0.4478 - val_accuracy: 0.7966\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.4144 - accuracy: 0.8133 - val_loss: 0.4369 - val_accuracy: 0.8058\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.4329 - val_accuracy: 0.8110\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.3925 - accuracy: 0.8266 - val_loss: 0.4288 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.3860 - accuracy: 0.8276 - val_loss: 0.4309 - val_accuracy: 0.8123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeI0kvVVDmbl"
      },
      "source": [
        "M√¥ h√¨nh USE ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán! H√£y ƒë∆∞a ra m·ªôt s·ªë d·ª± ƒëo√°n v·ªõi n√≥ v√† ƒë√°nh gi√° nh∆∞ ch√∫ng ta ƒë√£ th·ª±c hi·ªán v·ªõi c√°c m√¥ h√¨nh kh√°c."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeyNXqU-gM2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbc27f6-ee98-4633-f703-7a186fc6c932"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n v·ªõi m√¥ h√¨nh USE TF Hub\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14443193],\n",
              "       [0.7271502 ],\n",
              "       [0.9856655 ],\n",
              "       [0.19740924],\n",
              "       [0.73417026],\n",
              "       [0.6859663 ],\n",
              "       [0.9808888 ],\n",
              "       [0.97411025],\n",
              "       [0.91573215],\n",
              "       [0.08070081]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbn1Z0FfgVdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101ab428-2f85-42a0-b308-feb7888f8b5d"
      },
      "source": [
        "# Chuy·ªÉn ƒë·ªïi x√°c su·∫•t d·ª± ƒëo√°n th√†nh c√°c nh√£n\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Ow2de3okcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b82286e-5589-4ddc-8982-d1dd0da78f49"
      },
      "source": [
        "# T√≠nh to√°n c√°c ph√©p ƒëo ch·∫•t l∆∞·ª£ng c·ªßa model 6\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'f1': 0.810686575717776,\n",
              " 'precision': 0.8148798668657973,\n",
              " 'recall': 0.8123359580052494}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BHnRHHHgp1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab489c1-4f16-428d-b391-46a95f10c044"
      },
      "source": [
        "# So s√°nh m√¥ h√¨nh TF Hub v·ªõi baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 81.23, Difference: 1.97\n",
            "Baseline precision: 0.81, New precision: 0.81, Difference: 0.00\n",
            "Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n",
            "Baseline f1: 0.79, New f1: 0.81, Difference: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHwu4QjijYWG"
      },
      "source": [
        "### Model 7: TensorFlow Hub Pretrained Sentence Encoder v·ªõi 10% d·ªØ li·ªáu hu·∫•n luy·ªán\n",
        "\n",
        "M·ªôt trong nh·ªØng l·ª£i √≠ch c·ªßa vi·ªác s·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p transfer learning, ch·∫≥ng h·∫°n nh∆∞ embedding ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc trong USE l√† kh·∫£ nƒÉng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët v·ªõi √≠t d·ªØ li·ªáu (t√†i li·ªáu c·ªßa USE ƒë√£ ƒë·ªÅ c·∫≠p ƒë·∫øn v·∫•n ƒë·ªÅ n√†y ·ªü ph·∫ßn t√≥m t·∫Øt).\n",
        "\n",
        "ƒê·ªÉ th·ª≠ nghi·ªám ƒëi·ªÅu n√†y, ch√∫ng ta s·∫Ω t·∫°o m·ªôt t·∫≠p h·ª£p con d·ªØ li·ªáu hu·∫•n luy·ªán (10%), hu·∫•n luy·ªán m√¥ h√¨nh v√† ƒë√°nh gi√° n√≥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Sal8DpjzWm"
      },
      "source": [
        "### L∆∞u √Ω: Vi·ªác chia t√°ch nh∆∞ v·∫≠y s·∫Ω d·∫´n ƒë·∫øn r√≤ r·ªâ d·ªØ li·ªáu ###\n",
        "### (m·ªôt s·ªë m·∫´u hu·∫•n luy·ªán trong t·∫≠p ki·ªÉm ƒë·ªãnh) ###\n",
        "\n",
        "### CHIA T√ÅCH SAI C√ÅCH (train_df_shuffled ƒë√£ ƒë∆∞·ª£c ph√¢n t√°ch) ###\n",
        "\n",
        "# # T·∫°o t·∫≠p h·ª£p con c√≥ 10% d·ªØ li·ªáu hu·∫•n luy·ªán\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHgowC3GUPJH"
      },
      "source": [
        "# M·ªôt c√°ch th·ª±c hi·ªán ƒë√∫ng (c√≤n nhi·ªÅu c√°ch kh√°c) ƒë·ªÉ t·∫°o t·∫≠p d·ªØ li·ªáu con\n",
        "# (t√°ch train_sentences/train_labels ƒë√£ ƒë∆∞·ª£c ph√¢n t√°ch)\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8jaydmiVnJP",
        "outputId": "17634293-52c5-4a51-e4ef-b5521d339bb3"
      },
      "source": [
        "# Ki·ªÉm tra ƒë·ªô d√†i c·ªßa t·∫≠p d·ªØ li·ªáu 10%\n",
        "print(f\"Total training examples: {len(train_sentences)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E2jr7rSEYT8"
      },
      "source": [
        "Do ch√∫ng ta ƒë√£ ch·ªçn m·ªôt t·∫≠p h·ª£p con ng·∫´u nhi√™n c·ªßa c√°c m·∫´u hu·∫•n luy·ªán, cho n√™n c√°c l·ªõp g·∫ßn nh∆∞ ƒë·ªÅu c√¢n b·∫±ng (v√¨ ch√∫ng n·∫±m trong t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán ƒë·∫ßy ƒë·ªß)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0lEpFT0k0RB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140c4560-e0a5-472e-bdc2-47374fe7f95e"
      },
      "source": [
        "# Ki·ªÉm tra s·ªë l∆∞·ª£ng m·ª•c ti√™u trong t·∫≠p con d·ªØ li·ªáu\n",
        "# (ƒëi·ªÅu n√†y ph·∫£i g·∫ßn v·ªõi ph√¢n ph·ªëi c·ªßa c√°c nh√£n trong train_labels ban ƒë·∫ßu)\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415\n",
              "1    271\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghl1qeGOEnXG"
      },
      "source": [
        "ƒê·ªÉ c√≥ th·ªÉ so s√°nh th√≠ch h·ª£p gi·ªØa kh·∫£ nƒÉng h·ªçc h·ªèi t·ª´ t·∫≠p hu·∫•n luy·ªán ƒë·∫ßy ƒë·ªß v√† t·∫≠p h·ª£p con 10% c·ªßa m√¥ h√¨nh, ch√∫ng ta s·∫Ω clone m√¥ h√¨nh USE (`model_6`) b·∫±ng c√°ch s·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c [`tf.keras.models.clone_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model).\n",
        "\n",
        "Th·ª±c hi·ªán nh∆∞ v·∫≠y s·∫Ω t·∫°o ra m·ªôt ki·∫øn tr√∫c t∆∞∆°ng t·ª±, nh∆∞ng thi·∫øt l·∫≠p l·∫°i c√°c tr·ªçng s·ªë ƒë√£ h·ªçc c·ªßa m·ª•c ti√™u clone (c√°c tr·ªçng s·ªë ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc t·ª´ USE v·∫´n c√≤n nh∆∞ng t·∫•t c·∫£ c√°c tr·ªçng s·ªë kh√°c s·∫Ω ƒë∆∞·ª£c thi·∫øt l·∫≠p l·∫°i)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGmxeAOBjdg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c321240-d2c1-4afe-e8a0-fa35fe64038e"
      },
      "source": [
        "# Clone model_6 nh∆∞ng thi·∫øt l·∫≠p l·∫°i c√°c tr·ªçng s·ªë\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Bi√™n d·ªãch m√¥ h√¨nh\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# L·∫•y summary (gi·ªëng v·ªõi model_6)\n",
        "model_7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxFkEM_aFoLK"
      },
      "source": [
        "Notice the layout of `model_7` is the same as `model_6`. Now let's train the newly created model on our 10% training data subset. L∆∞u √Ω r·∫±ng ki·∫øn tr√∫c c·ªßa `model_7` gi·ªëng v·ªõi `model_6`. B√¢y gi·ªù, h√£y hu·∫•n luy·ªán m√¥ h√¨nh m·ªõi t·∫°o tr√™n t·∫≠p con d·ªØ li·ªáu hu·∫•n luy·ªán 10%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LklU2maOkgUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c50e4b-73f1-4012-af7a-f6ec5e2a1591"
      },
      "source": [
        "# Kh·ªõp m√¥ h√¨nh v·ªõi 10% d·ªØ li·ªáu hu·∫•n luy·ªán\n",
        "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20210923-052925\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 6s 147ms/step - loss: 0.6716 - accuracy: 0.6574 - val_loss: 0.6526 - val_accuracy: 0.6903\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 47ms/step - loss: 0.5972 - accuracy: 0.8032 - val_loss: 0.5944 - val_accuracy: 0.7362\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 45ms/step - loss: 0.5178 - accuracy: 0.8149 - val_loss: 0.5398 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.4526 - accuracy: 0.8265 - val_loss: 0.5084 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 46ms/step - loss: 0.4094 - accuracy: 0.8382 - val_loss: 0.4915 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qpyqdh-F6Eh"
      },
      "source": [
        "Do c√≥ √≠t d·ªØ li·ªáu hu·∫•n luy·ªán h∆°n n√™n vi·ªác hu·∫•n luy·ªán di·ªÖn ra nhanh h∆°n tr∆∞·ªõc.\n",
        "\n",
        "H√£y ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng c·ªßa m√¥ h√¨nh sau khi h·ªçc tr√™n 10% d·ªØ li·ªáu hu·∫•n luy·ªán."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot6MRnznlgCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9b410c-117c-4292-b33e-206ebf4de1a9"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n v·ªõi m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán tr√™n 10% d·ªØ li·ªáu\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24043235],\n",
              "       [0.76837844],\n",
              "       [0.90137184],\n",
              "       [0.29067948],\n",
              "       [0.57149994],\n",
              "       [0.8356514 ],\n",
              "       [0.8062943 ],\n",
              "       [0.83358175],\n",
              "       [0.85545677],\n",
              "       [0.11749928]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj_4aZellpRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce5ceab-3cbf-4d0d-c762-f4c3893affe1"
      },
      "source": [
        "# Chuy·ªÉn ƒë·ªïi x√°c su·∫•t d·ª± ƒëo√°n th√†nh c√°c nh√£n\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_lTXrDblyva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1a4228-9944-4e17-ecae-6c864c3a51fa"
      },
      "source": [
        "# T√≠nh to√°n c√°c k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.7667059443150692,\n",
              " 'precision': 0.7755630249535594,\n",
              " 'recall': 0.7703412073490814}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G84ezltll6DT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d966d5b-0c50-48e9-bb29-1e55063a06e8"
      },
      "source": [
        "# So s√°nh v·ªõi m√¥ h√¨nh c∆° s·ªü\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBs9V61EGh0J"
      },
      "source": [
        "## So s√°nh ch·∫•t l∆∞·ª£ng c·ªßa t·ª´ng m√¥ h√¨nh\n",
        "\n",
        "Ch√∫ng ta ƒë√£ ƒëi ƒë∆∞·ª£c m·ªôt ch·∫∑ng ƒë∆∞·ªùng d√†i, t·ª´ hu·∫•n luy·ªán m√¥ h√¨nh c∆° s·ªü ƒë·∫øn m·ªôt s·ªë m√¥ h√¨nh s√¢u.\n",
        "\n",
        "ƒê√£ ƒë·∫øn l√∫c so s√°nh k·∫øt qu·∫£ c·ªßa c√°c m√¥ h√¨nh.\n",
        "\n",
        "Tuy nhi√™n, tr∆∞·ªõc khi ti·∫øn h√†nh th·ª±c hi·ªán, t√¥i mu·ªën ƒë·ªÅ c·∫≠p r·∫±ng ƒë√¢y l√† m·ªôt quy tr√¨nh h·ªçc s√¢u ti√™u chu·∫©n: hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh kh√°c nhau, sau ƒë√≥ so s√°nh ch√∫ng ƒë·ªÉ xem m√¥ h√¨nh n√†o ho·∫°t ƒë·ªông t·ªët nh·∫•t v√† ti·∫øp t·ª•c hu·∫•n luy·ªán n·∫øu c·∫ßn.\n",
        "\n",
        "C·∫ßn l∆∞u √Ω l√† ƒë·ªëi v·ªõi t·∫•t c·∫£ c√°c th·ª≠ nghi·ªám l·∫≠p m√¥ h√¨nh, ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng c√πng m·ªôt d·ªØ li·ªáu hu·∫•n luy·ªán (ngo·∫°i tr·ª´ `model_7`, ·ªü m√¥ h√¨nh n√†y, ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng 10% d·ªØ li·ªáu hu·∫•n luy·ªán).\n",
        "\n",
        "ƒê·ªÉ hi·ªÉn th·ªã ch·∫•t l∆∞·ª£ng c·ªßa m√¥ h√¨nh, h√£y t·∫°o pandas DataFrame, dictionary ch·ª©a k·∫øt qu·∫£ r·ªìi v·∫Ω bi·ªÉu ƒë·ªì."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex0NSaz7lRf-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "421ea5ed-744d-4bc8-a0fb-b79e367f5ec3"
      },
      "source": [
        "# K·∫øt h·ª£p c√°c k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh th√†nh m·ªôt DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>78.740157</td>\n",
              "      <td>0.791492</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>75.065617</td>\n",
              "      <td>0.751008</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>76.771654</td>\n",
              "      <td>0.767545</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>81.233596</td>\n",
              "      <td>0.814880</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.810687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>77.034121</td>\n",
              "      <td>0.775563</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.766706</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 79.265092   0.811139  0.792651  0.786219\n",
              "simple_dense             78.740157   0.791492  0.787402  0.784697\n",
              "lstm                     75.065617   0.751008  0.750656  0.748927\n",
              "gru                      76.771654   0.767545  0.767717  0.766793\n",
              "bidirectional            76.640420   0.766590  0.766404  0.765121\n",
              "conv1d                   77.821522   0.780752  0.778215  0.775881\n",
              "tf_hub_sentence_encoder  81.233596   0.814880  0.812336  0.810687\n",
              "tf_hub_10_percent_data   77.034121   0.775563  0.770341  0.766706"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-s2DSLpmM1F"
      },
      "source": [
        "# Gi·∫£m accuracy xu·ªëng c√πng t·ª∑ l·ªá v·ªõi c√°c ph√©p ƒëo kh√°c\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp69bR8umD5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "cb7ae0e4-2a9c-4ef3-d23a-a9a93a6a992d"
      },
      "source": [
        "# V·∫Ω v√† so s√°nh c√°c k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avbdkiIuKNNr"
      },
      "source": [
        "C√≥ v·∫ª nh∆∞ c√°c m√¥ h√¨nh USE TensorFlow Hub ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc c·ªßa ch√∫ng ta c√≥ ch·∫•t l∆∞·ª£ng t·ªët nh·∫•t, th·∫≠m ch√≠ m√¥ h√¨nh ch·ªâ c√≥ 10% d·ªØ li·ªáu hu·∫•n luy·ªán d∆∞·ªùng nh∆∞ c≈©ng ho·∫°t ƒë·ªông t·ªët h∆°n c√°c m√¥ h√¨nh kh√°c. ƒêi·ªÅu n√†y cho th·∫•y s·ª©c m·∫°nh c·ªßa transfer learning.\n",
        "\n",
        "L√†m th·∫ø n√†o ƒë·ªÉ ƒëi s√¢u v√† l·∫•y F1-score c·ªßa t·ª´ng m√¥ h√¨nh?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yktdOiufmm3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "97090bc0-63d5-41e2-f7b1-deddfcd99f53"
      },
      "source": [
        "# S·∫Øp x·∫øp k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh theo f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv2iE0TPGdNy"
      },
      "source": [
        "T√¨m hi·ªÉu k·ªπ h∆°n v·ªÅ m·ªôt ph√©p ƒëo, ch√∫ng ta th·∫•y c√°c m√¥ h√¨nh USE TensorFlow Hub ho·∫°t ƒë·ªông t·ªët h∆°n t·∫•t c·∫£ c√°c m√¥ h√¨nh kh√°c. Th·∫≠t th√∫ v·ªã, F1-score c·ªßa m√¥ h√¨nh c∆° s·ªü kh√¥ng qu√° c√°ch bi·ªát so v·ªõi c√°c m√¥ h√¨nh s√¢u c√≤n l·∫°i.\n",
        "\n",
        "Ch√∫ng ta c≈©ng c√≥ th·ªÉ tr·ª±c quan h√≥a t·∫•t c·∫£ nh·∫≠t k√Ω hu·∫•n luy·ªán c·ªßa m√¥ h√¨nh b·∫±ng TensorBoard.dev."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ca8TalwGhPf"
      },
      "source": [
        "# # Xem tensorboad logs c·ªßa c√°c th·ª≠ nghi·ªám m√¥ h√¨nh h√≥a transfer learning (n√™n l√† 4 m√¥ h√¨nh)\n",
        "# # Upload c√°c b·∫£n ghi TensorBoard dev\n",
        "# !tensorboard dev upload --logdir ./model_logs \\\n",
        "#   --name \"NLP modelling experiments\" \\\n",
        "#   --description \"A series of different NLP modellings experiments with various models\" \\\n",
        "#   --one_shot # tho√°t kh·ªèi uploader sau khi ho√†n th√†nh upload"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIYVXCUJ3FBn"
      },
      "source": [
        "C√≥ th·ªÉ xem TensorBoard logs c·ªßa c√°c th·ª≠ nghi·ªám l·∫≠p m√¥ h√¨nh kh√°c nhau m√† ch√∫ng t√¥i ƒë√£ ch·∫°y t·∫°i ƒë√¢y: https://tensorboard.dev/experiment/LkoAakb7QIKBZ0RL97cXbw/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os7dv00u21jg"
      },
      "source": [
        "# N·∫øu c·∫ßn lo·∫°i b·ªè c√°c th·ª≠ nghi·ªám tr∆∞·ªõc, ch√∫ng ta c√≥ th·ªÉ d√πng l·ªánh sau\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGVZhTTiGdd5"
      },
      "source": [
        "## K·∫øt h·ª£p c√°c m√¥ h√¨nh (model ensembling/stacking)\n",
        "\n",
        "Nhi·ªÅu h·ªá th·ªëng s·∫£n xu·∫•t s·ª≠ d·ª•ng m√¥ h√¨nh **ensemble** (k·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh kh√°c nhau) ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n.\n",
        "\n",
        "√ù t∆∞·ªüng ƒë·∫±ng sau model stacking l√† n·∫øu m·ªôt s·ªë m√¥ h√¨nh kh√¥ng t∆∞∆°ng quan th·ªëng nh·∫•t v·ªÅ m·ªôt d·ª± ƒëo√°n, th√¨ d·ª± ƒëo√°n ƒë√≥ ph·∫£i m·∫°nh m·∫Ω h∆°n d·ª± ƒëo√°n ƒë∆∞·ª£c th·ª±c hi·ªán b·ªüi m·ªôt m√¥ h√¨nh ƒë∆°n l·∫ª.\n",
        "\n",
        "T·ª´ kh√≥a trong c√¢u tr√™n l√† **kh√¥ng t∆∞∆°ng quan**, t·ª©c l√† c√°c ki·ªÉu m√¥ h√¨nh kh√°c nhau. V√≠ d·ª•: trong tr∆∞·ªùng h·ª£p c·ªßa ch√∫ng ta, c√≥ th·ªÉ k·∫øt h·ª£p m√¥ h√¨nh c∆° s·ªü, m√¥ h√¨nh hai chi·ªÅu v√† m√¥ h√¨nh USE TTensorFlow Hub.\n",
        "\n",
        "M·∫∑c d√π t·∫•t c·∫£ c√°c m√¥ h√¨nh n√†y ƒë·ªÅu ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n c√πng m·ªôt d·ªØ li·ªáu, nh∆∞ng ch√∫ng l·∫°i c√≥ c√°ch t√¨m pattern kh√°c nhau.\n",
        "\n",
        "N·∫øu ch√∫ng ta s·ª≠ d·ª•ng ba m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán t∆∞∆°ng t·ª±, ch·∫≥ng h·∫°n nh∆∞ ba m√¥ h√¨nh LSTM th√¨ c√°c d·ª± ƒëo√°n m√† ch√∫ng ƒë∆∞a ra c√≥ th·ªÉ s·∫Ω r·∫•t gi·ªëng nhau.\n",
        "\n",
        "H√£y coi ƒëi·ªÅu n√†y nh∆∞ vi·ªác b·∫°n ƒëang quy·∫øt ƒë·ªãnh ƒëi ƒÉn ·ªü ƒë√¢u v·ªõi b·∫°n b√®. N·∫øu b·∫°n v√† c√°c ban c·ªßa b·∫°n c√≥ s·ªü th√≠ch gi·ªëng nhau, c√≥ th·ªÉ c√°c b·∫°n s·∫Ω ch·ªçn c√πng m·ªôt nh√† h√†ng. Nh∆∞ng n·∫øu c√°c b·∫°n c√≥ s·ªü th√≠ch kh√°c nhau v√† cu·ªëi c√πng v·∫´n ch·ªçn c√πng m·ªôt nh√† h√†ng, th√¨ ch·∫Øc h·∫≥n nh√† h√†ng ƒë√≥ ph·∫£i t·ªët.\n",
        "\n",
        "Since we're working with a classification problem, there are a few of ways we can combine our models: Do ch√∫ng ta ƒëang gi·∫£i b√†i to√°n ph√¢n lo·∫°i, n√™n c√≥ m·ªôt s·ªë c√°ch ƒë·ªÉ k·∫øt h·ª£p c√°c m√¥ h√¨nh:\n",
        "1. **Averaging** - L·∫•y x√°c su·∫•t d·ª± ƒëo√°n ƒë·∫ßu ra c·ªßa t·ª´ng m√¥ h√¨nh cho t·ª´ng m·∫´u, k·∫øt h·ª£p ch√∫ng l·∫°i r·ªìi t√≠nh trung b√¨nh.\n",
        "2. **Majority vote (mode)** - ƒê∆∞a ra d·ª± ƒëo√°n v·ªÅ l·ªõp v·ªõi t·ª´ng m√¥ h√¨nh tr√™n t·∫•t c·∫£ c√°c m·∫´u, l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n chi·∫øm ƒëa s·ªë. V√≠ d·ª•: n·∫øu ba m√¥ h√¨nh kh√°c nhau l·∫ßn l∆∞·ª£t d·ª± ƒëo√°n `[1, 0, 1]`, th√¨ l·ªõp ƒëa s·ªë l√† `1`; nh∆∞ v·∫≠y, ƒë√≥ s·∫Ω l√† nh√£n ƒë∆∞·ª£c d·ª± ƒëo√°n.\n",
        "3. **Model stacking** - L·∫•y ƒë·∫ßu ra c·ªßa t·ª´ng m√¥ h√¨nh ƒë√£ ch·ªçn v√† s·ª≠ d·ª•ng ch√∫ng l√†m ƒë·∫ßu v√†o cho m√¥ h√¨nh kh√°c.\n",
        "\n",
        "> üìñ **T√†i li·ªáu:** C√°c ph∆∞∆°ng ph√°p model stacking/ensembling ·ªü tr√™n ƒë∆∞·ª£c tr√≠ch t·ª´ Ch∆∞∆°ng 6 c·ªßa cu·ªën [Machine Learning Engineering](http://www.mlebook.com/wiki/doku.php) (Andriy Burkov). N·∫øu b·∫°n ƒëang mu·ªën t√¨m hi·ªÉu lƒ©nh v·ª±c k·ªπ thu·∫≠t m√°y h·ªçc, kh√¥ng ch·ªâ x√¢y d·ª±ng m√¥ h√¨nh m√† c·∫£ h·ªá th·ªëng m√°y h·ªçc tr√™n quy m√¥ s·∫£n xu·∫•t, t√¥i khuy·∫øn kh√≠ch b·∫°n n√™n ƒë·ªçc to√†n b·ªô cu·ªën n√†y.\n",
        "\n",
        "M·ªôt l·∫ßn n·ªØa, kh√°i ni·ªám model stacking ƒë∆∞·ª£c th·∫•y r√µ nh·∫•t trong th·ª±c t·∫ø.\n",
        "\n",
        "Ch√∫ng ta s·∫Ω k·∫øt h·ª£p m√¥ h√¨nh c∆° s·ªü (`model_0`), m√¥ h√¨nh LSTM (`model_2`) v√† m√¥ h√¨nh USE ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi to√†n b·ªô d·ªØ li·ªáu hu·∫•n luy·ªán (`model_6`) b·∫±ng c√°ch t√≠nh trung b√¨nh c√°c x√°c su·∫•t d·ª± ƒëo√°n k·∫øt h·ª£p c·ªßa t·ª´ng m√¥ h√¨nh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t63u8PCCm-yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a65c8c-325a-402c-bfa3-0a940416bd54"
      },
      "source": [
        "# L·∫•y mean pred probs cho 3 m√¥ h√¨nh\n",
        "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # l·∫•y x√°c su·∫•t d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh c∆° s·ªü\n",
        "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
        "combined_preds = tf.round(combined_pred_probs/3) # t√≠nh trung b√¨nh v√† l√†m tr√≤n c√°c x√°c su·∫•t d·ª± ƒëo√°n ƒë·ªÉ c√≥ ƒë∆∞·ª£c c√°c l·ªõp d·ª± ƒëo√°n\n",
        "combined_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abZa7wqlXSI"
      },
      "source": [
        "Tuy·ªát v·ªùi! Ch√∫ng ta c√≥ m·ªôt m·∫£ng d·ª± ƒëo√°n k·∫øt h·ª£p c·ªßa c√°c l·ªõp kh√°c nhau, h√£y ƒë√°nh gi√° ch√∫ng d·ª±a tr√™n true label v√† th√™m k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh ƒë√£ x·∫øp ch·ªìng v√†o DataFrame `all_model_results`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieYvhDiev8Et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b965dd-54c8-4796-edcc-b31e344b38bb"
      },
      "source": [
        "# T√≠nh to√°n k·∫øt qu·∫£ t·ª´ vi·ªác t√≠nh trung b√¨nh c√°c x√°c su·∫•t d·ª± ƒëo√°n\n",
        "ensemble_results = calculate_results(val_labels, combined_preds)\n",
        "ensemble_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1': 0.7805169025578647,\n",
              " 'precision': 0.7805216999297674,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "132EHlUUpRrP"
      },
      "source": [
        "# Th√™m c√°c k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh k·∫øt h·ª£p v√†o results DataFrame\n",
        "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm2P1zsvpZ3D"
      },
      "source": [
        "# Chuy·ªÉn ƒë·ªïi accuracy sang c√πng thang ƒëo v·ªõi c√°c k·∫øt qu·∫£ c√≤n l·∫°i\n",
        "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trmdZ6eEpwHI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "b2704163-e293-4b88-f289-efcc04d9b4b2"
      },
      "source": [
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.791492</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.751008</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.767545</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.814880</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.810687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.775563</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.766706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.780522</td>\n",
              "      <td>0.780840</td>\n",
              "      <td>0.780517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                 0.792651   0.811139  0.792651  0.786219\n",
              "simple_dense             0.787402   0.791492  0.787402  0.784697\n",
              "lstm                     0.750656   0.751008  0.750656  0.748927\n",
              "gru                      0.767717   0.767545  0.767717  0.766793\n",
              "bidirectional            0.766404   0.766590  0.766404  0.765121\n",
              "conv1d                   0.778215   0.780752  0.778215  0.775881\n",
              "tf_hub_sentence_encoder  0.812336   0.814880  0.812336  0.810687\n",
              "tf_hub_10_percent_data   0.770341   0.775563  0.770341  0.766706\n",
              "ensemble_results         0.780840   0.780522  0.780840  0.780517"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZwqwF_swdIA"
      },
      "source": [
        "M√¥ h√¨nh x·∫øp ch·ªìng ƒëi ng∆∞·ª£c l·∫°i v·ªõi c√°c m√¥ h√¨nh kh√°c nh∆∞ th·∫ø n√†o?\n",
        "\n",
        "> üîë **L∆∞u √Ω:** C√≥ v·∫ª nh∆∞ nhi·ªÅu k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh kh√° t∆∞∆°ng t·ª± nhau. ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† c√≥ m·ªôt s·ªë h·∫°n ch·∫ø ƒë·ªëi v·ªõi vi·ªác h·ªçc t·ª´ d·ªØ li·ªáu. Khi nhi·ªÅu th·ª≠ nghi·ªám l·∫≠p m√¥ h√¨nh tr·∫£ l·∫°i k·∫øt qu·∫£ t∆∞∆°ng t·ª±, b·∫°n n√™n truy c·∫≠p l·∫°i d·ªØ li·ªáu c·ªßa m√¨nh, ch√∫ng ta s·∫Ω th·ª±c hi·ªán ngay ƒëi·ªÅu n√†y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpwErZOgX_nC"
      },
      "source": [
        "## L∆∞u v√† load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n",
        "\n",
        "M·∫∑c d√π th·ªùi gian hu·∫•n luy·ªán d√†i, nh∆∞ng ch√∫ng ta c≈©ng n√™n l∆∞u l·∫°i c√°c m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ tr√°nh ph·∫£i hu·∫•n luy·ªán l·∫°i.\n",
        "\n",
        "L∆∞u c√°c m√¥ h√¨nh c≈©ng cho ph√©p ch√∫ng ta xu·∫•t ch√∫ng ƒë·ªÉ s·ª≠ d·ª•ng ·ªü n∆°i kh√°c b√™n ngo√†i notebook, ch·∫≥ng h·∫°n nh∆∞ trong m·ªôt ·ª©ng d·ª•ng web.\n",
        "\n",
        "C√≥ hai c√°ch ch√≠nh ƒë·ªÉ [l∆∞u m·ªôt m√¥ h√¨nh trong TensorFlow](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model):\n",
        "1. `HDF5` format.\n",
        "2. `SavedModel` format (m·∫∑c ƒë·ªãnh).\n",
        "\n",
        "Ch√∫ng ta h√£y xem x√©t c·∫£ hai."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlwjGFVyX-_T"
      },
      "source": [
        "# L∆∞u m√¥ h√¨nh TF Hub Sentence Encoder th√†nh HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp6zvmprm9A3"
      },
      "source": [
        "N·∫øu ch√∫ng ta l∆∞u m√¥ h√¨nh ·ªü d·∫°ng `HDF5`, th√¨ khi load l·∫°i m√¥ h√¨nh ƒë√≥, c·∫ßn [cho TensorFlow bi·∫øt v·ªÅ b·∫•t k·ª≥ ƒë·ªëi t∆∞·ª£ng t√πy ch·ªânh n√†o m√† ch√∫ng ta ƒë√£ s·ª≠ d·ª•ng](https://www.tensorflow.org/tutorials/keras/save_and_load#saving_custom_objects) (v√≠ d·ª•: c√°c th√†nh ph·∫ßn kh√¥ng ƒë∆∞·ª£c t·∫°o t·ª´ TensorFlow thu·∫ßn t√∫y, ch·∫≥ng h·∫°n nh∆∞ c√°c th√†nh ph·∫ßn TensorFlow Hub)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSINZ0Q-nRb2"
      },
      "source": [
        "# Load m√¥ h√¨nh v·ªõi Hub Layer t√πy ch·ªânh (y√™u c·∫ßu v·ªõi HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4BCJ8iXnZ4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3a7c0e-bea8-4f99-923d-943213cd72cd"
      },
      "source": [
        "# M√¥ h√¨nh ƒë√£ load ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 14ms/step - loss: 0.4309 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43088313937187195, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02rbT4fwn0It"
      },
      "source": [
        "G·ªçi ph∆∞∆°ng th·ª©c `save()` tr√™n m√¥ h√¨nh m·ª•c ti√™u v√† chuy·ªÉn cho n√≥ m·ªôt ƒë∆∞·ªùng d·∫´n file cho ph√©p ch√∫ng ta l∆∞u m√¥ h√¨nh c·ªßa m√¨nh ·ªü `SavedModel` format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3eVaNBDoMsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55b3bd1-ac2d-45c1-90f2-4b021c9368f9"
      },
      "source": [
        "# L∆∞u m√¥ h√¨nh TF Hub Sentence Encoder th√†nh SavedModel format (m·∫∑c ƒë·ªãnh)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-t01S-JoOqK"
      },
      "source": [
        "N·∫øu s·ª≠ d·ª•ng SavedModel format (m·∫∑c ƒë·ªãnh), ch√∫ng ta c√≥ th·ªÉ reload m√¥ h√¨nh c·ªßa m√¨nh m√† kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh c√°c ƒë·ªëi t∆∞·ª£ng t√πy ch·ªânh b·∫±ng c√°ch s·ª≠ d·ª•ng h√†m [`tensorflow.keras.models.load_model()`](https://www.tensorflow.org/tutorials/keras/save_and_load)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw3zf4fVoU5H"
      },
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqiPr6iiofi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4395889-dca0-4061-ba22-1723001c5c4e"
      },
      "source": [
        "# ƒê√°nh gi√° SavedModel format ƒë√£ load\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 14ms/step - loss: 0.4309 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43088313937187195, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzp3SHi3oQ3u"
      },
      "source": [
        "Nh∆∞ c√°c b·∫°n th·∫•y, vi·ªác l∆∞u v√† load m√¥ h√¨nh v·ªõi m·ªôt trong hai ƒë·ªãnh d·∫°ng ƒë·ªÅu cho ch·∫•t l∆∞·ª£ng nh∆∞ nhau.\n",
        "\n",
        "> ü§î **C√¢u h·ªèi:** Ch√∫ng ta n√™n s·ª≠ d·ª•ng `SavedModel` format hay `HDF5` format?\n",
        "\n",
        "V·ªõi h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p, `SavedModel` format ƒë√£ ƒë·ªß. Tuy nhi√™n, ƒë√¢y l√† m·ªôt ti√™u chu·∫©n c·ª• th·ªÉ c·ªßa TensorFlow. N·∫øu b·∫°n c·∫ßn m·ªôt ti√™u chu·∫©n d·ªØ li·ªáu c√≥ m·ª•c ƒë√≠ch chung h∆°n, `HDF5` c√≥ th·ªÉ s·∫Ω t·ªët h∆°n. Xem [t√†i li·ªáu TensorFlow v·ªÅ c√°ch l∆∞u v√† load m√¥ h√¨nh](https://www.tensorflow.org/tutorials/keras/save_and_load) ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5a1648rG3z1"
      },
      "source": [
        "## T√¨m nh·ªØng m·∫´u sai nh·∫•t\n",
        "\n",
        "Ch√∫ng ta ƒë√£ ƒë·ªÅ c·∫≠p tr∆∞·ªõc ƒë√≥ r·∫±ng n·∫øu nhi·ªÅu th·ª≠ nghi·ªám l·∫≠p m√¥ h√¨nh tr·∫£ l·∫°i c√°c k·∫øt qu·∫£ t∆∞∆°ng t·ª±, d√π s·ª≠ d·ª•ng c√°c lo·∫°i m√¥ h√¨nh kh√°c nhau, th√¨ ch√∫ng ta n√™n xem l·∫°i d·ªØ li·ªáu v√† ki·ªÉm tra xem t·∫°i sao l·∫°i nh∆∞ v·∫≠y.\n",
        "\n",
        "M·ªôt trong nh·ªØng c√°ch t·ªët nh·∫•t ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu l√† s·∫Øp x·∫øp c√°c d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh v√† t√¨m c√°c m·∫´u m√† m√¥ h√¨nh ƒë√≥ sai nhi·ªÅu *nh·∫•t*, t·ª©c l√† nh·ªØng d·ª± ƒëo√°n c√≥ x√°c su·∫•t d·ª± ƒëo√°n cao nh∆∞ng h√≥a ra l·∫°i sai.\n",
        "\n",
        "V√¨ v·∫≠y, h√£y tr·ª±c quan h√≥a n√≥ ra.\n",
        "\n",
        "ƒê·ªÉ m·ªçi th·ª© tr·ª±c quan h∆°n, h√£y l·∫•y c√°c l·ªõp v√† x√°c su·∫•t d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët nh·∫•t c√πng v·ªõi c√°c m·∫´u ki·ªÉm ƒë·ªãnh (vƒÉn b·∫£n v√† nh√£n g·ªëc) v√† k·∫øt h·ª£p ch√∫ng v√†o m·ªôt pandas DataFrame.\n",
        "\n",
        "* N·∫øu m√¥ h√¨nh t·ªët nh·∫•t c·ªßa ch√∫ng ta v·∫´n kh√¥ng ho√†n h·∫£o, th√¨ c√≥ nh·ªØng m·∫´u n√†o b·ªã sai?\n",
        "* Nh·ªØng m·∫´u n√†o sai *nh·∫•t*?\n",
        "* C√≥ nh√£n n√†o b·ªã sai kh√¥ng? V√≠ d·ª•: m√¥ h√¨nh g√°n ƒë√∫ng nh∆∞ng nh√£n g·ªëc kh√¥ng ph·∫£n √°nh ƒë∆∞·ª£c ƒëi·ªÅu n√†y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnHfX--TwMIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d060505e-21c7-42b7-e664-8c517f92d425"
      },
      "source": [
        "# T·∫°o dataframe v·ªõi validation sentences v√† c√°c d·ª± ƒëo√°n m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët nh·∫•t\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.144432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.727150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.985666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.197409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.734170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.144432\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.727150\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.985666\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.197409\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.734170"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKJ9dTbPrIG4"
      },
      "source": [
        "B√¢y gi·ªù, h√£y t√¨m c√°c d·ª± ƒëo√°n sai c·ªßa m√¥ h√¨nh (`target != pred`) v√† s·∫Øp x·∫øp ch√∫ng theo x√°c su·∫•t d·ª± ƒëo√°n (c·ªôt `pred_prob`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DwBXQS1wvZx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "7d37fad0-db94-471e-fef1-3859b48c58f3"
      },
      "source": [
        "# T√¨m c√°c d·ª± ƒëo√°n sai v√† s·∫Øp x·∫øp theo x√°c su·∫•t d·ª± ƒëo√°n\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.864676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.837961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.836361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.834875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.800890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.782611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>√•√àMGN-AFRICA√•¬® pin:263789F4 √•√à Correction: Ten...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.782433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>The Sound of Arson</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.771343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910481\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.864676\n",
              "209  Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...       0   1.0   0.837961\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.836361\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.835225\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.834875\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.800890\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.782611\n",
              "698  √•√àMGN-AFRICA√•¬® pin:263789F4 √•√à Correction: Ten...       0   1.0   0.782433\n",
              "144                                 The Sound of Arson       0   1.0   0.771343"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3VcRHOusB2D"
      },
      "source": [
        "Cu·ªëi c√πng, ch√∫ng ta c√≥ th·ªÉ vi·∫øt code ƒë·ªÉ hi·ªÉn th·ªã vƒÉn b·∫£n m·∫´u, truth label, l·ªõp d·ª± ƒëo√°n v√† x√°c su·∫•t d·ª± ƒëo√°n. V√¨ ch√∫ng ta ƒë√£ s·∫Øp x·∫øp c√°c m·∫´u c·ªßa m√¨nh theo x√°c su·∫•t d·ª± ƒëo√°n, n√™n vi·ªác xem c√°c m·∫´u t·ª´ ph·∫ßn ƒë·∫ßu c·ªßa DataFrame `most_wrong` s·∫Ω hi·ªÉn th·ªã false positives.\n",
        "\n",
        "Nh·∫Øc l·∫°i:\n",
        "* `0` = Kh√¥ng ph·∫£i real diaster Tweet\n",
        "* `1` = Real diaster Tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLFYDEsoxRFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d66210-3007-4661-e8c2-655d621f0e90"
      },
      "source": [
        "# Ki·ªÉm tra false positives (m√¥ h√¨nh d·ª± ƒëo√°n l√† 1 trong khi l·∫Ω ra ph·∫£i l√† 0)\n",
        "for row in most_wrong[:10].itertuples(): # l·∫∑p qua 10 h√†ng tr√™n c√πng (thay ƒë·ªïi ch·ªâ m·ª•c ƒë·ªÉ xem c√°c h√†ng kh√°c nhau)\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.9104808568954468\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8646755218505859\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8379608988761902\n",
            "Text:\n",
            "Ashes 2015: Australia¬â√õ¬™s collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8363614082336426\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8352250456809998\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8348745107650757\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.800889790058136\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.7826112508773804\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.7824334502220154\n",
            "Text:\n",
            "√•√àMGN-AFRICA√•¬® pin:263789F4 √•√à Correction: Tent Collapse Story: Correction: Tent Collapse story √•√à http://t.co/fDJUYvZMrv @wizkidayo\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.7713427543640137\n",
            "Text:\n",
            "The Sound of Arson\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXCH9J-UspWg"
      },
      "source": [
        "Ch√∫ng ta c√≥ th·ªÉ xem ph·∫ßn cu·ªëi c·ªßa DataFrame `most_wrong` ƒë·ªÉ ki·ªÉm tra false negatives (m√¥ h√¨nh d·ª± ƒëo√°n 0, kh√¥ng ph·∫£i l√† real diaster Tweet, trong khi l·∫Ω ra n√≥ ph·∫£i d·ª± ƒëo√°n 1, real diaster Tweet)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EaMchehxwLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5fdb89-38b2-405a-f5d5-f816b83d3c79"
      },
      "source": [
        "# Ki·ªÉm tra false negatives sai nhi·ªÅu nh·∫•t (m√¥ h√¨nh d·ª± ƒëo√°n l√† 0 trong khi l·∫Ω ra n√≥ ph·∫£i d·ª± ƒëo√°n l√† 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.06304337829351425\n",
            "Text:\n",
            "@BoyInAHorsemask its a panda trapped in a dogs body\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.06279505044221878\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.06060810014605522\n",
            "Text:\n",
            "VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP WATCH 241487 http://t.co/yFy3nkkcoH http://t.co/KNEhVvOHVK\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.0573178268969059\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.04535556212067604\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.04145137220621109\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03926113247871399\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.0385933592915535\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03627230226993561\n",
            "Text:\n",
            "Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.032887961715459824\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRKQPEAgtpJq"
      },
      "source": [
        "B·∫°n c√≥ nh·∫≠n th·∫•y ƒëi·ªÅu g√¨ th√∫ v·ªã v·ªÅ nh·ªØng m·∫´u sai nh·∫•t kh√¥ng?\n",
        "\n",
        "C√°c nh√£n g·ªëc c√≥ ch√≠nh x√°c kh√¥ng? B·∫°n nghƒ© ƒëi·ªÅu g√¨ s·∫Ω x·∫£y ra n·∫øu ch√∫ng ta quay l·∫°i v√† s·ª≠a c√°c nh√£n kh√¥ng ƒë√∫ng?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0W3DWgWJCWs"
      },
      "source": [
        "## ƒê∆∞a ra d·ª± ƒëo√°n tr√™n t·∫≠p d·ªØ li·ªáu ki·ªÉm tra\n",
        "\n",
        "Ch√∫ng ta ƒë√£ th·∫•y m√¥ h√¨nh ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o tr√™n t·∫≠p ki·ªÉm ƒë·ªãnh.\n",
        "\n",
        "V·∫≠y n√≥ ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o tr√™n t·∫≠p ki·ªÉm tra?\n",
        "\n",
        "Ch√∫ng ta kh√¥ng c√≥ nh√£n cho t·∫≠p d·ªØ li·ªáu ki·ªÉm tra, v√¨ v·∫≠y, ch√∫ng ta s·∫Ω ph·∫£i ƒë∆∞a ra m·ªôt s·ªë d·ª± ƒëo√°n v√† t·ª± ki·ªÉm tra ch√∫ng.\n",
        "\n",
        "H√£y vi·∫øt code ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n tr√™n c√°c m·∫´u ng·∫´u nhi√™n t·ª´ t·∫≠p d·ªØ li·ªáu ki·ªÉm tra v√† hi·ªÉn th·ªã ch√∫ng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q9lgqoDyequ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81e856d-8024-4471-ee0d-3c14eb128cb0"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n tr√™n t·∫≠p d·ªØ li·ªáu ki·ªÉm tra\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # ph·∫£i l√† list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1, Prob: 0.538340151309967\n",
            "Text:\n",
            "Flash Flood Watch in effect through 7:00am Thursday morning/12:00pm Thursday afternoon.\n",
            "For: Perry Wayne Cape... http://t.co/fs7vro5seS\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.9250481128692627\n",
            "Text:\n",
            "NONSENSE &gt;&gt; famine memories  -- strong exaggeration of Ukrainian MSM\n",
            "#ukraine #russia #?????????? #sanctions https://t.co/dDOTd7W2o8\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.8940093517303467\n",
            "Text:\n",
            "New warning for Central Hills 1' hail 60 mph winds. NOT affecting Sturgis but could later tonight. #KOTAWeather http://t.co/E8oUxVKuTE\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.07600127905607224\n",
            "Text:\n",
            "@imaginator1dx currently reading after. as you can see after we collided is on my dresser waiting to get read http://t.co/QwrASZ6LHO\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.026800094172358513\n",
            "Text:\n",
            "Don't ruin a good today by thinking about a bad yesterday ????\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.21049749851226807\n",
            "Text:\n",
            "I hope I get electrocuted today at work\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.07167388498783112\n",
            "Text:\n",
            "http://t.co/16EClWrW84 Asics GT-II Super Red 2.0 11 Ronnie Fieg Kith Red White 3M x gel grey volcano 2\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.04366963729262352\n",
            "Text:\n",
            "I swear my eyes be bloody red but bitch I feel amazing.\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.9714540839195251\n",
            "Text:\n",
            "Japan marks 70th anniversary of Hiroshima atomic bombing: Bells tolled in Hiroshima on Thursday as Japan marke... http://t.co/IqAIRPdIhg\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.10844964534044266\n",
            "Text:\n",
            "@USCOURT If 90BLKs&amp;8WHTs colluded 2 take WHT F @USAgov AUTH Hostage&amp;2 make her look BLK w/Bioterrorism&amp;use her lgl/org IDis ID still hers?\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcvI5zgJ0Tgp"
      },
      "source": [
        "C√°c d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh tr√¥ng nh∆∞ th·∫ø n√†o tr√™n t·∫≠p d·ªØ li·ªáu ki·ªÉm tra?\n",
        "\n",
        "C·∫ßn th·ª±c hi·ªán c√°c lo·∫°i ki·ªÉm tra tr·ª±c quan n√†y th∆∞·ªùng xuy√™n nh·∫•t c√≥ th·ªÉ ƒë·ªÉ xem qua c√°ch m√¥ h√¨nh ho·∫°t ƒë·ªông tr√™n d·ªØ li·ªáu ch∆∞a bi·∫øt, r·ªìi c√°ch n√≥ ho·∫°t ƒë·ªông trong th·ª≠ nghi·ªám th·ª±c: Tweets from the wild."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT1jhk8xdod5"
      },
      "source": [
        "## D·ª± ƒëo√°n v·ªÅ Tweets from the wild\n",
        "\n",
        "L√†m th·∫ø n√†o ƒë·ªÉ t√¨m th·∫•y m·ªôt s·ªë Tweet v√† s·ª≠ d·ª•ng m√¥ h√¨nh c·ªßa ch√∫ng ta ƒë·ªÉ d·ª± ƒëo√°n xem ch√∫ng c√≥ ph·∫£i th·∫£m h·ªça kh√¥ng?\n",
        "\n",
        "ƒê·ªÉ b·∫Øt ƒë·∫ßu, h√£y l·∫•y m·ªôt trong c√°c Tweet c·ªßa t√¥i: [cu·ªôc s·ªëng gi·ªëng nh∆∞ m·ªôt m√¥ h√¨nh ensemble](https://twitter.com/mrdbourke/status/1313649328351662082)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHmXxuPH0aUB"
      },
      "source": [
        "# Bi·∫øn Tweet th√†nh string\n",
        "daniels_tweet = \"Life like an ensemble: take the best choices from others and make your own\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPbZaGznvbEx"
      },
      "source": [
        "Gi·ªù ch√∫ng ta s·∫Ω vi·∫øt m·ªôt h√†m nh·ªè nh·∫≠n m√¥ h√¨nh v√† c√¢u m·∫´u r·ªìi tr·∫£ v·ªÅ d·ª± ƒëo√°n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyH9tn9upjld"
      },
      "source": [
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n v·ªÅ c√¢u.\n",
        "\n",
        "  Tr·∫£ v·ªÅ c√¢u, nh√£n ƒë√£ d·ª± ƒëo√°n v√† x√°c su·∫•t d·ª± ƒëo√°n.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvCG4RuUvj6d"
      },
      "source": [
        "Tuy·ªát! Gi·ªù h√£y ki·ªÉm tra m√¥ h√¨nh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxONpJV8qmWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd8f755-089c-4d6b-a2be-890644d10199"
      },
      "source": [
        "# ƒê∆∞a ra d·ª± ƒëo√°n v·ªÅ Tweet from the wild\n",
        "predict_on_sentence(model=model_6, # S·ª≠ d·ª•ng m√¥ h√¨nh USE\n",
        "                    sentence=daniels_tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0.0 (not real disaster) Prob: 0.046233948320150375\n",
            "Text:\n",
            "Life like an ensemble: take the best choices from others and make your own\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYOfNacw08Of"
      },
      "source": [
        "M√¥ h√¨nh c·ªßa ch√∫ng ta ƒë√£ d·ª± ƒëo√°n ƒë√∫ng. Tweet c·ªßa t√¥i kh√¥ng ph·∫£i v·ªÅ th·∫£m h·ªça.\n",
        "\n",
        "L√†m th·∫ø n√†o ƒë·ªÉ t√¨m ƒë∆∞·ª£c m·ªôt v√†i Tweet v·ªÅ c√°c th·∫£m h·ªça th·ª±c t·∫ø?\n",
        "\n",
        "Ch·∫≥ng h·∫°n nh∆∞ hai Tweet sau v·ªÅ v·ª• n·ªï t·∫°i Beirut nƒÉm 2020."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqILBsTK2i9R"
      },
      "source": [
        "# Ngu·ªìn - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
        "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
        "\n",
        "# Ngu·ªìn - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
        "beirut_tweet_2 = \"#Beirut declared a ‚Äúdevastated city‚Äù, two-week state of emergency officially declared. #Lebanon\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvlbHDISrVmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be0b58b-4ac6-4948-cd1e-1d43f4ddb159"
      },
      "source": [
        "# D·ª± ƒëo√°n v·ªÅ Tweet 1: diaster\n",
        "predict_on_sentence(model=model_6,\n",
        "                    sentence=beirut_tweet_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9625465869903564\n",
            "Text:\n",
            "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uKYx11p2zCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4b7408-f56d-49ed-ff41-584dfe65cf1b"
      },
      "source": [
        "# D·ª± ƒëo√°n v·ªÅ Tweet 2: diaster\n",
        "predict_on_sentence(model=model_6,\n",
        "                    sentence=beirut_tweet_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9678557515144348\n",
            "Text:\n",
            "#Beirut declared a ‚Äúdevastated city‚Äù, two-week state of emergency officially declared. #Lebanon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fczP1dFcwe98"
      },
      "source": [
        "C√≥ v·∫ª nh∆∞ m√¥ h√¨nh c·ªßa ch√∫ng ta ƒëang ho·∫°t ƒë·ªông nh∆∞ d·ª± ki·∫øn, d·ª± ƒëo√°n c·∫£ hai Tweet v·ªÅ diaster th·ª±c s·ª± l√† th·∫£m h·ªça.\n",
        "\n",
        "> üîë **L∆∞u √Ω:** C√°c v√≠ d·ª• tr√™n ƒë∆∞·ª£c tuy·ªÉn ch·ªçn v√† l√† nh·ªØng tr∆∞·ªùng h·ª£p ch√∫ng ta d·ª± ki·∫øn m√¥ h√¨nh ho·∫°t ƒë·ªông v·ªõi ch·∫•t l∆∞·ª£ng cao. ƒê·ªëi v·ªõi c√°c h·ªá th·ªëng s·∫£n xu·∫•t th·ª±c t·∫ø, ch√∫ng ta s·∫Ω c·∫ßn li√™n t·ª•c th·ª±c hi·ªán c√°c ki·ªÉm th·ª≠ ƒë·ªÉ xem m√¥ h√¨nh ƒëang ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp0fkK-tHPRE"
      },
      "source": [
        "## C√¢n b·∫±ng h·ªá s·ªë/t·ªëc ƒë·ªô\n",
        "\n",
        "M·ªôt trong nh·ªØng b√†i ki·ªÉm tra cu·ªëi c√πng m√† ch√∫ng ta s·∫Ω th·ª±c hi·ªán l√† t√¨m c√¢n b·∫±ng t·ªëc ƒë·ªô/h·ªá s·ªë gi·ªØa m√¥ h√¨nh t·ªët nh·∫•t v√† m√¥ h√¨nh c∆° s·ªü.\n",
        "\n",
        "T·∫°i sao ƒëi·ªÅu n√†y l·∫°i quan tr·ªçng?\n",
        "\n",
        "M·∫∑c d√π ch√∫ng ta c√≥ th·ªÉ ch·ªçn ƒë∆∞·ª£c m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët nh·∫•t th√¥ng qua th·ª≠ nghi·ªám, nh∆∞ng m√¥ h√¨nh n√†y c√≥ th·ªÉ kh√¥ng th·ª±c s·ª± hi·ªáu qu·∫£ trong thi·∫øt l·∫≠p s·∫£n xu·∫•t.\n",
        "\n",
        "Theo c√°ch n√†y, gi·∫£ s·ª≠ ch√∫ng ta ƒëang s·ª≠ d·ª•ng Twitter v√† nh·∫≠n ƒë∆∞·ª£c 1 tri·ªáu Tweet m·ªói gi·ªù (ƒë√¢y ch·ªâ l√† con s·ªë b·ªãa ƒë·∫∑t, con s·ªë th·ª±c t·∫ø cao h∆°n nhi·ªÅu). Ch√∫ng ta ƒëang c·ªë g·∫Øng x√¢y d·ª±ng m·ªôt h·ªá th·ªëng ph√°t hi·ªán thi√™n tai ƒë·ªÉ ƒë·ªçc c√°c Tweet v√† c·∫£nh b√°o c√°c c∆° quan ch·ª©c nƒÉng v·ªÅ c√°c thi√™n tai s√°t v·ªõi th·ª±c t·∫ø.\n",
        "\n",
        "NƒÉng l·ª±c m√°y t√≠nh kh√¥ng mi·ªÖn ph√≠, v√¨ v·∫≠y ch√∫ng ta b·ªã gi·ªõi h·∫°n, ch·ªâ c√≥ duy nh·∫•t m·ªôt m√°y t√≠nh cho d·ª± √°n. ·ªû m√°y ƒë√≥, m·ªôt trong c√°c m√¥ h√¨nh s·∫Ω th·ª±c hi·ªán 10,000 d·ª± ƒëo√°n m·ªói gi√¢y v·ªõi ƒë·ªô ch√≠nh x√°c 80% trong khi m·ªôt m√¥ h√¨nh kh√°c (m√¥ h√¨nh l·ªõn h∆°n) ƒë∆∞a ra 100 d·ª± ƒëo√°n m·ªói gi√¢y v·ªõi ƒë·ªô ch√≠nh x√°c 85%.\n",
        "\n",
        "B·∫°n s·∫Ω ch·ªçn m√¥ h√¨nh n√†o?\n",
        "\n",
        "Vi·ªác tƒÉng ch·∫•t l∆∞·ª£ng c·ªßa m√¥ h√¨nh th·ª© hai c√≥ ƒë√°ng ƒë·ªÉ b·ªè qua nƒÉng l·ª±c b·ªï sung kh√¥ng?\n",
        "\n",
        "T·∫•t nhi√™n, ch√∫ng ta c√≥ th·ªÉ th·ª≠ nhi·ªÅu t√πy ch·ªçn th·ª≠ ·ªü ƒë√¢y, ch·∫≥ng h·∫°n nh∆∞ g·ª≠i c√†ng nhi·ªÅu Tweet c√†ng t·ªët cho m√¥ h√¨nh ƒë·∫ßu ti√™n, sau ƒë√≥ g·ª≠i nh·ªØng Tweet m√† m√¥ h√¨nh ƒë√≥ √≠t ch·∫Øc ch·∫Øn nh·∫•t cho m√¥ h√¨nh th·ª© hai.\n",
        "\n",
        "V·∫•n ƒë·ªÅ ·ªü ƒë√¢y l√† c·∫ßn minh h·ªça m√¥ h√¨nh t·ªët nh·∫•t m√† ch√∫ng ta t√¨m th·∫•y th√¥ng qua th·ª≠ nghi·ªám, c√≥ th·ªÉ kh√¥ng ph·∫£i m√¥ h√¨nh m√† ch√∫ng ta s·ª≠ d·ª•ng trong qu√° tr√¨nh s·∫£n xu·∫•t.\n",
        "\n",
        "ƒê·ªÉ c·ª• th·ªÉ h∆°n, h√£y vi·∫øt m·ªôt h√†m l·∫•y m·ªôt m√¥ h√¨nh, m·ªôt s·ªë m·∫´u v√† th·ªùi gian ƒë·ªÉ m√¥ h√¨nh ƒë∆∞a ra d·ª± ƒëo√°n v·ªÅ c√°c m·∫´u ƒë√≥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnXp8DKOp3J6"
      },
      "source": [
        "# T√≠nh th·ªùi gian d·ª± ƒëo√°n\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Th·ªùi gian m·ªôt m√¥ h√¨nh ƒë∆∞a ra d·ª± ƒëo√°n tr√™n c√°c m·∫´u.\n",
        "\n",
        "  ƒê·ªëi s·ªë:\n",
        "  ----\n",
        "  model = m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n",
        "  sample = danh s√°ch c√°c m·∫´u\n",
        "\n",
        "  Tr·∫£ v·ªÅ:\n",
        "  ----\n",
        "  total_time = t·ªïng th·ªùi gian ƒë√£ tr√¥i qua ƒë·ªÉ m√¥ h√¨nh ƒë∆∞a ra d·ª± ƒëo√°n tr√™n c√°c m·∫´u\n",
        "  time_per_pred = th·ªùi gian t√≠nh b·∫±ng gi√¢y cho m·ªói m·∫´u ƒë∆°n l·∫ª\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # l·∫•y th·ªùi gian b·∫Øt ƒë·∫ßu\n",
        "  model.predict(samples) # ƒë∆∞a ra d·ª± ƒëo√°n\n",
        "  end_time = time.perf_counter() # get finish time l·∫•y th·ªùi gian k·∫øt th√∫c\n",
        "  total_time = end_time-start_time # t√≠nh xem d·ª± ƒëo√°n m·∫•t bao nhi√™u th·ªùi gian\n",
        "  time_per_pred = total_time/len(val_sentences) # t√¨m th·ªùi gian d·ª± ƒëo√°n cho m·ªói m·∫´u\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxWwS73hze6Z"
      },
      "source": [
        "Tr√¥ng ·ªïn ƒë·∫•y!\n",
        "\n",
        "B√¢y gi·ªù, h√£y s·ª≠ d·ª•ng h√†m `pred_timer()` ƒë·ªÉ ƒë√°nh gi√° th·ªùi gian d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët nh·∫•t (`model_6`) v√† m√¥ h√¨nh c∆° s·ªü c·ªßa ch√∫ng ta (`model_0`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMbGMIWd5c9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a151071-956a-4c97-fd95-18392a57a78b"
      },
      "source": [
        "# T√≠nh th·ªùi gian d·ª± ƒëo√°n c·ªßa TF Hub Sentence Encoder\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3529780789999677, 0.0004632258254592752)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ej2VyT5oQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbedfa1-282e-4b04-b2c4-1a3b33771b1e"
      },
      "source": [
        "# T√≠nh th·ªùi gian d·ª± ƒëo√°n c·ªßa Naive Bayes\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.018752853000023606, 2.4610043307117593e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqNnKMxhz8Kl"
      },
      "source": [
        "C√≥ v·∫ª nh∆∞ v·ªõi ph·∫ßn c·ª©ng hi·ªán t·∫°i c·ªßa ch√∫ng ta (trong tr∆∞·ªùng h·ª£p n√†y, t√¥i ƒëang s·ª≠ d·ª•ng Google Colab notebook), m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët nh·∫•t t·ªën g·∫•p 10 l·∫ßn th·ªùi gian ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n nh∆∞ m√¥ h√¨nh c∆° s·ªü.\n",
        "\n",
        "Th·ªùi gian d·ª± ƒëo√°n th√™m ƒë√≥ c√≥ ƒë√°ng kh√¥ng?\n",
        "\n",
        "H√£y so s√°nh th·ªùi gian tr√™n m·ªói d·ª± ƒëo√°n v·ªõi F1-score c·ªßa m√¥ h√¨nh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANKHEfRN7Nhd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "a4ca1fff-0b84-41d0-85fd-b7f258d47558"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlHdTqTl0aOq"
      },
      "source": [
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-ideal-performance-speed-of-pred-tradeoff-highlighted.png)\n",
        "*V·ªã tr√≠ l√Ω t∆∞·ªüng cho m√¥ h√¨nh c√¢n b·∫±ng t·ªëc ƒë·ªô v√† ch·∫•t l∆∞·ª£ng (d·ª± ƒëo√°n nhanh v·ªõi k·∫øt qu·∫£ t·ªët).*\n",
        "\n",
        "T·∫•t nhi√™n, v·ªã tr√≠ l√Ω t∆∞·ªüng cho m·ªói ch·∫•m n√†y l√† ·ªü ph√≠a tr√™n c√πng b√™n tr√°i c·ªßa bi·ªÉu ƒë·ªì (th·ªùi gian cho m·ªói d·ª± ƒëo√°n th·∫•p, F1-score cao).\n",
        "\n",
        "Trong tr∆∞·ªùng h·ª£p n√†y, c√≥ s·ª± c√¢n b·∫±ng r√µ r√†ng v·ªÅ th·ªùi gian cho m·ªói d·ª± ƒëo√°n v√† ch·∫•t l∆∞·ª£ng. M√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët nh·∫•t c·ªßa ch√∫ng ta c√≥ b·∫≠c ƒë·ªô l·ªõn d√†i h∆°n h∆°n cho m·ªói d·ª± ƒëo√°n nh∆∞ng ch·ªâ d·∫´n ƒë·∫øn vi·ªác tƒÉng m·ªôt s·ªë ƒëi·ªÉm F1-score.\n",
        "\n",
        "C√°c b·∫°n c·∫ßn ch√∫ √Ω lo·∫°i c√¢n b·∫±ng n√†y khi k·∫øt h·ª£p c√°c m√¥ h√¨nh h·ªçc m√°y v√†o ·ª©ng d·ª•ng c·ªßa ri√™ng m√¨nh."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJWGI6GpH4Gl"
      },
      "source": [
        "## üõ† B√†i t·∫≠p th·ª±c h√†nh\n",
        "> **L∆∞u √Ω:** C√°c b·∫°n c·∫ßn l√†m ph·∫ßn b√†i t·∫≠p n√†y ƒë·ªÉ chu·∫©n b·ªã cho phi√™n review lab.\n",
        "\n",
        "1. X√¢y d·ª±ng l·∫°i, bi√™n d·ªãch v√† hu·∫•n luy·ªán `model_1`, `model_2` v√† `model_5` b·∫±ng [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) thay v√¨ Functional API.\n",
        "2. Hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh c∆° s·ªü v·ªõi 10% d·ªØ li·ªáu hu·∫•n luy·ªán. M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o so v·ªõi m√¥ h√¨nh Universal Sentence Encoder v·ªõi 10% d·ªØ li·ªáu hu·∫•n luy·ªán?\n",
        "3. Th·ª≠ tinh ch·ªânh m√¥ h√¨nh TF Hub Universal Sentence Encoder b·∫±ng c√°ch ƒë·∫∑t `training=True` khi kh·ªüi t·∫°o n√≥ d∆∞·ªõi d·∫°ng Keras layer.\n",
        "\n",
        "```\n",
        "Ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng encoding layer thay cho text_vectorizer v√† embedding layer\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=True) # b·∫≠t hu·∫•n luy·ªán ƒë·ªÉ tinh ch·ªânh m√¥ h√¨nh TensorFlow Hub\n",
        "```\n",
        "4. Hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh t·ªët nh·∫•t m√† b·∫°n c√≥ tr√™n to√†n b·ªô t·∫≠p hu·∫•n luy·ªán (kh√¥ng ph√¢n t√°ch ki·ªÉm ƒë·ªãnh). Sau ƒë√≥ s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán n√†y ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n tr√™n t·∫≠p d·ªØ li·ªáu ki·ªÉm tra v√† ƒë·ªãnh d·∫°ng d·ª± ƒëo√°n sao cho c√≥ c√πng ƒë·ªãnh d·∫°ng v·ªõi file `sample_submission.csv` t·ª´ Kaggle (xem tab Files tr√™n Colab ƒë·ªÉ bi·∫øt file `sample_submission.csv` tr√¥ng nh∆∞ th·∫ø n√†o). Sau khi ho√†n th√†nh, [h√£y g·ª≠i t·ªõi Kaggle competition](https://www.kaggle.com/c/nlp-getting-started/data), m√¥ h√¨nh c·ªßa b·∫°n ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?\n",
        "5. K·∫øt h·ª£p c√°c d·ª± ƒëo√°n ensemble b·∫±ng c√°ch s·ª≠ d·ª•ng majority vote (mode), ƒëi·ªÅu n√†y ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o so v·ªõi t√≠nh trung b√¨nh x√°c su·∫•t d·ª± ƒëo√°n c·ªßa t·ª´ng m√¥ h√¨nh?\n",
        "6. T·∫°o confusion matrix v·ªõi c√°c d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët nh·∫•t tr√™n t·∫≠p ki·ªÉm ƒë·ªãnh v√† c√°c nh√£n g·ªëc ki·ªÉm ƒë·ªãnh."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BarVJji8H6M4"
      },
      "source": [
        "## üìñ T√†i li·ªáu ƒë·ªçc th√™m\n",
        "\n",
        "ƒê·ªÉ th·ª±c h√†nh nh·ªØng g√¨ ƒë√£ h·ªçc, b·∫°n n√™n d√†nh m·ªói gi·ªù cho 3 trong s·ªë nh·ªØng ƒëi·ªÅu sau ƒë√¢y (t·ªïng c·ªông 3 gi·ªù, b·∫°n c≈©ng c√≥ th·ªÉ xem qua t·∫•t c·∫£ n·∫øu mu·ªën), sau ƒë√≥ vi·∫øt blog v·ªÅ nh·ªØng g√¨ b·∫°n ƒë√£ h·ªçc ƒë∆∞·ª£c.\n",
        "\n",
        "* ƒê·ªÉ c√≥ c√°i nh√¨n t·ªïng quan v·ªÅ c√°c b√†i to√°n kh√°c nhau trong NLP v√† c√°ch x·ª≠ l√Ω ch√∫ng, h√£y ƒë·ªçc qua:\n",
        " * [A Simple Introduction to Natural Language Processing](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32)\n",
        " * [How to solve 90% of NLP problems: a step-by-step guide](https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e)\n",
        "* Xem qua [c√°c b√†i gi·∫£ng c·ªßa MIT v·ªÅ Recurrent Neural Networks](https://youtu.be/SEnXr6v2ifU). ƒê√¢y s·∫Ω l√† m·ªôt trong nh·ªØng ph·∫ßn b·ªï sung tuy·ªát v·ªùi nh·∫•t v·ªÅ nh·ªØng g√¨ di·ªÖn ra ƒë·∫±ng sau m√¥ h√¨nh RNN m√† b·∫°n ƒëang x√¢y d·ª±ng.\n",
        "* ƒê·ªçc qua trang [word embedding tr√™n website TensorFlow](https://www.tensorflow.org/tutorials/text/word_embeddings), embedding l√† m·ªôt b·ªô ph·∫≠n l·ªõn c·ªßa NLP. Ch√∫ng ta ƒë√£ ƒë·ªÅ c·∫≠p ch√∫ng trong su·ªët notebook n√†y nh∆∞ng v·∫´n n√™n luy·ªán t·∫≠p th√™m, t·ªët h∆°n n√™n vi·∫øt to√†n b·ªô code v√†o notebook m·ªõi.\n",
        "* ƒê·ªÉ bi·∫øt th√™m v·ªÅ RNN trong TensorFlow, h√£y ƒë·ªçc v√† m√¥ ph·ªèng l·∫°i [TensorFlow RNN guide](https://www.tensorflow.org/guide/keras/rnn). Ch√∫ng t√¥i ƒë√£ ƒë·ªÅ c·∫≠p nhi·ªÅu kh√°i ni·ªám trong h∆∞·ªõng d·∫´n n√†y, tuy nhi√™n, b·∫°n v·∫´n n√™n t·ª± vi·∫øt l·∫°i code.\n",
        "* Kh√¥ng ph·∫£i l√∫c n√†o d·ªØ li·ªáu text c≈©ng c√≥ m·ªôt th∆∞ vi·ªán t·ªët nh∆∞ d·ªØ li·ªáu ch√∫ng ta ƒë√£ download. V√¨ v·∫≠y, n·∫øu b·∫°n mu·ªën chu·∫©n b·ªã nhi·ªÅu ngu·ªìn text kh√°c nhau cho c√°c m√¥ h√¨nh h·ªçc s√¢u TensorFlow, h√£y ki·ªÉm tra nh·ªØng ƒëi·ªÅu sau:\n",
        " * [H∆∞·ªõng d·∫´n load text TensorFlow](https://www.tensorflow.org/tutorials/load_data/text).\n",
        "  * [ƒê·ªçc file text v·ªõi Python](https://realpython.com/read-write-files-python/) t·ª´ Real Python.\n",
        "* Notebook n√†y t·∫≠p trung v√†o vi·ªác vi·∫øt code NLP. ƒê·ªÉ bi·∫øt NLP v·ªõi H·ªçc s√¢u di·ªÖn ra th·∫ø n√†o v·ªÅ m·∫∑t to√°n h·ªçc, h√£y ƒë·ªçc [Ph·∫ßn 1 c·ªßa b√†i gi·∫£ng X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v·ªõi H·ªçc s√¢u ƒë·∫øn t·ª´ Standford](https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf).\n",
        "  * ƒê·ªÉ t√¨m hi·ªÉu s√¢u h∆°n n·ªØa, b·∫°n c√≥ th·ªÉ tham gia to√†n b·ªô kh√≥a h·ªçc [CS224n](http://web.stanford.edu/class/cs224n/) (X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v·ªõi H·ªçc s√¢u).\n",
        "* C√°c b√†i blog hay n√™n ƒë·ªçc:\n",
        "  * [The Unreasonable Effectiveness of RNNs](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) (Andrei Karpathy) ƒë√†o s√¢u v√†o vi·ªác t·∫°o Shakespeare text v·ªõi RNN.\n",
        "  * [Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT](https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794) (Mauro Di Pietro). T·ªïng quan v·ªÅ c√°c k·ªπ thu·∫≠t kh√°c nhau ƒë·ªÉ chuy·ªÉn text th√†nh s·ªë r·ªìi ph√¢n lo·∫°i n√≥.\n",
        "  * [What are word embeddings?](https://machinelearningmastery.com/what-are-word-embeddings/) t·ª´ Machine Learning Mastery.\n",
        "* C√°c ch·ªß ƒë·ªÅ ƒë√°ng c√¢n nh·∫Øc kh√°c:\n",
        "  * [C∆° ch·∫ø Attention](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/). ƒê√¢y l√† th√†nh ph·∫ßn c∆° b·∫£n c·ªßa ki·∫øn ‚Äã‚Äãtr√∫c transformer v√† c≈©ng th∆∞·ªùng c·∫£i thi·ªán cho c√°c m√¥ h√¨nh NLP s√¢u.\n",
        "  * [Ki·∫øn tr√∫c Transformer](http://jalammar.github.io/illustrated-transformer/). Ki·∫øn tr√∫c m√¥ h√¨nh n√†y g·∫ßn ƒë√¢y ƒë√£ g√¢y b√£o c·ªông ƒë·ªìng NLP, ghi ƒëi·ªÉm c√°c ƒë√°nh gi√° x·∫øp h·∫°ng t√¢n ti·∫øn nh·∫•t. Tuy nhi√™n, c·∫ßn x·ª≠ l√Ω th√™m ƒë·ªÉ b·∫Øt ƒë·∫ßu, th∆∞ vi·ªán [HuggingFace Models (tr∆∞·ªõc ƒë√¢y l√† HuggingFace Transformers)](https://huggingface.co/models/) c√≥ l·∫Ω l√† kh·ªüi ƒë·∫ßu t·ªët nh·∫•t c·ªßa b·∫°n.\n",
        "    * V√† b√¢y gi·ªù [HuggingFace c≈©ng c√≥ kh√≥a h·ªçc ri√™ng](https://huggingface.co/course/chapter1) v·ªÅ c√°ch ho·∫°t ƒë·ªông c·ªßa th∆∞ vi·ªán! T√¥i ch∆∞a th·ª±c hi·ªán ƒë∆∞·ª£c ƒëi·ªÅu ƒë√≥, nh∆∞ng b·∫•t c·ª© th·ª© g√¨ HuggingFace l√†m ra ƒë·ªÅu ·ªü ƒë·∫≥ng c·∫•p th·∫ø gi·ªõi.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLzfxgXkzEdr"
      },
      "source": [
        "> üìñ **T√†i li·ªáu:** Xem to√†n b·ªô t√†i li·ªáu kh√≥a h·ªçc tr√™n GitHub: https://github.com/mrdbourke/tensorflow-deep-learning"
      ]
    }
  ]
}